{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76ab80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.load_session('case_value_session1.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c5e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ef8ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5356, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['gen', 'horas_sem', 'sal_caidos', 'prima_antig', 'prima_vac', 'rec20',\n",
       "       'prima_dom', 'desc_sem', 'desc_ob', 'sarimssinf', 'utilidades',\n",
       "       'nulidad', 'salario_diario', 'reinst', 'indem', 'horas_extra',\n",
       "       'antiguedad', 'min_prima_antig', 'min_ag', 'min_vac', 'min_ley',\n",
       "       'c_recsueldo', 'reclutamiento', 'num_actores', 'liq_total', 'duracion',\n",
       "       'liq_total_disc', 'hd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:/Users/isaac/Dropbox/Apps/ShareLaTeX/information_lawyer_quality'\n",
    "\n",
    "# Read data \n",
    "data = pd.read_csv(path + '/_aux/hd_case_value.csv') \n",
    "#data = data.sample(frac=0.1, replace=True, random_state=1)\n",
    "print(data.shape)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657bb0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen</th>\n",
       "      <th>horas_sem</th>\n",
       "      <th>sal_caidos</th>\n",
       "      <th>prima_antig</th>\n",
       "      <th>prima_vac</th>\n",
       "      <th>rec20</th>\n",
       "      <th>prima_dom</th>\n",
       "      <th>desc_sem</th>\n",
       "      <th>desc_ob</th>\n",
       "      <th>sarimssinf</th>\n",
       "      <th>...</th>\n",
       "      <th>min_ag</th>\n",
       "      <th>min_vac</th>\n",
       "      <th>min_ley</th>\n",
       "      <th>c_recsueldo</th>\n",
       "      <th>reclutamiento</th>\n",
       "      <th>num_actores</th>\n",
       "      <th>liq_total</th>\n",
       "      <th>duracion</th>\n",
       "      <th>liq_total_disc</th>\n",
       "      <th>hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5340.000000</td>\n",
       "      <td>5256.000000</td>\n",
       "      <td>5340.000000</td>\n",
       "      <td>5340.000000</td>\n",
       "      <td>5334.000000</td>\n",
       "      <td>5341.000000</td>\n",
       "      <td>5341.000000</td>\n",
       "      <td>5341.000000</td>\n",
       "      <td>5341.000000</td>\n",
       "      <td>5341.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5286.000000</td>\n",
       "      <td>5209.000000</td>\n",
       "      <td>5.336000e+03</td>\n",
       "      <td>5.340000e+03</td>\n",
       "      <td>5198.000000</td>\n",
       "      <td>5356.000000</td>\n",
       "      <td>5.356000e+03</td>\n",
       "      <td>5356.000000</td>\n",
       "      <td>5.356000e+03</td>\n",
       "      <td>5356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.483895</td>\n",
       "      <td>57.286975</td>\n",
       "      <td>0.982959</td>\n",
       "      <td>0.849438</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>0.254634</td>\n",
       "      <td>0.200899</td>\n",
       "      <td>0.171691</td>\n",
       "      <td>0.290957</td>\n",
       "      <td>0.552893</td>\n",
       "      <td>...</td>\n",
       "      <td>2758.465764</td>\n",
       "      <td>2068.817676</td>\n",
       "      <td>5.341699e+04</td>\n",
       "      <td>2.172577e+04</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>1.141337</td>\n",
       "      <td>3.080080e+04</td>\n",
       "      <td>28.801694</td>\n",
       "      <td>1.976041e+04</td>\n",
       "      <td>0.933906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499787</td>\n",
       "      <td>15.538088</td>\n",
       "      <td>0.129437</td>\n",
       "      <td>0.357655</td>\n",
       "      <td>0.206486</td>\n",
       "      <td>0.435696</td>\n",
       "      <td>0.400710</td>\n",
       "      <td>0.377147</td>\n",
       "      <td>0.454246</td>\n",
       "      <td>0.497241</td>\n",
       "      <td>...</td>\n",
       "      <td>14974.160132</td>\n",
       "      <td>6613.749970</td>\n",
       "      <td>1.078012e+05</td>\n",
       "      <td>2.429452e+05</td>\n",
       "      <td>0.396740</td>\n",
       "      <td>0.464623</td>\n",
       "      <td>1.437205e+05</td>\n",
       "      <td>153.506144</td>\n",
       "      <td>8.149673e+04</td>\n",
       "      <td>0.248470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.470000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>561.455365</td>\n",
       "      <td>361.970000</td>\n",
       "      <td>2.059550e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1282.189900</td>\n",
       "      <td>868.609990</td>\n",
       "      <td>3.248035e+04</td>\n",
       "      <td>1.077145e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000e+03</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>5.884490e+03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2489.529900</td>\n",
       "      <td>1929.759300</td>\n",
       "      <td>5.545549e+04</td>\n",
       "      <td>7.475002e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.216250e+04</td>\n",
       "      <td>1.630137</td>\n",
       "      <td>1.650361e+04</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>725185.750000</td>\n",
       "      <td>213154.980000</td>\n",
       "      <td>4.449881e+06</td>\n",
       "      <td>1.531981e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.700000e+06</td>\n",
       "      <td>1396.000000</td>\n",
       "      <td>3.453441e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               gen    horas_sem   sal_caidos  prima_antig    prima_vac  \\\n",
       "count  5340.000000  5256.000000  5340.000000  5340.000000  5334.000000   \n",
       "mean      0.483895    57.286975     0.982959     0.849438     0.955381   \n",
       "std       0.499787    15.538088     0.129437     0.357655     0.206486   \n",
       "min       0.000000     3.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000    48.000000     1.000000     1.000000     1.000000   \n",
       "50%       0.000000    60.000000     1.000000     1.000000     1.000000   \n",
       "75%       1.000000    66.000000     1.000000     1.000000     1.000000   \n",
       "max       1.000000   258.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             rec20    prima_dom     desc_sem      desc_ob   sarimssinf  ...  \\\n",
       "count  5341.000000  5341.000000  5341.000000  5341.000000  5341.000000  ...   \n",
       "mean      0.254634     0.200899     0.171691     0.290957     0.552893  ...   \n",
       "std       0.435696     0.400710     0.377147     0.454246     0.497241  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000  ...   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     1.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "              min_ag        min_vac       min_ley   c_recsueldo  \\\n",
       "count    5286.000000    5209.000000  5.336000e+03  5.340000e+03   \n",
       "mean     2758.465764    2068.817676  5.341699e+04  2.172577e+04   \n",
       "std     14974.160132    6613.749970  1.078012e+05  2.429452e+05   \n",
       "min         2.470000       0.990000  0.000000e+00  0.000000e+00   \n",
       "25%       561.455365     361.970000  2.059550e+04  0.000000e+00   \n",
       "50%      1282.189900     868.609990  3.248035e+04  1.077145e+03   \n",
       "75%      2489.529900    1929.759300  5.545549e+04  7.475002e+03   \n",
       "max    725185.750000  213154.980000  4.449881e+06  1.531981e+07   \n",
       "\n",
       "       reclutamiento  num_actores     liq_total     duracion  liq_total_disc  \\\n",
       "count    5198.000000  5356.000000  5.356000e+03  5356.000000    5.356000e+03   \n",
       "mean        0.195652     1.141337  3.080080e+04    28.801694    1.976041e+04   \n",
       "std         0.396740     0.464623  1.437205e+05   153.506144    8.149673e+04   \n",
       "min         0.000000     1.000000  0.000000e+00     0.000000    0.000000e+00   \n",
       "25%         0.000000     1.000000  0.000000e+00     0.350000    0.000000e+00   \n",
       "50%         0.000000     1.000000  9.000000e+03     0.760000    5.884490e+03   \n",
       "75%         0.000000     1.000000  2.216250e+04     1.630137    1.650361e+04   \n",
       "max         1.000000     3.000000  6.700000e+06  1396.000000    3.453441e+06   \n",
       "\n",
       "                hd  \n",
       "count  5356.000000  \n",
       "mean      0.933906  \n",
       "std       0.248470  \n",
       "min       0.000000  \n",
       "25%       1.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c342c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['gen',\n",
    "            'reclutamiento',\n",
    "            'salario_diario',\n",
    "            'horas_sem',\n",
    "            'reinst',\n",
    "            'prima_dom',\n",
    "            'desc_sem',\n",
    "            'sarimssinf',\n",
    "            'antiguedad',\n",
    "            'c_recsueldo',\n",
    "            'desc_ob',\n",
    "            'min_prima_antig',\n",
    "            'min_ag',\n",
    "            'min_vac',\n",
    "            'min_ley']]\n",
    "\n",
    "Z = data[['num_actores',\n",
    "            'gen',\n",
    "            'reclutamiento',\n",
    "            'salario_diario',\n",
    "            'antiguedad',          \n",
    "            'horas_sem',\n",
    "            'reinst',\n",
    "            'indem',\n",
    "            'sal_caidos',\n",
    "            'prima_antig',\n",
    "            'prima_vac',\n",
    "            'horas_extra',\n",
    "            'rec20',\n",
    "            'prima_dom',\n",
    "            'desc_sem',\n",
    "            'sarimssinf',\n",
    "            'utilidades',\n",
    "            'nulidad']]\n",
    "\n",
    "y1 = data['liq_total']\n",
    "y2 = data['liq_total_disc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e1c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_featuresX = ['salario_diario',\n",
    "            'horas_sem',\n",
    "            'antiguedad',\n",
    "            'c_recsueldo',\n",
    "            'min_prima_antig',\n",
    "            'min_ag',\n",
    "            'min_vac',\n",
    "            'min_ley']\n",
    "numeric_featuresZ = ['salario_diario',\n",
    "            'horas_sem',\n",
    "            'antiguedad']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('polynomial', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "categorical_featuresZ = ['num_actores']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse = False)\n",
    "\n",
    "\n",
    "binary_featuresX = ['gen',\n",
    "            'reclutamiento',\n",
    "            'reinst',\n",
    "            'prima_dom',\n",
    "            'desc_sem',\n",
    "            'sarimssinf',\n",
    "            'desc_ob']\n",
    "binary_featuresZ = ['gen',\n",
    "            'reclutamiento',\n",
    "            'reinst',\n",
    "            'indem',\n",
    "            'sal_caidos',\n",
    "            'prima_antig',\n",
    "            'prima_vac',\n",
    "            'horas_extra',\n",
    "            'rec20',\n",
    "            'prima_dom',\n",
    "            'desc_sem',\n",
    "            'sarimssinf',\n",
    "            'utilidades',\n",
    "            'nulidad']\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('polynomial', PolynomialFeatures(degree=1, include_bias=False))])\n",
    "\n",
    "\n",
    "preprocessorX = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_featuresX),\n",
    "        ('bin', binary_transformer, binary_featuresX)])\n",
    "preprocessorZ = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_featuresZ),\n",
    "        ('cat', categorical_transformer, categorical_featuresZ),\n",
    "        ('bin', binary_transformer, binary_featuresZ)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e3874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Z_train, Z_test, y_train, y_test = train_test_split(X, Z, y2, test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed55188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c5193d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['salario_diario',\n",
       "                                                   'horas_sem', 'antiguedad',\n",
       "                                                   'c_recsueldo',\n",
       "                                                   'min_prima_antig', 'min_ag',\n",
       "                                                   'min_vac', 'min_ley']),\n",
       "                                                 ('bin',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(degree=1,\n",
       "                                                                                      include_bias=False))]),\n",
       "                                                  ['gen', 'reclutamiento',\n",
       "                                                   'reinst', 'prima_dom',\n",
       "                                                   'desc_sem', 'sarimssinf',\n",
       "                                                   'desc_ob'])])),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "LRX = Pipeline(steps=[('preprocessor', preprocessorX),\n",
    "                      ('model', LinearRegression())])\n",
    "LRX.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb1488c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['salario_diario',\n",
       "                                                   'horas_sem', 'antiguedad']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['num_actores']),\n",
       "                                                 ('bin',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(degree=1,\n",
       "                                                                                      include_bias=False))]),\n",
       "                                                  ['gen', 'reclutamiento',\n",
       "                                                   'reinst', 'indem',\n",
       "                                                   'sal_caidos', 'prima_antig',\n",
       "                                                   'prima_vac', 'horas_extra',\n",
       "                                                   'rec20', 'prima_dom',\n",
       "                                                   'desc_sem', 'sarimssinf',\n",
       "                                                   'utilidades',\n",
       "                                                   'nulidad'])])),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRZ = Pipeline(steps=[('preprocessor', preprocessorZ),\n",
    "                      ('model', LinearRegression())])\n",
    "LRZ.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fbb290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cee3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 432 candidates, totalling 6480 fits\n",
      "Fitting 15 folds for each of 432 candidates, totalling 6480 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedKFold(n_repeats=3, n_splits=5, random_state=123),\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('polynomial',\n",
       "                                                                                          PolynomialFeatures(include_bias=False)),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['salario_diario',\n",
       "                                                                          'horas_sem',\n",
       "                                                                          'antiguedad']),\n",
       "                                                                        ('cat',\n",
       "                                                                         O...\n",
       "                                        GradientBoostingRegressor(n_iter_no_change=5,\n",
       "                                                                  random_state=123))]),\n",
       "             n_jobs=7,\n",
       "             param_grid={'model__learning_rate': [0.001, 0.01, 0.1],\n",
       "                         'model__max_depth': [None, 1, 3, 5, 10, 20],\n",
       "                         'model__max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'model__n_estimators': [50, 100, 500, 1000],\n",
       "                         'model__subsample': [0.5, 1]},\n",
       "             return_train_score=True, scoring='neg_root_mean_squared_error',\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid de hiperparámetros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = {'model__n_estimators'  : [50, 100, 500, 1000],\n",
    "              'model__max_features'  : ['auto', 'sqrt', 'log2'],\n",
    "              'model__max_depth'     : [None, 1, 3, 5, 10, 20],\n",
    "              'model__subsample'     : [0.5, 1],\n",
    "              'model__learning_rate' : [0.001, 0.01, 0.1]\n",
    "             }\n",
    "\n",
    "\n",
    "GB  = GradientBoostingRegressor(\n",
    "                        random_state        = 123,\n",
    "                        # Activación de la parada temprana\n",
    "                        validation_fraction = 0.1,\n",
    "                        n_iter_no_change    = 5,\n",
    "                        tol                 = 0.0001\n",
    "                    )\n",
    "# Gradient Boosting\n",
    "GBX = Pipeline(steps=[('preprocessor', preprocessorX),\n",
    "                      ('model', GB)])\n",
    "GBZ = Pipeline(steps=[('preprocessor', preprocessorZ),\n",
    "                      ('model', GB)])\n",
    "\n",
    "# Búsqueda por grid search con validación cruzada\n",
    "# ==============================================================================\n",
    "gridX = GridSearchCV(GBX,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 4,\n",
    "        return_train_score = True\n",
    "       )\n",
    "gridZ = GridSearchCV(GBZ,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 4,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridX.fit(X = X_train, y = y_train)\n",
    "gridZ.fit(X = Z_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6295d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__subsample</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-63069.171309</td>\n",
       "      <td>20991.393747</td>\n",
       "      <td>-54502.803082</td>\n",
       "      <td>7438.463315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-63069.171309</td>\n",
       "      <td>20991.393747</td>\n",
       "      <td>-54502.803082</td>\n",
       "      <td>7438.463315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-63069.171309</td>\n",
       "      <td>20991.393747</td>\n",
       "      <td>-54502.803082</td>\n",
       "      <td>7438.463315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-63125.498467</td>\n",
       "      <td>20571.390753</td>\n",
       "      <td>-56638.292983</td>\n",
       "      <td>7707.608457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_model__learning_rate param_model__max_depth  \\\n",
       "158                       0.01                   None   \n",
       "156                       0.01                   None   \n",
       "154                       0.01                   None   \n",
       "272                       0.01                     20   \n",
       "\n",
       "    param_model__max_features param_model__n_estimators  \\\n",
       "158                      sqrt                      1000   \n",
       "156                      sqrt                       500   \n",
       "154                      sqrt                       100   \n",
       "272                      sqrt                        50   \n",
       "\n",
       "    param_model__subsample  mean_test_score  std_test_score  mean_train_score  \\\n",
       "158                    0.5    -63069.171309    20991.393747     -54502.803082   \n",
       "156                    0.5    -63069.171309    20991.393747     -54502.803082   \n",
       "154                    0.5    -63069.171309    20991.393747     -54502.803082   \n",
       "272                    0.5    -63125.498467    20571.390753     -56638.292983   \n",
       "\n",
       "     std_train_score  \n",
       "158      7438.463315  \n",
       "156      7438.463315  \n",
       "154      7438.463315  \n",
       "272      7707.608457  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb155bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final_GBX = gridX.best_estimator_\n",
    "modelo_final_GBZ = gridZ.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec318b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importances_mean</th>\n",
       "      <th>importances_std</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1369.923209</td>\n",
       "      <td>30.428258</td>\n",
       "      <td>salario_diario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1272.040208</td>\n",
       "      <td>76.346678</td>\n",
       "      <td>antiguedad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1063.813219</td>\n",
       "      <td>41.270977</td>\n",
       "      <td>min_vac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1021.884767</td>\n",
       "      <td>26.354959</td>\n",
       "      <td>min_ley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>932.458964</td>\n",
       "      <td>37.691371</td>\n",
       "      <td>c_recsueldo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>625.800035</td>\n",
       "      <td>46.292649</td>\n",
       "      <td>min_ag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>395.191065</td>\n",
       "      <td>79.743210</td>\n",
       "      <td>min_prima_antig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349.643261</td>\n",
       "      <td>84.362845</td>\n",
       "      <td>horas_sem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.981643</td>\n",
       "      <td>5.885754</td>\n",
       "      <td>gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.458658</td>\n",
       "      <td>7.642260</td>\n",
       "      <td>sarimssinf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.352610</td>\n",
       "      <td>1.350280</td>\n",
       "      <td>reinst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.934905</td>\n",
       "      <td>0.700044</td>\n",
       "      <td>desc_ob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.153529</td>\n",
       "      <td>0.213684</td>\n",
       "      <td>desc_sem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.100546</td>\n",
       "      <td>0.431011</td>\n",
       "      <td>prima_dom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988660</td>\n",
       "      <td>0.479821</td>\n",
       "      <td>reclutamiento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    importances_mean  importances_std          feature\n",
       "2        1369.923209        30.428258   salario_diario\n",
       "8        1272.040208        76.346678       antiguedad\n",
       "13       1063.813219        41.270977          min_vac\n",
       "14       1021.884767        26.354959          min_ley\n",
       "9         932.458964        37.691371      c_recsueldo\n",
       "12        625.800035        46.292649           min_ag\n",
       "11        395.191065        79.743210  min_prima_antig\n",
       "3         349.643261        84.362845        horas_sem\n",
       "0          12.981643         5.885754              gen\n",
       "7          10.458658         7.642260       sarimssinf\n",
       "4           9.352610         1.350280           reinst\n",
       "10          1.934905         0.700044          desc_ob\n",
       "6           1.153529         0.213684         desc_sem\n",
       "5           1.100546         0.431011        prima_dom\n",
       "1           0.988660         0.479821    reclutamiento"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importancia = permutation_importance(\n",
    "                estimator    = modelo_final_GBX,\n",
    "                X            = X_train,\n",
    "                y            = y_train,\n",
    "                n_repeats    = 5,\n",
    "                scoring      = 'neg_root_mean_squared_error',\n",
    "                n_jobs       = multiprocessing.cpu_count() - 1,\n",
    "                random_state = 123\n",
    "             )\n",
    "\n",
    "# Se almacenan los resultados (media y desviación) en un dataframe\n",
    "df_importancia = pd.DataFrame(\n",
    "                    {k: importancia[k] for k in ['importances_mean', 'importances_std']}\n",
    "                 )\n",
    "df_importancia['feature'] = X_train.columns\n",
    "df_importancia.sort_values('importances_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34ab6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac3a5388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 72 candidates, totalling 1080 fits\n",
      "Fitting 15 folds for each of 72 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__l2_regularization</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__loss</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>least_squares</td>\n",
       "      <td>20</td>\n",
       "      <td>-62004.285236</td>\n",
       "      <td>20479.769375</td>\n",
       "      <td>-59164.501226</td>\n",
       "      <td>5987.460466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>least_squares</td>\n",
       "      <td>None</td>\n",
       "      <td>-62007.484829</td>\n",
       "      <td>20487.917194</td>\n",
       "      <td>-59153.487344</td>\n",
       "      <td>5995.054509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>least_squares</td>\n",
       "      <td>20</td>\n",
       "      <td>-62069.271694</td>\n",
       "      <td>20485.313862</td>\n",
       "      <td>-58762.459814</td>\n",
       "      <td>5997.236032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>least_squares</td>\n",
       "      <td>None</td>\n",
       "      <td>-62080.375746</td>\n",
       "      <td>20477.548613</td>\n",
       "      <td>-58796.357092</td>\n",
       "      <td>5921.683080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__l2_regularization param_model__learning_rate  \\\n",
       "17                              0                       0.01   \n",
       "12                              0                       0.01   \n",
       "53                              1                       0.01   \n",
       "48                              1                       0.01   \n",
       "\n",
       "   param_model__loss param_model__max_depth  mean_test_score  std_test_score  \\\n",
       "17     least_squares                     20    -62004.285236    20479.769375   \n",
       "12     least_squares                   None    -62007.484829    20487.917194   \n",
       "53     least_squares                     20    -62069.271694    20485.313862   \n",
       "48     least_squares                   None    -62080.375746    20477.548613   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "17     -59164.501226      5987.460466  \n",
       "12     -59153.487344      5995.054509  \n",
       "53     -58762.459814      5997.236032  \n",
       "48     -58796.357092      5921.683080  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid de hiperparámetros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = {'model__loss'             : ['least_squares', 'least_absolute_deviation'],\n",
    "              'model__learning_rate'    : [0.001, 0.01, 0.1],\n",
    "              'model__max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "              'model__l2_regularization': [0, 1]\n",
    "             }\n",
    "\n",
    "\n",
    "# Gradient Boosting\n",
    "HGBX = Pipeline(steps=[('preprocessor', preprocessorX),\n",
    "                      ('model', HistGradientBoostingRegressor(\n",
    "                        max_iter            = 10000,\n",
    "                        # Activación de la parada temprana\n",
    "                        early_stopping      = True,\n",
    "                        scoring             = 'loss',\n",
    "                        validation_fraction = 0.1,\n",
    "                        n_iter_no_change    = 10,\n",
    "                        tol                 = 1e-7,\n",
    "                        random_state        = 123\n",
    "                    ))])\n",
    "HGBZ = Pipeline(steps=[('preprocessor', preprocessorZ),\n",
    "                      ('model', HistGradientBoostingRegressor(\n",
    "                        max_iter            = 10000,\n",
    "                        # Activación de la parada temprana\n",
    "                        early_stopping      = True,\n",
    "                        scoring             = 'loss',\n",
    "                        validation_fraction = 0.1,\n",
    "                        n_iter_no_change    = 10,\n",
    "                        tol                 = 1e-7,\n",
    "                        random_state        = 123\n",
    "                    ))])\n",
    "\n",
    "# Búsqueda por grid search con validación cruzada\n",
    "# ==============================================================================\n",
    "gridX = GridSearchCV(HGBX,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 4,\n",
    "        return_train_score = True\n",
    "       )\n",
    "gridZ = GridSearchCV(HGBZ,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 4,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridX.fit(X = X_train, y = y_train)\n",
    "gridZ.fit(X = Z_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42a94451",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final_HGBX = gridX.best_estimator_\n",
    "modelo_final_HGBZ = gridZ.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d7f5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da666f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid de hiperparámetros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = {'model__max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "              'model__subsample'        : [0.5, 1],\n",
    "              'model__learning_rate'    : [0.001, 0.01, 0.1],\n",
    "              'model__booster'          : ['gbtree'],\n",
    "              'model__n_estimators'     : [50, 100, 500, 1000],\n",
    "             }\n",
    "\n",
    "\n",
    "# Crear conjunto de validación\n",
    "# ==============================================================================\n",
    "np.random.seed(123)\n",
    "idx_validacion = np.random.choice(\n",
    "                    X_train.shape[0],\n",
    "                    size= int(X_train.shape[0]*0.1),\n",
    "                    replace=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67fcda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train.iloc[idx_validacion, :].copy()\n",
    "Z_val = Z_train.iloc[idx_validacion, :].copy()\n",
    "y_val = y_train.iloc[idx_validacion].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "822add39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_grid = X_train.reset_index(drop = True).drop(idx_validacion, axis = 0).copy()\n",
    "Z_train_grid = Z_train.reset_index(drop = True).drop(idx_validacion, axis = 0).copy()\n",
    "y_train_grid = y_train.reset_index(drop = True).drop(idx_validacion, axis = 0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2fe88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessorX_ = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_featuresX),\n",
    "        ('bin', binary_transformer, binary_featuresX)],\n",
    "        remainder='passthrough')\n",
    "preprocessorZ_ = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_featuresZ),\n",
    "        ('cat', categorical_transformer, categorical_featuresZ),\n",
    "        ('bin', binary_transformer, binary_featuresZ)],\n",
    "        remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bc60e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderX = preprocessorX_.fit(X_train)\n",
    "encoderZ = preprocessorZ_.fit(Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e7d7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_grid = encoderX.transform(X_train_grid)\n",
    "Z_train_grid = encoderZ.transform(Z_train_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b304532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = encoderX.transform(X_val)\n",
    "Z_val = encoderZ.transform(Z_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f17d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost necesita pasar los paramétros específicos del entrenamiento al llamar\n",
    "# al método .fit()\n",
    "fit_paramsX = {\"model__early_stopping_rounds\" : 5, \n",
    "              \"model__eval_metric\"           : \"rmse\", \n",
    "              \"model__eval_set\"              : [(X_val, y_val)],\n",
    "              \"model__verbose\"               : 0\n",
    "             }\n",
    "fit_paramsZ = {\"model__early_stopping_rounds\" : 5, \n",
    "              \"model__eval_metric\"           : \"rmse\", \n",
    "              \"model__eval_set\"              : [(Z_val, y_val)],\n",
    "              \"model__verbose\"               : 0\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8baaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBX = Pipeline(steps=[('model', XGBRegressor(\n",
    "                        random_state = 123\n",
    "                    ))])\n",
    "XGBZ = Pipeline(steps=[('model', XGBRegressor(\n",
    "                        random_state = 123\n",
    "                    ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ec079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Búsqueda por grid search con validación cruzada\n",
    "# ==============================================================================\n",
    "gridX = GridSearchCV(\n",
    "        estimator  = XGBX,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 4,\n",
    "        return_train_score = True\n",
    "       )\n",
    "gridZ = GridSearchCV(\n",
    "        estimator  = XGBZ,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 4,\n",
    "        return_train_score = True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5b0bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 144 candidates, totalling 2160 fits\n",
      "Fitting 15 folds for each of 144 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedKFold(n_repeats=3, n_splits=5, random_state=123),\n",
       "             estimator=Pipeline(steps=[('model',\n",
       "                                        XGBRegressor(base_score=None,\n",
       "                                                     booster=None,\n",
       "                                                     colsample_bylevel=None,\n",
       "                                                     colsample_bynode=None,\n",
       "                                                     colsample_bytree=None,\n",
       "                                                     gamma=None, gpu_id=None,\n",
       "                                                     importance_type='gain',\n",
       "                                                     interaction_constraints=None,\n",
       "                                                     learning_rate=None,\n",
       "                                                     max_delta_step=None,\n",
       "                                                     max_depth=None,\n",
       "                                                     min_ch...\n",
       "                                                     scale_pos_weight=None,\n",
       "                                                     subsample=None,\n",
       "                                                     tree_method=None,\n",
       "                                                     validate_parameters=None,\n",
       "                                                     verbosity=None))]),\n",
       "             n_jobs=7,\n",
       "             param_grid={'model__booster': ['gbtree'],\n",
       "                         'model__learning_rate': [0.001, 0.01, 0.1],\n",
       "                         'model__max_depth': [None, 1, 3, 5, 10, 20],\n",
       "                         'model__n_estimators': [50, 100, 500, 1000],\n",
       "                         'model__subsample': [0.5, 1]},\n",
       "             return_train_score=True, scoring='neg_root_mean_squared_error',\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridX.fit(X = X_train_grid, y = y_train_grid, **fit_paramsX)\n",
    "gridZ.fit(X = Z_train_grid, y = y_train_grid, **fit_paramsZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bbb2ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__booster</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__subsample</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>-66433.003375</td>\n",
       "      <td>22774.945189</td>\n",
       "      <td>-62386.853167</td>\n",
       "      <td>7416.332267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>-66433.003375</td>\n",
       "      <td>22774.945189</td>\n",
       "      <td>-62386.853167</td>\n",
       "      <td>7416.332267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>-66433.003375</td>\n",
       "      <td>22774.945189</td>\n",
       "      <td>-62386.853167</td>\n",
       "      <td>7416.332267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>-66433.003375</td>\n",
       "      <td>22774.945189</td>\n",
       "      <td>-62386.853167</td>\n",
       "      <td>7416.332267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_model__booster param_model__learning_rate param_model__max_depth  \\\n",
       "119               gbtree                        0.1                      3   \n",
       "117               gbtree                        0.1                      3   \n",
       "115               gbtree                        0.1                      3   \n",
       "113               gbtree                        0.1                      3   \n",
       "\n",
       "    param_model__n_estimators param_model__subsample  mean_test_score  \\\n",
       "119                      1000                      1    -66433.003375   \n",
       "117                       500                      1    -66433.003375   \n",
       "115                       100                      1    -66433.003375   \n",
       "113                        50                      1    -66433.003375   \n",
       "\n",
       "     std_test_score  mean_train_score  std_train_score  \n",
       "119    22774.945189     -62386.853167      7416.332267  \n",
       "117    22774.945189     -62386.853167      7416.332267  \n",
       "115    22774.945189     -62386.853167      7416.332267  \n",
       "113    22774.945189     -62386.853167      7416.332267  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "656ca5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final_XGBX = gridX.best_estimator_\n",
    "modelo_final_XGBZ = gridZ.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53863fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63b4d2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 72 candidates, totalling 1080 fits\n",
      "Fitting 15 folds for each of 72 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__criterion</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mse</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>-65576.848773</td>\n",
       "      <td>21402.003828</td>\n",
       "      <td>-48389.587037</td>\n",
       "      <td>3346.247156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mse</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>-65585.733666</td>\n",
       "      <td>21587.838127</td>\n",
       "      <td>-48261.791965</td>\n",
       "      <td>3159.783166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mae</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>-65622.080940</td>\n",
       "      <td>21584.480350</td>\n",
       "      <td>-26702.862047</td>\n",
       "      <td>3533.386616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mse</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>-65633.975781</td>\n",
       "      <td>21115.154903</td>\n",
       "      <td>-30663.165575</td>\n",
       "      <td>3249.604810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__criterion param_model__max_depth param_model__max_features  \\\n",
       "15                    mse                      3                      log2   \n",
       "17                    mse                      3                      log2   \n",
       "42                    mae                   None                      log2   \n",
       "24                    mse                     10                      log2   \n",
       "\n",
       "   param_model__n_estimators  mean_test_score  std_test_score  \\\n",
       "15                       100    -65576.848773    21402.003828   \n",
       "17                       500    -65585.733666    21587.838127   \n",
       "42                       100    -65622.080940    21584.480350   \n",
       "24                       100    -65633.975781    21115.154903   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "15     -48389.587037      3346.247156  \n",
       "17     -48261.791965      3159.783166  \n",
       "42     -26702.862047      3533.386616  \n",
       "24     -30663.165575      3249.604810  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'model__n_estimators': [100, 200, 500],\n",
    "              'model__max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "              'model__max_depth'   : [None, 3, 10, 20],\n",
    "              'model__criterion'   : [\"mse\", \"mae\"]\n",
    "             }\n",
    "\n",
    "# Random Forests\n",
    "RFX = Pipeline(steps=[('preprocessor', preprocessorX),\n",
    "                      ('model', RandomForestRegressor(random_state=123))])\n",
    "RFZ = Pipeline(steps=[('preprocessor', preprocessorZ),\n",
    "                      ('model', RandomForestRegressor(random_state=123))])\n",
    "\n",
    "# Búsqueda por grid search con validación cruzada\n",
    "# ==============================================================================\n",
    "gridX = GridSearchCV(\n",
    "        estimator  = RFX,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 4,\n",
    "        return_train_score = True\n",
    "       )\n",
    "gridZ = GridSearchCV(\n",
    "        estimator  = RFZ,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 4,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridX.fit(X = X_train, y = y_train)\n",
    "gridZ.fit(X = Z_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45cd9176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelo_final_RFX = gridX.best_estimator_\n",
    "modelo_final_RFZ = gridZ.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "105e5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "#from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39ef099c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['salario_diario',\n",
       "                                                   'horas_sem', 'antiguedad']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['num_actores']),\n",
       "                                                 ('bin',\n",
       "                                                  Pipeli...('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(degree=1,\n",
       "                                                                                      include_bias=False))]),\n",
       "                                                  ['gen', 'reclutamiento',\n",
       "                                                   'reinst', 'indem',\n",
       "                                                   'sal_caidos', 'prima_antig',\n",
       "                                                   'prima_vac', 'horas_extra',\n",
       "                                                   'rec20', 'prima_dom',\n",
       "                                                   'desc_sem', 'sarimssinf',\n",
       "                                                   'utilidades',\n",
       "                                                   'nulidad'])])),\n",
       "                ('components', TruncatedSVD(n_components=10)),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCR\n",
    "pcrX = Pipeline(steps=[('preprocessor', preprocessorX),\n",
    "                     ('components', TruncatedSVD(n_components=10)),\n",
    "                      ('model', LinearRegression())])\n",
    "pcrZ = Pipeline(steps=[('preprocessor', preprocessorZ),\n",
    "                     ('components', TruncatedSVD(n_components=10)),\n",
    "                      ('model', LinearRegression())])\n",
    "\n",
    "pcrX.fit(X_train, y_train)\n",
    "pcrZ.fit(Z_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43d79141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "plsX = Pipeline(steps=[('preprocessor', preprocessorX),\n",
    "                    ('model', PLSRegression(n_components=10))])\n",
    "plsZ = Pipeline(steps=[('preprocessor', preprocessorZ),\n",
    "                    ('model', PLSRegression(n_components=10))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a43a860b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['salario_diario',\n",
       "                                                   'horas_sem', 'antiguedad']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['num_actores']),\n",
       "                                                 ('bin',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(degree=1,\n",
       "                                                                                      include_bias=False))]),\n",
       "                                                  ['gen', 'reclutamiento',\n",
       "                                                   'reinst', 'indem',\n",
       "                                                   'sal_caidos', 'prima_antig',\n",
       "                                                   'prima_vac', 'horas_extra',\n",
       "                                                   'rec20', 'prima_dom',\n",
       "                                                   'desc_sem', 'sarimssinf',\n",
       "                                                   'utilidades',\n",
       "                                                   'nulidad'])])),\n",
       "                ('model', PLSRegression(n_components=10))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plsX.fit(X_train, y_train)\n",
    "plsZ.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b920738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39b54a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 288 candidates, totalling 4320 fits\n",
      "Iteration 1, loss = 2724755322.98816109\n",
      "Iteration 2, loss = 2510905567.62352467\n",
      "Iteration 3, loss = 2510563945.29874945\n",
      "Iteration 4, loss = 2510209491.26505947\n",
      "Iteration 5, loss = 2509836324.05729246\n",
      "Iteration 6, loss = 2509470050.22171783\n",
      "Iteration 7, loss = 2509098882.58382559\n",
      "Iteration 8, loss = 2508720854.41511488\n",
      "Iteration 9, loss = 2508335939.64172077\n",
      "Iteration 10, loss = 2507957552.95315552\n",
      "Iteration 11, loss = 2507576316.79245615\n",
      "Iteration 12, loss = 2507192308.70005798\n",
      "Iteration 13, loss = 2506803818.04110289\n",
      "Iteration 14, loss = 2506418807.21482182\n",
      "Iteration 15, loss = 2506039683.08998108\n",
      "Iteration 16, loss = 2505647681.40948439\n",
      "Iteration 17, loss = 2505269124.08581877\n",
      "Iteration 18, loss = 2504881401.21202183\n",
      "Iteration 19, loss = 2504491052.84546518\n",
      "Iteration 20, loss = 2504102144.05731964\n",
      "Iteration 21, loss = 2503714536.51567364\n",
      "Iteration 22, loss = 2503337148.56002045\n",
      "Iteration 23, loss = 2502951748.42273378\n",
      "Iteration 24, loss = 2502563507.37992907\n",
      "Iteration 25, loss = 2502183944.16042423\n",
      "Iteration 26, loss = 2501799289.72017002\n",
      "Iteration 27, loss = 2501424167.17338943\n",
      "Iteration 28, loss = 2501037185.57884932\n",
      "Iteration 29, loss = 2500656885.60002613\n",
      "Iteration 30, loss = 2500268236.52370119\n",
      "Iteration 31, loss = 2499887499.58621407\n",
      "Iteration 32, loss = 2499506439.72328854\n",
      "Iteration 33, loss = 2499131940.62824678\n",
      "Iteration 34, loss = 2498752291.17391777\n",
      "Iteration 35, loss = 2498378355.81440163\n",
      "Iteration 36, loss = 2498009545.55883074\n",
      "Iteration 37, loss = 2497628456.01624918\n",
      "Iteration 38, loss = 2497261537.57078457\n",
      "Iteration 39, loss = 2496888704.49977732\n",
      "Iteration 40, loss = 2496516419.25770903\n",
      "Iteration 41, loss = 2496134027.11153221\n",
      "Iteration 42, loss = 2495766628.22973728\n",
      "Iteration 43, loss = 2495387503.04449797\n",
      "Iteration 44, loss = 2495016166.67780352\n",
      "Iteration 45, loss = 2494646384.53153563\n",
      "Iteration 46, loss = 2494276747.89705086\n",
      "Iteration 47, loss = 2493914466.48909903\n",
      "Iteration 48, loss = 2493533604.38432360\n",
      "Iteration 49, loss = 2493166104.12164164\n",
      "Iteration 50, loss = 2492791276.10809851\n",
      "Iteration 51, loss = 2492423175.11314344\n",
      "Iteration 52, loss = 2492048365.62167597\n",
      "Iteration 53, loss = 2491686753.04519367\n",
      "Iteration 54, loss = 2491320997.23879623\n",
      "Iteration 55, loss = 2490956064.77349663\n",
      "Iteration 56, loss = 2490585956.19355011\n",
      "Iteration 57, loss = 2490215262.17824697\n",
      "Iteration 58, loss = 2489855851.92073154\n",
      "Iteration 59, loss = 2489488670.42729473\n",
      "Iteration 60, loss = 2489128003.67972851\n",
      "Iteration 61, loss = 2488772309.20875263\n",
      "Iteration 62, loss = 2488400912.97183275\n",
      "Iteration 63, loss = 2488042479.63519192\n",
      "Iteration 64, loss = 2487683574.60059643\n",
      "Iteration 65, loss = 2487322571.12076473\n",
      "Iteration 66, loss = 2486962974.52353001\n",
      "Iteration 67, loss = 2486597354.44666004\n",
      "Iteration 68, loss = 2486243997.48280716\n",
      "Iteration 69, loss = 2485883198.61884642\n",
      "Iteration 70, loss = 2485522514.97700214\n",
      "Iteration 71, loss = 2485166551.60330057\n",
      "Iteration 72, loss = 2484812384.29713154\n",
      "Iteration 73, loss = 2484456236.36642122\n",
      "Iteration 74, loss = 2484101460.39665937\n",
      "Iteration 75, loss = 2483744270.81102467\n",
      "Iteration 76, loss = 2483385267.53188753\n",
      "Iteration 77, loss = 2483037576.22201157\n",
      "Iteration 78, loss = 2482680206.73570585\n",
      "Iteration 79, loss = 2482329395.74183273\n",
      "Iteration 80, loss = 2481982036.71178436\n",
      "Iteration 81, loss = 2481622856.47620201\n",
      "Iteration 82, loss = 2481274167.42799854\n",
      "Iteration 83, loss = 2480917101.05120325\n",
      "Iteration 84, loss = 2480571136.37195683\n",
      "Iteration 85, loss = 2480216983.30244112\n",
      "Iteration 86, loss = 2479869286.30026770\n",
      "Iteration 87, loss = 2479520604.77185345\n",
      "Iteration 88, loss = 2479167811.22690773\n",
      "Iteration 89, loss = 2478826275.45837927\n",
      "Iteration 90, loss = 2478478707.87986422\n",
      "Iteration 91, loss = 2478126443.75702190\n",
      "Iteration 92, loss = 2477787012.47627878\n",
      "Iteration 93, loss = 2477442833.12758923\n",
      "Iteration 94, loss = 2477090390.62190342\n",
      "Iteration 95, loss = 2476752009.54797220\n",
      "Iteration 96, loss = 2476402816.00138569\n",
      "Iteration 97, loss = 2476060188.24519444\n",
      "Iteration 98, loss = 2475713224.76660585\n",
      "Iteration 99, loss = 2475363934.52709103\n",
      "Iteration 100, loss = 2475025873.24119186\n",
      "Iteration 101, loss = 2474684141.70819330\n",
      "Iteration 102, loss = 2474335796.94940329\n",
      "Iteration 103, loss = 2473993954.46053171\n",
      "Iteration 104, loss = 2473653849.15873766\n",
      "Iteration 105, loss = 2473308824.15254831\n",
      "Iteration 106, loss = 2472964437.39639425\n",
      "Iteration 107, loss = 2472634813.10863733\n",
      "Iteration 108, loss = 2472285623.56167650\n",
      "Iteration 109, loss = 2471941929.53126812\n",
      "Iteration 110, loss = 2471617263.62907934\n",
      "Iteration 111, loss = 2471272978.29706383\n",
      "Iteration 112, loss = 2470932131.16102362\n",
      "Iteration 113, loss = 2470603310.79687262\n",
      "Iteration 114, loss = 2470261801.94873762\n",
      "Iteration 115, loss = 2469927769.75466967\n",
      "Iteration 116, loss = 2469588658.71150160\n",
      "Iteration 117, loss = 2469256757.18681955\n",
      "Iteration 118, loss = 2468915005.35573912\n",
      "Iteration 119, loss = 2468592946.39499855\n",
      "Iteration 120, loss = 2468259269.43309736\n",
      "Iteration 121, loss = 2467928071.03734255\n",
      "Iteration 122, loss = 2467602326.75680542\n",
      "Iteration 123, loss = 2467263972.15471125\n",
      "Iteration 124, loss = 2466935204.77170229\n",
      "Iteration 125, loss = 2466607726.83530903\n",
      "Iteration 126, loss = 2466277337.69829941\n",
      "Iteration 127, loss = 2465949735.05699921\n",
      "Iteration 128, loss = 2465617915.06496286\n",
      "Iteration 129, loss = 2465286465.09231520\n",
      "Iteration 130, loss = 2464957169.74562120\n",
      "Iteration 131, loss = 2464628716.76697016\n",
      "Iteration 132, loss = 2464299477.87318373\n",
      "Iteration 133, loss = 2463974794.40718031\n",
      "Iteration 134, loss = 2463646349.63675308\n",
      "Iteration 135, loss = 2463321341.16641760\n",
      "Iteration 136, loss = 2462995459.59984779\n",
      "Iteration 137, loss = 2462672233.81711102\n",
      "Iteration 138, loss = 2462345102.24346495\n",
      "Iteration 139, loss = 2462019661.38405085\n",
      "Iteration 140, loss = 2461703060.27878189\n",
      "Iteration 141, loss = 2461379054.60602808\n",
      "Iteration 142, loss = 2461052839.01245975\n",
      "Iteration 143, loss = 2460732212.85463238\n",
      "Iteration 144, loss = 2460409392.57138968\n",
      "Iteration 145, loss = 2460093278.44977140\n",
      "Iteration 146, loss = 2459769232.71369267\n",
      "Iteration 147, loss = 2459453309.81849146\n",
      "Iteration 148, loss = 2459127467.28524303\n",
      "Iteration 149, loss = 2458810146.01059866\n",
      "Iteration 150, loss = 2458493376.08759069\n",
      "Iteration 151, loss = 2458163711.96585417\n",
      "Iteration 152, loss = 2457839007.72142553\n",
      "Iteration 153, loss = 2457512390.77255583\n",
      "Iteration 154, loss = 2457184019.18330288\n",
      "Iteration 155, loss = 2456872941.91334057\n",
      "Iteration 156, loss = 2456556267.99195719\n",
      "Iteration 157, loss = 2456240095.68197870\n",
      "Iteration 158, loss = 2455920796.10598660\n",
      "Iteration 159, loss = 2455608092.69964170\n",
      "Iteration 160, loss = 2455294374.02024984\n",
      "Iteration 161, loss = 2454979808.22967386\n",
      "Iteration 162, loss = 2454666865.39467812\n",
      "Iteration 163, loss = 2454360480.64567518\n",
      "Iteration 164, loss = 2454046864.10896397\n",
      "Iteration 165, loss = 2453729634.55531311\n",
      "Iteration 166, loss = 2453423980.58278751\n",
      "Iteration 167, loss = 2453112368.53508663\n",
      "Iteration 168, loss = 2452802511.09072733\n",
      "Iteration 169, loss = 2452502616.85321665\n",
      "Iteration 170, loss = 2452198752.59176683\n",
      "Iteration 171, loss = 2451886279.01403666\n",
      "Iteration 172, loss = 2451584734.86530495\n",
      "Iteration 173, loss = 2451275858.60412073\n",
      "Iteration 174, loss = 2450964876.50770855\n",
      "Iteration 175, loss = 2450657357.28765535\n",
      "Iteration 176, loss = 2450342824.49139452\n",
      "Iteration 177, loss = 2450043719.69664955\n",
      "Iteration 178, loss = 2449731894.32866144\n",
      "Iteration 179, loss = 2449435615.74501753\n",
      "Iteration 180, loss = 2449129286.08745718\n",
      "Iteration 181, loss = 2448827944.34323454\n",
      "Iteration 182, loss = 2448522902.95315218\n",
      "Iteration 183, loss = 2448221856.19136906\n",
      "Iteration 184, loss = 2447917189.59755564\n",
      "Iteration 185, loss = 2447614000.63413858\n",
      "Iteration 186, loss = 2447303739.53344536\n",
      "Iteration 187, loss = 2447005240.62047052\n",
      "Iteration 188, loss = 2446705436.50169086\n",
      "Iteration 189, loss = 2446412109.70339918\n",
      "Iteration 190, loss = 2446104743.16927147\n",
      "Iteration 191, loss = 2445812514.19275236\n",
      "Iteration 192, loss = 2445518135.00811148\n",
      "Iteration 193, loss = 2445224378.93763924\n",
      "Iteration 194, loss = 2444923858.93359804\n",
      "Iteration 195, loss = 2444633087.27374840\n",
      "Iteration 196, loss = 2444333361.72706747\n",
      "Iteration 197, loss = 2444046375.16764259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 198, loss = 2443744717.82070112\n",
      "Iteration 199, loss = 2443452814.50682211\n",
      "Iteration 200, loss = 2443151566.83743668\n",
      "Iteration 201, loss = 2442856848.03404951\n",
      "Iteration 202, loss = 2442571868.65741062\n",
      "Iteration 203, loss = 2442278011.55540752\n",
      "Iteration 204, loss = 2441981567.35803986\n",
      "Iteration 205, loss = 2441692082.30171347\n",
      "Iteration 206, loss = 2441393321.97740126\n",
      "Iteration 207, loss = 2441100619.44400263\n",
      "Iteration 208, loss = 2440813788.57672071\n",
      "Iteration 209, loss = 2440517059.67179441\n",
      "Iteration 210, loss = 2440228015.70899916\n",
      "Iteration 211, loss = 2439940463.26252031\n",
      "Iteration 212, loss = 2439654069.17013884\n",
      "Iteration 213, loss = 2439362430.91926241\n",
      "Iteration 214, loss = 2439084506.19746828\n",
      "Iteration 215, loss = 2438785490.61516523\n",
      "Iteration 216, loss = 2438503624.95822287\n",
      "Iteration 217, loss = 2438222062.82525539\n",
      "Iteration 218, loss = 2437925335.72946262\n",
      "Iteration 219, loss = 2437642641.13751745\n",
      "Iteration 220, loss = 2437357981.68183947\n",
      "Iteration 221, loss = 2437068534.01265955\n",
      "Iteration 222, loss = 2436776207.11295509\n",
      "Iteration 223, loss = 2436502641.39173508\n",
      "Iteration 224, loss = 2436210566.89249945\n",
      "Iteration 225, loss = 2435924782.23324060\n",
      "Iteration 226, loss = 2435647911.70869923\n",
      "Iteration 227, loss = 2435366658.71681643\n",
      "Iteration 228, loss = 2435078797.03211069\n",
      "Iteration 229, loss = 2434801391.28034925\n",
      "Iteration 230, loss = 2434521034.52428865\n",
      "Iteration 231, loss = 2434242778.54513597\n",
      "Iteration 232, loss = 2433965046.62856436\n",
      "Iteration 233, loss = 2433681513.76650572\n",
      "Iteration 234, loss = 2433398201.86359882\n",
      "Iteration 235, loss = 2433112850.65384960\n",
      "Iteration 236, loss = 2432833865.12587309\n",
      "Iteration 237, loss = 2432549553.38677073\n",
      "Iteration 238, loss = 2432274144.81797171\n",
      "Iteration 239, loss = 2432001139.46596003\n",
      "Iteration 240, loss = 2431721265.77438927\n",
      "Iteration 241, loss = 2431446560.30412722\n",
      "Iteration 242, loss = 2431172181.84431314\n",
      "Iteration 243, loss = 2430894000.58795595\n",
      "Iteration 244, loss = 2430623289.93567896\n",
      "Iteration 245, loss = 2430347798.19520998\n",
      "Iteration 246, loss = 2430081380.84151602\n",
      "Iteration 247, loss = 2429797227.70870352\n",
      "Iteration 248, loss = 2429532505.19107056\n",
      "Iteration 249, loss = 2429263505.20061255\n",
      "Iteration 250, loss = 2428993094.31103706\n",
      "Iteration 251, loss = 2428710115.38942099\n",
      "Iteration 252, loss = 2428444384.15817881\n",
      "Iteration 253, loss = 2428172397.16232920\n",
      "Iteration 254, loss = 2427902272.26662159\n",
      "Iteration 255, loss = 2427632368.71778536\n",
      "Iteration 256, loss = 2427357016.18053198\n",
      "Iteration 257, loss = 2427091145.52239513\n",
      "Iteration 258, loss = 2426829951.76823807\n",
      "Iteration 259, loss = 2426561574.43586445\n",
      "Iteration 260, loss = 2426296624.70833302\n",
      "Iteration 261, loss = 2426032655.73934793\n",
      "Iteration 262, loss = 2425767880.13141394\n",
      "Iteration 263, loss = 2425505541.45710897\n",
      "Iteration 264, loss = 2425230340.50393820\n",
      "Iteration 265, loss = 2424966068.53334332\n",
      "Iteration 266, loss = 2424705834.96201754\n",
      "Iteration 267, loss = 2424442585.20602703\n",
      "Iteration 268, loss = 2424175964.08773518\n",
      "Iteration 269, loss = 2423916711.58641195\n",
      "Iteration 270, loss = 2423647041.33870125\n",
      "Iteration 271, loss = 2423384399.60028934\n",
      "Iteration 272, loss = 2423129970.50858116\n",
      "Iteration 273, loss = 2422861297.66711521\n",
      "Iteration 274, loss = 2422605506.48135233\n",
      "Iteration 275, loss = 2422341276.45692205\n",
      "Iteration 276, loss = 2422090683.65328407\n",
      "Iteration 277, loss = 2421819908.74832582\n",
      "Iteration 278, loss = 2421562417.67361736\n",
      "Iteration 279, loss = 2421295465.89631224\n",
      "Iteration 280, loss = 2421034082.01609468\n",
      "Iteration 281, loss = 2420781934.02092838\n",
      "Iteration 282, loss = 2420526550.86499453\n",
      "Iteration 283, loss = 2420271484.48543358\n",
      "Iteration 284, loss = 2420016690.92462921\n",
      "Iteration 285, loss = 2419761160.44148159\n",
      "Iteration 286, loss = 2419496946.18973398\n",
      "Iteration 287, loss = 2419242722.31069517\n",
      "Iteration 288, loss = 2418989004.48745728\n",
      "Iteration 289, loss = 2418730785.86409092\n",
      "Iteration 290, loss = 2418485562.17416286\n",
      "Iteration 291, loss = 2418225935.11919498\n",
      "Iteration 292, loss = 2417977595.97686911\n",
      "Iteration 293, loss = 2417727954.71297169\n",
      "Iteration 294, loss = 2417476757.22065353\n",
      "Iteration 295, loss = 2417222064.82339048\n",
      "Iteration 296, loss = 2416970744.58224440\n",
      "Iteration 297, loss = 2416723335.23134565\n",
      "Iteration 298, loss = 2416459576.56184006\n",
      "Iteration 299, loss = 2416204855.69029999\n",
      "Iteration 300, loss = 2415958642.00405884\n",
      "Iteration 301, loss = 2415706775.34619188\n",
      "Iteration 302, loss = 2415456391.96262121\n",
      "Iteration 303, loss = 2415213211.95211506\n",
      "Iteration 304, loss = 2414967312.16506290\n",
      "Iteration 305, loss = 2414720846.63673830\n",
      "Iteration 306, loss = 2414477555.28128052\n",
      "Iteration 307, loss = 2414235565.45980930\n",
      "Iteration 308, loss = 2413987628.40969896\n",
      "Iteration 309, loss = 2413747350.22357655\n",
      "Iteration 310, loss = 2413496166.57715321\n",
      "Iteration 311, loss = 2413260165.29261398\n",
      "Iteration 312, loss = 2413007134.95197010\n",
      "Iteration 313, loss = 2412758211.00275660\n",
      "Iteration 314, loss = 2412520446.23978376\n",
      "Iteration 315, loss = 2412279989.54422951\n",
      "Iteration 316, loss = 2412033097.63345003\n",
      "Iteration 317, loss = 2411801596.86992311\n",
      "Iteration 318, loss = 2411555979.53519821\n",
      "Iteration 319, loss = 2411316011.82005930\n",
      "Iteration 320, loss = 2411075724.15276575\n",
      "Iteration 321, loss = 2410834519.36734533\n",
      "Iteration 322, loss = 2410598965.99403524\n",
      "Iteration 323, loss = 2410358327.16773415\n",
      "Iteration 324, loss = 2410118477.14118242\n",
      "Iteration 325, loss = 2409878639.85609102\n",
      "Iteration 326, loss = 2409641463.73229313\n",
      "Iteration 327, loss = 2409408254.30009127\n",
      "Iteration 328, loss = 2409169300.84848070\n",
      "Iteration 329, loss = 2408929663.18027258\n",
      "Iteration 330, loss = 2408692667.54508400\n",
      "Iteration 331, loss = 2408458933.03730154\n",
      "Iteration 332, loss = 2408215346.36743116\n",
      "Iteration 333, loss = 2407985333.39485931\n",
      "Iteration 334, loss = 2407747878.11991262\n",
      "Iteration 335, loss = 2407517384.74234390\n",
      "Iteration 336, loss = 2407278266.72383118\n",
      "Iteration 337, loss = 2407046709.91811943\n",
      "Iteration 338, loss = 2406814900.37519693\n",
      "Iteration 339, loss = 2406578746.76904440\n",
      "Iteration 340, loss = 2406353244.43383789\n",
      "Iteration 341, loss = 2406114055.65587330\n",
      "Iteration 342, loss = 2405882924.45765734\n",
      "Iteration 343, loss = 2405654293.96089888\n",
      "Iteration 344, loss = 2405424842.56644249\n",
      "Iteration 345, loss = 2405189875.25307751\n",
      "Iteration 346, loss = 2404956378.31634808\n",
      "Iteration 347, loss = 2404726061.31826210\n",
      "Iteration 348, loss = 2404493239.69535494\n",
      "Iteration 349, loss = 2404253885.82320404\n",
      "Iteration 350, loss = 2404038880.22623682\n",
      "Iteration 351, loss = 2403805277.37892866\n",
      "Iteration 352, loss = 2403584101.89743900\n",
      "Iteration 353, loss = 2403357695.90404558\n",
      "Iteration 354, loss = 2794911565.31108189\n",
      "Iteration 355, loss = 2402847631.43706799\n",
      "Iteration 356, loss = 2402620556.25743675\n",
      "Iteration 357, loss = 2402392042.69763279\n",
      "Iteration 358, loss = 2402172204.98725414\n",
      "Iteration 359, loss = 2401948306.07637835\n",
      "Iteration 360, loss = 2401727902.74028969\n",
      "Iteration 361, loss = 2401509399.24342680\n",
      "Iteration 362, loss = 2401292871.52894545\n",
      "Iteration 363, loss = 2401062794.79435778\n",
      "Iteration 364, loss = 2400850839.58529902\n",
      "Iteration 365, loss = 2400627364.37717581\n",
      "Iteration 366, loss = 2400410952.88988590\n",
      "Iteration 367, loss = 2400188706.09144163\n",
      "Iteration 368, loss = 2399970203.26115179\n",
      "Iteration 369, loss = 2399751291.69934845\n",
      "Iteration 370, loss = 2399537979.96307468\n",
      "Iteration 371, loss = 2399309770.77696705\n",
      "Iteration 372, loss = 2399091471.96615076\n",
      "Iteration 373, loss = 2398872548.24110079\n",
      "Iteration 374, loss = 2398662387.31407309\n",
      "Iteration 375, loss = 2398447765.62058115\n",
      "Iteration 376, loss = 2398230199.02118778\n",
      "Iteration 377, loss = 2398020026.69197845\n",
      "Iteration 378, loss = 2397806635.96053410\n",
      "Iteration 379, loss = 2397587739.99062538\n",
      "Iteration 380, loss = 2397374947.54837942\n",
      "Iteration 381, loss = 2397159321.62710381\n",
      "Iteration 382, loss = 2396946759.00285196\n",
      "Iteration 383, loss = 2396735821.88223362\n",
      "Iteration 384, loss = 2396518140.04905844\n",
      "Iteration 385, loss = 2396310143.97225094\n",
      "Iteration 386, loss = 2396101519.56755257\n",
      "Iteration 387, loss = 2395889986.95110559\n",
      "Iteration 388, loss = 2395684553.97399282\n",
      "Iteration 389, loss = 2395472905.28199434\n",
      "Iteration 390, loss = 2395264276.46634388\n",
      "Iteration 391, loss = 2395052283.90599203\n",
      "Iteration 392, loss = 2394845032.07572365\n",
      "Iteration 393, loss = 2394634230.13547897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 394, loss = 2394425753.28354549\n",
      "Iteration 395, loss = 2394212897.04740667\n",
      "Iteration 396, loss = 2394007877.39681292\n",
      "Iteration 397, loss = 2393802660.59064245\n",
      "Iteration 398, loss = 2393590654.31710339\n",
      "Iteration 399, loss = 2393392117.18704462\n",
      "Iteration 400, loss = 2393190320.51495790\n",
      "Iteration 401, loss = 2392981447.99016666\n",
      "Iteration 402, loss = 2392772643.52799129\n",
      "Iteration 403, loss = 2392572468.17439747\n",
      "Iteration 404, loss = 2392364669.16433334\n",
      "Iteration 405, loss = 2392158157.84931660\n",
      "Iteration 406, loss = 2391959056.51485872\n",
      "Iteration 407, loss = 2391750573.29265499\n",
      "Iteration 408, loss = 2391551351.01231766\n",
      "Iteration 409, loss = 2391342863.87258101\n",
      "Iteration 410, loss = 2391152849.65472126\n",
      "Iteration 411, loss = 2390951332.21271896\n",
      "Iteration 412, loss = 2390750285.37234306\n",
      "Iteration 413, loss = 2390548043.49475193\n",
      "Iteration 414, loss = 2390357902.02486515\n",
      "Iteration 415, loss = 2390161852.20720530\n",
      "Iteration 416, loss = 2389961745.44466114\n",
      "Iteration 417, loss = 2389757289.07755947\n",
      "Iteration 418, loss = 2389563491.61752176\n",
      "Iteration 419, loss = 2389367702.03179598\n",
      "Iteration 420, loss = 2389166110.73274088\n",
      "Iteration 421, loss = 2388970753.99492788\n",
      "Iteration 422, loss = 2388775330.56785870\n",
      "Iteration 423, loss = 2388579723.48970175\n",
      "Iteration 424, loss = 2388386723.64261389\n",
      "Iteration 425, loss = 2388189670.05746841\n",
      "Iteration 426, loss = 2387996519.25691652\n",
      "Iteration 427, loss = 2387800337.73533964\n",
      "Iteration 428, loss = 2387611917.14450073\n",
      "Iteration 429, loss = 2387415357.40428638\n",
      "Iteration 430, loss = 2387219330.95552444\n",
      "Iteration 431, loss = 2387029883.33251238\n",
      "Iteration 432, loss = 2386831630.75972939\n",
      "Iteration 433, loss = 2386652962.32481432\n",
      "Iteration 434, loss = 2386450703.16377211\n",
      "Iteration 435, loss = 2386260257.18794060\n",
      "Iteration 436, loss = 2386076853.21180296\n",
      "Iteration 437, loss = 2385882316.72607613\n",
      "Iteration 438, loss = 2385694865.46760368\n",
      "Iteration 439, loss = 2385506399.00877666\n",
      "Iteration 440, loss = 2385306942.79851484\n",
      "Iteration 441, loss = 2385116138.03800344\n",
      "Iteration 442, loss = 2384928121.51159430\n",
      "Iteration 443, loss = 2384742029.47008896\n",
      "Iteration 444, loss = 2384549228.80061913\n",
      "Iteration 445, loss = 2384362249.32722950\n",
      "Iteration 446, loss = 2384180696.10301113\n",
      "Iteration 447, loss = 2383988307.50491476\n",
      "Iteration 448, loss = 2383812438.47819376\n",
      "Iteration 449, loss = 2383621555.75317287\n",
      "Iteration 450, loss = 2383430467.12415314\n",
      "Iteration 451, loss = 2383255889.90221071\n",
      "Iteration 452, loss = 2383061130.63994455\n",
      "Iteration 453, loss = 2382882997.31524086\n",
      "Iteration 454, loss = 2382693942.07931423\n",
      "Iteration 455, loss = 2382506883.92463875\n",
      "Iteration 456, loss = 2382323935.55799866\n",
      "Iteration 457, loss = 2382141340.79023218\n",
      "Iteration 458, loss = 2381956922.19474554\n",
      "Iteration 459, loss = 2381775159.17387438\n",
      "Iteration 460, loss = 2381603480.25001144\n",
      "Iteration 461, loss = 2381418387.32842875\n",
      "Iteration 462, loss = 2381244199.32375145\n",
      "Iteration 463, loss = 2381055900.13990211\n",
      "Iteration 464, loss = 2380877041.92958403\n",
      "Iteration 465, loss = 2380692045.50893879\n",
      "Iteration 466, loss = 2380518486.89491034\n",
      "Iteration 467, loss = 2380329400.31378317\n",
      "Iteration 468, loss = 2380155274.62538815\n",
      "Iteration 469, loss = 2379979106.21865225\n",
      "Iteration 470, loss = 2379797488.67426157\n",
      "Iteration 471, loss = 2379620694.82130861\n",
      "Iteration 472, loss = 2379445696.96208096\n",
      "Iteration 473, loss = 2379271143.47535849\n",
      "Iteration 474, loss = 2379098580.56767225\n",
      "Iteration 475, loss = 2378924239.03147554\n",
      "Iteration 476, loss = 2378756280.43546152\n",
      "Iteration 477, loss = 2378581762.90486383\n",
      "Iteration 478, loss = 2378417343.36190176\n",
      "Iteration 479, loss = 2378238448.37530375\n",
      "Iteration 480, loss = 2378069063.49371862\n",
      "Iteration 481, loss = 2377890233.87595797\n",
      "Iteration 482, loss = 2377719772.14140558\n",
      "Iteration 483, loss = 2377545059.49984884\n",
      "Iteration 484, loss = 2377377371.52821684\n",
      "Iteration 485, loss = 2377203400.06881666\n",
      "Iteration 486, loss = 2377034481.48016310\n",
      "Iteration 487, loss = 2376864464.77538347\n",
      "Iteration 488, loss = 2376686375.34983587\n",
      "Iteration 489, loss = 2376525236.29127026\n",
      "Iteration 490, loss = 2376345041.86157179\n",
      "Iteration 491, loss = 2376182975.85032749\n",
      "Iteration 492, loss = 2376013854.57652760\n",
      "Iteration 493, loss = 2375848774.97536039\n",
      "Iteration 494, loss = 2375682202.60018826\n",
      "Iteration 495, loss = 2375518343.00292015\n",
      "Iteration 496, loss = 2375345627.48579836\n",
      "Iteration 497, loss = 2375172983.92019510\n",
      "Iteration 498, loss = 2375003564.94956684\n",
      "Iteration 499, loss = 2374843666.33837175\n",
      "Iteration 500, loss = 2374679432.42272377\n",
      "Iteration 501, loss = 2374523863.06822920\n",
      "Iteration 502, loss = 2374357241.80609560\n",
      "Iteration 503, loss = 2374197464.68349504\n",
      "Iteration 504, loss = 2374033057.21647263\n",
      "Iteration 505, loss = 2373874181.23725986\n",
      "Iteration 506, loss = 2373711786.14796495\n",
      "Iteration 507, loss = 2373554499.23371935\n",
      "Iteration 508, loss = 2373393582.88477039\n",
      "Iteration 509, loss = 2373231941.01477242\n",
      "Iteration 510, loss = 2373067869.06450319\n",
      "Iteration 511, loss = 2372906643.68322754\n",
      "Iteration 512, loss = 2372739849.51212311\n",
      "Iteration 513, loss = 2372584664.94223070\n",
      "Iteration 514, loss = 2372427053.30105877\n",
      "Iteration 515, loss = 2372268402.25710678\n",
      "Iteration 516, loss = 2372112254.35298300\n",
      "Iteration 517, loss = 2371945313.30777359\n",
      "Iteration 518, loss = 2371798447.71060467\n",
      "Iteration 519, loss = 2371645005.92957258\n",
      "Iteration 520, loss = 2371491819.80267715\n",
      "Iteration 521, loss = 2371338474.25142574\n",
      "Iteration 522, loss = 2371181643.03432465\n",
      "Iteration 523, loss = 2371035633.19649982\n",
      "Iteration 524, loss = 2370879036.15072584\n",
      "Iteration 525, loss = 2370724054.75729227\n",
      "Iteration 526, loss = 2370567725.21595240\n",
      "Iteration 527, loss = 2370412284.83425760\n",
      "Iteration 528, loss = 2370261405.73396587\n",
      "Iteration 529, loss = 2370107138.16640186\n",
      "Iteration 530, loss = 14107190647.10404205\n",
      "Iteration 531, loss = 2369741274.48109436\n",
      "Iteration 532, loss = 2369590621.20955753\n",
      "Iteration 533, loss = 2369447691.52283144\n",
      "Iteration 534, loss = 2369315414.71307611\n",
      "Iteration 535, loss = 2369173885.60135317\n",
      "Iteration 536, loss = 2369032335.46712399\n",
      "Iteration 537, loss = 2368894614.93266678\n",
      "Iteration 538, loss = 2368753122.64436674\n",
      "Iteration 539, loss = 2368613815.63030386\n",
      "Iteration 540, loss = 2368476236.35679388\n",
      "Iteration 541, loss = 2368332854.14505434\n",
      "Iteration 542, loss = 2368198298.87451792\n",
      "Iteration 543, loss = 2368061076.45827532\n",
      "Iteration 544, loss = 2367924380.01944351\n",
      "Iteration 545, loss = 2367784343.03391171\n",
      "Iteration 546, loss = 2367652717.22314548\n",
      "Iteration 547, loss = 2367510449.57742691\n",
      "Iteration 548, loss = 2367373218.50138330\n",
      "Iteration 549, loss = 2367235992.12712669\n",
      "Iteration 550, loss = 2367095931.47548485\n",
      "Iteration 551, loss = 2366956439.93273640\n",
      "Iteration 552, loss = 2366830459.19672537\n",
      "Iteration 553, loss = 2366686761.09753895\n",
      "Iteration 554, loss = 2366553136.25403357\n",
      "Iteration 555, loss = 2366419184.63734913\n",
      "Iteration 556, loss = 2366288199.47684813\n",
      "Iteration 557, loss = 2366148055.27231932\n",
      "Iteration 558, loss = 2366017106.72486401\n",
      "Iteration 559, loss = 2365884481.57747984\n",
      "Iteration 560, loss = 2365753166.05286407\n",
      "Iteration 561, loss = 2365611646.87241268\n",
      "Iteration 562, loss = 2365477546.27774572\n",
      "Iteration 563, loss = 2365347403.15345097\n",
      "Iteration 564, loss = 2365214768.58497047\n",
      "Iteration 565, loss = 2365078949.17890644\n",
      "Iteration 566, loss = 2364947550.25736094\n",
      "Iteration 567, loss = 2364811476.91629314\n",
      "Iteration 568, loss = 2364682446.59740210\n",
      "Iteration 569, loss = 2364551144.20910835\n",
      "Iteration 570, loss = 2364423031.60583258\n",
      "Iteration 571, loss = 2364290343.41839123\n",
      "Iteration 572, loss = 2364161477.01896763\n",
      "Iteration 573, loss = 2364036597.40853834\n",
      "Iteration 574, loss = 2363895800.14793396\n",
      "Iteration 575, loss = 2363769288.75154114\n",
      "Iteration 576, loss = 2363640445.00385046\n",
      "Iteration 577, loss = 2363499898.04092550\n",
      "Iteration 578, loss = 2363376074.25572491\n",
      "Iteration 579, loss = 2363241514.78468037\n",
      "Iteration 580, loss = 2363115608.75630665\n",
      "Iteration 581, loss = 2362985879.20754528\n",
      "Iteration 582, loss = 2362864225.34151506\n",
      "Iteration 583, loss = 2362731397.12312126\n",
      "Iteration 584, loss = 2362608302.29228354\n",
      "Iteration 585, loss = 2362475838.18967962\n",
      "Iteration 586, loss = 2362354203.14647627\n",
      "Iteration 587, loss = 2362225264.97129154\n",
      "Iteration 588, loss = 2362098228.28828192\n",
      "Iteration 589, loss = 2361971569.87536430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 590, loss = 2361839993.22214842\n",
      "Iteration 591, loss = 2361715553.45690680\n",
      "Iteration 592, loss = 2361589638.31423903\n",
      "Iteration 593, loss = 2361466111.70687199\n",
      "Iteration 594, loss = 2361328332.28052187\n",
      "Iteration 595, loss = 2361199913.13658619\n",
      "Iteration 596, loss = 2361076708.33229446\n",
      "Iteration 597, loss = 2360945744.15885687\n",
      "Iteration 598, loss = 2360825479.10507298\n",
      "Iteration 599, loss = 2360698339.05166674\n",
      "Iteration 600, loss = 2360577536.29984188\n",
      "Iteration 601, loss = 2360449949.20761204\n",
      "Iteration 602, loss = 2360321752.83780956\n",
      "Iteration 603, loss = 2360206370.98674202\n",
      "Iteration 604, loss = 2360082668.60497618\n",
      "Iteration 605, loss = 2359961393.77771235\n",
      "Iteration 606, loss = 2359840241.55054045\n",
      "Iteration 607, loss = 2359710392.95277166\n",
      "Iteration 608, loss = 2359589516.76774359\n",
      "Iteration 609, loss = 2359463856.01667690\n",
      "Iteration 610, loss = 2359341544.52699947\n",
      "Iteration 611, loss = 2359226013.52069759\n",
      "Iteration 612, loss = 2359101687.72726059\n",
      "Iteration 613, loss = 2358990825.49022484\n",
      "Iteration 614, loss = 2358870655.95241117\n",
      "Iteration 615, loss = 2358754186.35302401\n",
      "Iteration 616, loss = 2358632154.33260393\n",
      "Iteration 617, loss = 2358514786.08010864\n",
      "Iteration 618, loss = 2358403211.64855051\n",
      "Iteration 619, loss = 2358273547.89458179\n",
      "Iteration 620, loss = 2358158725.35019779\n",
      "Iteration 621, loss = 2358037324.25683451\n",
      "Iteration 622, loss = 2357926864.28228283\n",
      "Iteration 623, loss = 2357808775.49248886\n",
      "Iteration 624, loss = 2357698303.38825178\n",
      "Iteration 625, loss = 2357581018.73243475\n",
      "Iteration 626, loss = 2357463600.16440535\n",
      "Iteration 627, loss = 2357353616.84043884\n",
      "Iteration 628, loss = 2357238542.32087851\n",
      "Iteration 629, loss = 2357131398.35800457\n",
      "Iteration 630, loss = 2357017186.94214201\n",
      "Iteration 631, loss = 2356901261.79529667\n",
      "Iteration 632, loss = 2356793109.58680344\n",
      "Iteration 633, loss = 2356677592.07665777\n",
      "Iteration 634, loss = 2356567454.93907166\n",
      "Iteration 635, loss = 2356455342.76303577\n",
      "Iteration 636, loss = 2356347832.66525698\n",
      "Iteration 637, loss = 2356235456.80646563\n",
      "Iteration 638, loss = 2356130781.61831093\n",
      "Iteration 639, loss = 2356018707.19664526\n",
      "Iteration 640, loss = 2355912090.42927837\n",
      "Iteration 641, loss = 2355795855.56526899\n",
      "Iteration 642, loss = 2355687719.34700346\n",
      "Iteration 643, loss = 2355580946.37425137\n",
      "Iteration 644, loss = 2355474510.06842709\n",
      "Iteration 645, loss = 2355367891.68918705\n",
      "Iteration 646, loss = 2355253563.58866262\n",
      "Iteration 647, loss = 2355152856.51619101\n",
      "Iteration 648, loss = 2355048862.21023560\n",
      "Iteration 649, loss = 2354941803.34118414\n",
      "Iteration 650, loss = 2354835444.95174932\n",
      "Iteration 651, loss = 2354732829.74249506\n",
      "Iteration 652, loss = 2354625954.09799051\n",
      "Iteration 653, loss = 2354523871.82061386\n",
      "Iteration 654, loss = 2354412997.88270617\n",
      "Iteration 655, loss = 2354307941.46059036\n",
      "Iteration 656, loss = 2354207394.88630486\n",
      "Iteration 657, loss = 2354102199.85828161\n",
      "Iteration 658, loss = 2354000558.56105375\n",
      "Iteration 659, loss = 2353894864.06997252\n",
      "Iteration 660, loss = 2353792764.95439911\n",
      "Iteration 661, loss = 2353685659.08654451\n",
      "Iteration 662, loss = 2353587466.45009708\n",
      "Iteration 663, loss = 2353484958.25996208\n",
      "Iteration 664, loss = 2353379163.23196125\n",
      "Iteration 665, loss = 2353278678.76606464\n",
      "Iteration 666, loss = 2353179406.23441696\n",
      "Iteration 667, loss = 2353083835.47877932\n",
      "Iteration 668, loss = 2352979655.67007732\n",
      "Iteration 669, loss = 2352878799.23244143\n",
      "Iteration 670, loss = 2352778500.07911491\n",
      "Iteration 671, loss = 2352682291.92234182\n",
      "Iteration 672, loss = 2352579395.21880865\n",
      "Iteration 673, loss = 2352483965.76162338\n",
      "Iteration 674, loss = 2352387411.08922482\n",
      "Iteration 675, loss = 2352287717.12278652\n",
      "Iteration 676, loss = 2352189913.64468193\n",
      "Iteration 677, loss = 2352088945.79160070\n",
      "Iteration 678, loss = 2351986889.33376026\n",
      "Iteration 679, loss = 2351883822.99118710\n",
      "Iteration 680, loss = 2351788131.45816088\n",
      "Iteration 681, loss = 2351692016.64811468\n",
      "Iteration 682, loss = 2351592679.06037617\n",
      "Iteration 683, loss = 2351496694.58842564\n",
      "Iteration 684, loss = 2351405371.53177118\n",
      "Iteration 685, loss = 2351315002.63562155\n",
      "Iteration 686, loss = 2351220417.21674299\n",
      "Iteration 687, loss = 2351129142.10649633\n",
      "Iteration 688, loss = 2351033167.89895725\n",
      "Iteration 689, loss = 2350939734.00748158\n",
      "Iteration 690, loss = 2350850910.97545576\n",
      "Iteration 691, loss = 2350756012.75283098\n",
      "Iteration 692, loss = 2350670024.93026686\n",
      "Iteration 693, loss = 2350575417.58226252\n",
      "Iteration 694, loss = 2350485076.35870028\n",
      "Iteration 695, loss = 2350398066.63475180\n",
      "Iteration 696, loss = 2350306268.12480164\n",
      "Iteration 697, loss = 2350216177.30937862\n",
      "Iteration 698, loss = 2350122370.97666454\n",
      "Iteration 699, loss = 2350033017.73138714\n",
      "Iteration 700, loss = 2349939672.02462721\n",
      "Iteration 701, loss = 2349849964.11647081\n",
      "Iteration 702, loss = 2349758802.03457642\n",
      "Iteration 703, loss = 2349676759.07151842\n",
      "Iteration 704, loss = 2349585219.11486864\n",
      "Iteration 705, loss = 2349498753.13703156\n",
      "Iteration 706, loss = 2349406730.02920532\n",
      "Iteration 707, loss = 2349323995.43900967\n",
      "Iteration 708, loss = 2349236293.57256794\n",
      "Iteration 709, loss = 2349146986.58038950\n",
      "Iteration 710, loss = 2349066335.02334738\n",
      "Iteration 711, loss = 2348981559.15343523\n",
      "Iteration 712, loss = 2348894729.25773478\n",
      "Iteration 713, loss = 2348805292.60422516\n",
      "Iteration 714, loss = 2348725790.98873186\n",
      "Iteration 715, loss = 2348639177.43742561\n",
      "Iteration 716, loss = 2348556022.25276709\n",
      "Iteration 717, loss = 2348469208.79923153\n",
      "Iteration 718, loss = 2348389129.15197515\n",
      "Iteration 719, loss = 2348299992.00825977\n",
      "Iteration 720, loss = 2348216325.01718712\n",
      "Iteration 721, loss = 2348131657.70519638\n",
      "Iteration 722, loss = 2348050468.18123960\n",
      "Iteration 723, loss = 2347964077.23066807\n",
      "Iteration 724, loss = 2347881318.29528570\n",
      "Iteration 725, loss = 2347799409.33509350\n",
      "Iteration 726, loss = 2347724301.94811440\n",
      "Iteration 727, loss = 2347642704.74244118\n",
      "Iteration 728, loss = 2347557489.55454206\n",
      "Iteration 729, loss = 2347482964.47671127\n",
      "Iteration 730, loss = 2347401299.92045212\n",
      "Iteration 731, loss = 2347320607.25059986\n",
      "Iteration 732, loss = 2347240522.01603031\n",
      "Iteration 733, loss = 2347158127.27162695\n",
      "Iteration 734, loss = 2347080686.98442316\n",
      "Iteration 735, loss = 2347000647.51123953\n",
      "Iteration 736, loss = 2346926553.69322681\n",
      "Iteration 737, loss = 2346844579.92252684\n",
      "Iteration 738, loss = 2346769371.07540035\n",
      "Iteration 739, loss = 2346688655.19431829\n",
      "Iteration 740, loss = 2346609475.90968752\n",
      "Iteration 741, loss = 2346535926.83368874\n",
      "Iteration 742, loss = 2346449408.96117115\n",
      "Iteration 743, loss = 2346376638.39776659\n",
      "Iteration 744, loss = 2346299642.75385380\n",
      "Iteration 745, loss = 2346226451.43434620\n",
      "Iteration 746, loss = 2346150150.94061136\n",
      "Iteration 747, loss = 2346071643.80006742\n",
      "Iteration 748, loss = 2346001123.76599598\n",
      "Iteration 749, loss = 2345924962.56104660\n",
      "Iteration 750, loss = 2345851570.96778584\n",
      "Iteration 751, loss = 2345782146.35620546\n",
      "Iteration 752, loss = 2345703253.98762178\n",
      "Iteration 753, loss = 2345629248.12195730\n",
      "Iteration 754, loss = 2345556145.10953951\n",
      "Iteration 755, loss = 2345484559.82955694\n",
      "Iteration 756, loss = 2345407673.71632957\n",
      "Iteration 757, loss = 2345340630.93536139\n",
      "Iteration 758, loss = 2345268428.06583691\n",
      "Iteration 759, loss = 2345190801.04634285\n",
      "Iteration 760, loss = 2345123004.97446585\n",
      "Iteration 761, loss = 2345049643.33579493\n",
      "Iteration 762, loss = 2344984185.95754290\n",
      "Iteration 763, loss = 2344915615.17964315\n",
      "Iteration 764, loss = 2344836980.48481846\n",
      "Iteration 765, loss = 2344768972.25649977\n",
      "Iteration 766, loss = 2344698418.56221104\n",
      "Iteration 767, loss = 2344630297.59158754\n",
      "Iteration 768, loss = 2344560692.44489431\n",
      "Iteration 769, loss = 2344490487.32935476\n",
      "Iteration 770, loss = 2344421564.19803953\n",
      "Iteration 771, loss = 2344353797.02024937\n",
      "Iteration 772, loss = 2344282861.45400858\n",
      "Iteration 773, loss = 2344210649.17410994\n",
      "Iteration 774, loss = 2344144213.03577948\n",
      "Iteration 775, loss = 2344075274.65099478\n",
      "Iteration 776, loss = 2344008564.93280935\n",
      "Iteration 777, loss = 2343935436.46235895\n",
      "Iteration 778, loss = 2343866453.74353123\n",
      "Iteration 779, loss = 2343790520.44095135\n",
      "Iteration 780, loss = 2343732726.20580864\n",
      "Iteration 781, loss = 2343663832.07568550\n",
      "Iteration 782, loss = 2343598250.82350683\n",
      "Iteration 783, loss = 2343536432.51823521\n",
      "Iteration 784, loss = 2343474299.12994242\n",
      "Iteration 785, loss = 2343406270.34790850\n",
      "Iteration 786, loss = 2343350015.38479424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 787, loss = 2343285867.58434153\n",
      "Iteration 788, loss = 2343224733.58830261\n",
      "Iteration 789, loss = 2343165276.02403307\n",
      "Iteration 790, loss = 2752761190.78140879\n",
      "Iteration 791, loss = 2343039349.69968081\n",
      "Iteration 792, loss = 2342980666.46601152\n",
      "Iteration 793, loss = 2342917883.92935514\n",
      "Iteration 794, loss = 2342859241.99403143\n",
      "Iteration 795, loss = 2342802945.15462208\n",
      "Iteration 796, loss = 2342739832.45064735\n",
      "Iteration 797, loss = 2342683980.94919968\n",
      "Iteration 798, loss = 2342618480.73658466\n",
      "Iteration 799, loss = 2342563743.73680067\n",
      "Iteration 800, loss = 2342503842.84371519\n",
      "Iteration 801, loss = 2342445112.39001560\n",
      "Iteration 802, loss = 2342383379.87918711\n",
      "Iteration 803, loss = 2342326343.76013517\n",
      "Iteration 804, loss = 2342266829.75582027\n",
      "Iteration 805, loss = 2342208465.07583904\n",
      "Iteration 806, loss = 2342152371.56296587\n",
      "Iteration 807, loss = 2342095055.13643551\n",
      "Iteration 808, loss = 2342037056.01262617\n",
      "Iteration 809, loss = 2341986327.46091080\n",
      "Iteration 810, loss = 2341927544.37140083\n",
      "Iteration 811, loss = 2341863217.97605610\n",
      "Iteration 812, loss = 2343266762.33867073\n",
      "Iteration 813, loss = 2341755281.83154774\n",
      "Iteration 814, loss = 2341700337.63698149\n",
      "Iteration 815, loss = 2341647068.71710348\n",
      "Iteration 816, loss = 2341586973.47645807\n",
      "Iteration 817, loss = 2341531867.41190577\n",
      "Iteration 818, loss = 2341484503.72594452\n",
      "Iteration 819, loss = 2341430101.05560112\n",
      "Iteration 820, loss = 2341381589.73066711\n",
      "Iteration 821, loss = 2341329980.96169853\n",
      "Iteration 822, loss = 2341277841.70385838\n",
      "Iteration 823, loss = 2341481138.73379135\n",
      "Iteration 824, loss = 2341172415.61591864\n",
      "Iteration 825, loss = 2341124215.12491703\n",
      "Iteration 826, loss = 2341073182.80473709\n",
      "Iteration 827, loss = 2341025315.99870634\n",
      "Iteration 828, loss = 36539332096.40404510\n",
      "Iteration 829, loss = 2340853963.71760941\n",
      "Iteration 830, loss = 2340834184.37726068\n",
      "Iteration 831, loss = 2340820235.42558193\n",
      "Iteration 832, loss = 2340807850.20171738\n",
      "Iteration 833, loss = 2340793591.99945545\n",
      "Iteration 834, loss = 2340780405.51033020\n",
      "Iteration 835, loss = 2340767355.95357323\n",
      "Iteration 836, loss = 2340754425.84802055\n",
      "Iteration 837, loss = 2340739503.93055296\n",
      "Iteration 838, loss = 2340725997.30333996\n",
      "Iteration 839, loss = 2340712457.82659435\n",
      "Iteration 840, loss = 2340697979.46532440\n",
      "Iteration 841, loss = 2340683447.16435528\n",
      "Iteration 842, loss = 2340671611.71152401\n",
      "Iteration 843, loss = 2340656122.52084923\n",
      "Iteration 844, loss = 2340641413.67917061\n",
      "Iteration 845, loss = 2340628540.46109247\n",
      "Iteration 846, loss = 2340614640.41860771\n",
      "Iteration 847, loss = 2340599108.40598583\n",
      "Iteration 848, loss = 3747471940.80463934\n",
      "Iteration 849, loss = 2340578257.07361698\n",
      "Iteration 850, loss = 2340561498.22691059\n",
      "Iteration 851, loss = 2340545621.23756218\n",
      "Iteration 852, loss = 2340531653.03657007\n",
      "Iteration 853, loss = 2340514371.64482832\n",
      "Iteration 854, loss = 2340500783.59944630\n",
      "Iteration 855, loss = 2340482467.42052412\n",
      "Iteration 856, loss = 2340466012.03203344\n",
      "Iteration 857, loss = 2340450621.95298147\n",
      "Iteration 858, loss = 2340650299.27112579\n",
      "Iteration 859, loss = 2340419150.23101139\n",
      "Iteration 860, loss = 2340403553.19962645\n",
      "Iteration 861, loss = 2340386279.65301800\n",
      "Iteration 862, loss = 2340371261.19303322\n",
      "Iteration 863, loss = 2344754106.43206453\n",
      "Iteration 864, loss = 2340336288.94296885\n",
      "Iteration 865, loss = 2340320161.11674118\n",
      "Iteration 866, loss = 2340302130.97353411\n",
      "Iteration 867, loss = 2340284901.28946686\n",
      "Iteration 868, loss = 2340268463.47957134\n",
      "Iteration 869, loss = 2340284947.75400972\n",
      "Iteration 870, loss = 2340231971.26782703\n",
      "Iteration 871, loss = 2340215583.24655390\n",
      "Iteration 872, loss = 2340194373.14687252\n",
      "Iteration 873, loss = 2340176505.65326071\n",
      "Iteration 874, loss = 2340158354.65629864\n",
      "Iteration 875, loss = 2340138787.75493431\n",
      "Iteration 876, loss = 2340119334.44748640\n",
      "Iteration 877, loss = 2340101834.25921726\n",
      "Iteration 878, loss = 2340082530.12842369\n",
      "Iteration 879, loss = 2340065328.38371086\n",
      "Iteration 880, loss = 2340044058.21586514\n",
      "Iteration 881, loss = 2340026654.88765526\n",
      "Iteration 882, loss = 2340006023.88855267\n",
      "Iteration 883, loss = 2339988587.81638336\n",
      "Iteration 884, loss = 2339964446.66893387\n",
      "Iteration 885, loss = 2339945924.95524883\n",
      "Iteration 886, loss = 2339925403.79995155\n",
      "Iteration 887, loss = 2339906843.57652760\n",
      "Iteration 888, loss = 2339885686.62292147\n",
      "Iteration 889, loss = 2339866105.07554007\n",
      "Iteration 890, loss = 2339844546.91211700\n",
      "Iteration 891, loss = 2339823378.06523085\n",
      "Iteration 892, loss = 2339803059.04502964\n",
      "Iteration 893, loss = 2339782016.13523102\n",
      "Iteration 894, loss = 2339762597.56116676\n",
      "Iteration 895, loss = 2339740452.21416950\n",
      "Iteration 896, loss = 2339723178.54779196\n",
      "Iteration 897, loss = 2339697962.56198406\n",
      "Iteration 898, loss = 2339677287.11317778\n",
      "Iteration 899, loss = 2339655768.33004808\n",
      "Iteration 900, loss = 2339633355.57070923\n",
      "Iteration 901, loss = 2339610909.28591728\n",
      "Iteration 902, loss = 2339586916.78906536\n",
      "Iteration 903, loss = 2339564827.84499884\n",
      "Iteration 904, loss = 2339543368.18043613\n",
      "Iteration 905, loss = 2339520545.15994215\n",
      "Iteration 906, loss = 2339499335.05764151\n",
      "Iteration 907, loss = 2339475155.02029800\n",
      "Iteration 908, loss = 2339451400.20237589\n",
      "Iteration 909, loss = 2339430338.09109068\n",
      "Iteration 910, loss = 2339408102.04462624\n",
      "Iteration 911, loss = 2339386275.21737957\n",
      "Iteration 912, loss = 2339363755.79930401\n",
      "Iteration 913, loss = 2339339863.55379248\n",
      "Iteration 914, loss = 2339321672.66980696\n",
      "Iteration 915, loss = 2339294153.77350569\n",
      "Iteration 916, loss = 2339272964.93463993\n",
      "Iteration 917, loss = 2339249258.72861671\n",
      "Iteration 918, loss = 2339226142.97910500\n",
      "Iteration 919, loss = 2339203109.21344995\n",
      "Iteration 920, loss = 2339179150.18472528\n",
      "Iteration 921, loss = 2339155504.14887238\n",
      "Iteration 922, loss = 2339131138.16405344\n",
      "Iteration 923, loss = 2339108884.30927134\n",
      "Iteration 924, loss = 2339085612.88731718\n",
      "Iteration 925, loss = 2339059461.40727997\n",
      "Iteration 926, loss = 2339035953.80629730\n",
      "Iteration 927, loss = 2339012131.06324244\n",
      "Iteration 928, loss = 2338987146.92565727\n",
      "Iteration 929, loss = 2338961179.74956608\n",
      "Iteration 930, loss = 2338935592.65559673\n",
      "Iteration 931, loss = 2338910096.33036613\n",
      "Iteration 932, loss = 2338884723.56219482\n",
      "Iteration 933, loss = 2339196821.89087677\n",
      "Iteration 934, loss = 2339544868.98341751\n",
      "Iteration 935, loss = 2338813133.22805119\n",
      "Iteration 936, loss = 2338786776.32235527\n",
      "Iteration 937, loss = 2338764126.54208565\n",
      "Iteration 938, loss = 2338739642.15198183\n",
      "Iteration 939, loss = 2338715005.51586819\n",
      "Iteration 940, loss = 2338689720.64115810\n",
      "Iteration 941, loss = 2338665764.83063936\n",
      "Iteration 942, loss = 2338641271.74058342\n",
      "Iteration 943, loss = 2338613807.59813166\n",
      "Iteration 944, loss = 2338589813.55097103\n",
      "Iteration 945, loss = 2338563268.60298824\n",
      "Iteration 946, loss = 2338538230.79823732\n",
      "Iteration 947, loss = 2338512818.19412851\n",
      "Iteration 948, loss = 2338487946.08263540\n",
      "Iteration 949, loss = 2338460286.08764458\n",
      "Iteration 950, loss = 2338437668.50161648\n",
      "Iteration 951, loss = 2338408258.83149481\n",
      "Iteration 952, loss = 2338385728.06779575\n",
      "Iteration 953, loss = 2338358920.90726280\n",
      "Iteration 954, loss = 2338333109.67147732\n",
      "Iteration 955, loss = 2338304939.68175220\n",
      "Iteration 956, loss = 2338277847.89231062\n",
      "Iteration 957, loss = 2338250776.85827160\n",
      "Iteration 958, loss = 2338223770.52428246\n",
      "Iteration 959, loss = 2338199237.85799456\n",
      "Iteration 960, loss = 2338172396.71862221\n",
      "Iteration 961, loss = 2338147075.00688028\n",
      "Iteration 962, loss = 2338120615.02655363\n",
      "Iteration 963, loss = 2338094783.94950199\n",
      "Iteration 964, loss = 2338068288.13631821\n",
      "Iteration 965, loss = 2339396610.67908382\n",
      "Iteration 966, loss = 2679956942.23046875\n",
      "Iteration 967, loss = 2337969191.01405287\n",
      "Iteration 968, loss = 2337941466.54866266\n",
      "Iteration 969, loss = 2337914699.90922117\n",
      "Iteration 970, loss = 2337891938.85370398\n",
      "Iteration 971, loss = 2337861655.55203485\n",
      "Iteration 972, loss = 2337835134.50763702\n",
      "Iteration 973, loss = 2337810355.97001886\n",
      "Iteration 974, loss = 2337786949.65307951\n",
      "Iteration 975, loss = 2337758875.24642515\n",
      "Iteration 976, loss = 2337731813.48948717\n",
      "Iteration 977, loss = 2337708261.47896576\n",
      "Iteration 978, loss = 2337684528.89624691\n",
      "Iteration 979, loss = 2337653763.49436045\n",
      "Iteration 980, loss = 2337627050.61128426\n",
      "Iteration 981, loss = 2337599771.31595850\n",
      "Iteration 982, loss = 2429569199.60443020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 983, loss = 2337547548.58810520\n",
      "Iteration 984, loss = 2337522554.08314323\n",
      "Iteration 985, loss = 2337499166.67186213\n",
      "Iteration 986, loss = 2337472899.62121916\n",
      "Iteration 987, loss = 2337447575.76877165\n",
      "Iteration 988, loss = 2337422196.41962576\n",
      "Iteration 989, loss = 2337396860.99498463\n",
      "Iteration 990, loss = 2337373769.04878950\n",
      "Iteration 991, loss = 2337349623.68733788\n",
      "Iteration 992, loss = 2337323159.15534019\n",
      "Iteration 993, loss = 2337297495.43054962\n",
      "Iteration 994, loss = 2358459782.12556744\n",
      "Iteration 995, loss = 2337246843.79113102\n",
      "Iteration 996, loss = 2337222982.41159773\n",
      "Iteration 997, loss = 2337195636.58689070\n",
      "Iteration 998, loss = 2337168981.83505106\n",
      "Iteration 999, loss = 2337145206.06468630\n",
      "Iteration 1000, loss = 2337118327.82799435\n",
      "Iteration 1001, loss = 2337095010.60960913\n",
      "Iteration 1002, loss = 2337071968.57528305\n",
      "Iteration 1003, loss = 2337046634.82960892\n",
      "Iteration 1004, loss = 2337024096.98660755\n",
      "Iteration 1005, loss = 2336998780.94068670\n",
      "Iteration 1006, loss = 2336976510.61035299\n",
      "Iteration 1007, loss = 2337053731.24267912\n",
      "Iteration 1008, loss = 2336925753.39783859\n",
      "Iteration 1009, loss = 2336901622.34028101\n",
      "Iteration 1010, loss = 2336878615.78952456\n",
      "Iteration 1011, loss = 2336857175.25657558\n",
      "Iteration 1012, loss = 2336883041.00895023\n",
      "Iteration 1013, loss = 2336808981.05189896\n",
      "Iteration 1014, loss = 2336785616.72852325\n",
      "Iteration 1015, loss = 2336759490.33592224\n",
      "Iteration 1016, loss = 2336736829.98302746\n",
      "Iteration 1017, loss = 2336712222.94931269\n",
      "Iteration 1018, loss = 2336685853.38269234\n",
      "Iteration 1019, loss = 2336660936.21142054\n",
      "Iteration 1020, loss = 2336632865.45339823\n",
      "Iteration 1021, loss = 2336611979.22370720\n",
      "Iteration 1022, loss = 2336585070.18125582\n",
      "Iteration 1023, loss = 2336565291.72175598\n",
      "Iteration 1024, loss = 2336539313.10211611\n",
      "Iteration 1025, loss = 2336519900.93166828\n",
      "Iteration 1026, loss = 2336496525.23261023\n",
      "Iteration 1027, loss = 2336471002.11396694\n",
      "Iteration 1028, loss = 2336448239.51758671\n",
      "Iteration 1029, loss = 2336425323.33182240\n",
      "Iteration 1030, loss = 2336402240.20868778\n",
      "Iteration 1031, loss = 2336380596.52693892\n",
      "Iteration 1032, loss = 2336360254.23107958\n",
      "Iteration 1033, loss = 2336337980.22554445\n",
      "Iteration 1034, loss = 2336318829.02443266\n",
      "Iteration 1035, loss = 2336293950.77848196\n",
      "Iteration 1036, loss = 2336276214.23928356\n",
      "Iteration 1037, loss = 2336251097.46756792\n",
      "Iteration 1038, loss = 2336231217.84563494\n",
      "Iteration 1039, loss = 2336207392.03948784\n",
      "Iteration 1040, loss = 2336186079.52206326\n",
      "Iteration 1041, loss = 2336170848.86967993\n",
      "Iteration 1042, loss = 2336142617.63316154\n",
      "Iteration 1043, loss = 2336125551.47216606\n",
      "Iteration 1044, loss = 2336099389.55525589\n",
      "Iteration 1045, loss = 2336080753.13848400\n",
      "Iteration 1046, loss = 2346110368.97163486\n",
      "Iteration 1047, loss = 2336037941.50094652\n",
      "Iteration 1048, loss = 2336019713.23902893\n",
      "Iteration 1049, loss = 2335997835.74733305\n",
      "Iteration 1050, loss = 2335977239.43622589\n",
      "Iteration 1051, loss = 2335955792.57544613\n",
      "Iteration 1052, loss = 2335936302.96459246\n",
      "Iteration 1053, loss = 2335912282.94995832\n",
      "Iteration 1054, loss = 2335894100.93559313\n",
      "Iteration 1055, loss = 2335874458.52866602\n",
      "Iteration 1056, loss = 2335856916.56473780\n",
      "Iteration 1057, loss = 2335833866.17238283\n",
      "Iteration 1058, loss = 2335814453.02670860\n",
      "Iteration 1059, loss = 2335794391.71740389\n",
      "Iteration 1060, loss = 2335775846.34997320\n",
      "Iteration 1061, loss = 2335753941.05402279\n",
      "Iteration 1062, loss = 2335733988.78964329\n",
      "Iteration 1063, loss = 2335714352.76202154\n",
      "Iteration 1064, loss = 2335698585.75281000\n",
      "Iteration 1065, loss = 2335675928.98603821\n",
      "Iteration 1066, loss = 2335657077.42621040\n",
      "Iteration 1067, loss = 2335637427.62477112\n",
      "Iteration 1068, loss = 2335617259.54707813\n",
      "Iteration 1069, loss = 2335599491.52807903\n",
      "Iteration 1070, loss = 2335578562.81438684\n",
      "Iteration 1071, loss = 2335560651.77972031\n",
      "Iteration 1072, loss = 2335540909.37017298\n",
      "Iteration 1073, loss = 34027952361.04177475\n",
      "Iteration 1074, loss = 2335579280.74229002\n",
      "Iteration 1075, loss = 2335580677.29156303\n",
      "Iteration 1076, loss = 2335576377.70973730\n",
      "Iteration 1077, loss = 2335571209.12333012\n",
      "Iteration 1078, loss = 2335566750.70564938\n",
      "Iteration 1079, loss = 2335561177.23761654\n",
      "Iteration 1080, loss = 2335556406.84272957\n",
      "Iteration 1081, loss = 2335551008.22345686\n",
      "Iteration 1082, loss = 2335545852.15349865\n",
      "Iteration 1083, loss = 2335541021.41402960\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Fitting 15 folds for each of 288 candidates, totalling 4320 fits\n",
      "Iteration 1, loss = 3868695884.20361042\n",
      "Iteration 2, loss = 2446110656.65819788\n",
      "Iteration 3, loss = 3425164764.23189402\n",
      "Iteration 4, loss = 2510926674.68666267\n",
      "Iteration 5, loss = 2510566917.26150274\n",
      "Iteration 6, loss = 2509279114.30227041\n",
      "Iteration 7, loss = 2354956153.32678795\n",
      "Iteration 8, loss = 2330223940.28140545\n",
      "Iteration 9, loss = 2524212525.95650864\n",
      "Iteration 10, loss = 2509613430.90245533\n",
      "Iteration 11, loss = 2509194984.55653381\n",
      "Iteration 12, loss = 2508865026.42516804\n",
      "Iteration 13, loss = 2508518266.99360561\n",
      "Iteration 14, loss = 2508178980.56788349\n",
      "Iteration 15, loss = 2507829448.18399525\n",
      "Iteration 16, loss = 2507484253.25425816\n",
      "Iteration 17, loss = 2507125785.40538836\n",
      "Iteration 18, loss = 2506772574.71114969\n",
      "Iteration 19, loss = 2506414867.35146189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_modelo__alpha</th>\n",
       "      <th>param_modelo__hidden_layer_sizes</th>\n",
       "      <th>param_modelo__learning_rate</th>\n",
       "      <th>param_modelo__learning_rate_init</th>\n",
       "      <th>param_modelo__solver</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>-65106.581212</td>\n",
       "      <td>21125.295547</td>\n",
       "      <td>-67996.679809</td>\n",
       "      <td>5672.079262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>constant</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>-65106.581212</td>\n",
       "      <td>21125.295547</td>\n",
       "      <td>-67996.679809</td>\n",
       "      <td>5672.079262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 20, 10, 20)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>-65238.750999</td>\n",
       "      <td>21493.755040</td>\n",
       "      <td>-68417.917729</td>\n",
       "      <td>5420.264358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 20, 10, 20)</td>\n",
       "      <td>constant</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>-65238.750999</td>\n",
       "      <td>21493.755040</td>\n",
       "      <td>-68417.917729</td>\n",
       "      <td>5420.264358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_modelo__alpha param_modelo__hidden_layer_sizes  \\\n",
       "271                0.01                     (50, 50, 50)   \n",
       "263                0.01                     (50, 50, 50)   \n",
       "287                0.01                 (10, 20, 10, 20)   \n",
       "279                0.01                 (10, 20, 10, 20)   \n",
       "\n",
       "    param_modelo__learning_rate param_modelo__learning_rate_init  \\\n",
       "271                    adaptive                                1   \n",
       "263                    constant                                1   \n",
       "287                    adaptive                                1   \n",
       "279                    constant                                1   \n",
       "\n",
       "    param_modelo__solver  mean_test_score  std_test_score  mean_train_score  \\\n",
       "271                 adam    -65106.581212    21125.295547     -67996.679809   \n",
       "263                 adam    -65106.581212    21125.295547     -67996.679809   \n",
       "287                 adam    -65238.750999    21493.755040     -68417.917729   \n",
       "279                 adam    -65238.750999    21493.755040     -68417.917729   \n",
       "\n",
       "     std_train_score  \n",
       "271      5672.079262  \n",
       "263      5672.079262  \n",
       "287      5420.264358  \n",
       "279      5420.264358  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Espacio de búsqueda de cada hiperparámetro\n",
    "# ==============================================================================\n",
    "param_grid = {\n",
    "    'modelo__hidden_layer_sizes': [(10), (20), (10, 10), (100,), (50,50,50), (10,20,10,20)],\n",
    "    'modelo__alpha': [0.0001, 0.001, 0.01],\n",
    "    'modelo__learning_rate_init': [0.001, 0.01, 0.1, 1],\n",
    "    'modelo__learning_rate': ['constant', 'adaptive'],\n",
    "    'modelo__solver': ['lbfgs', 'adam'],\n",
    "}\n",
    "\n",
    "# Se combinan los pasos de preprocesado y el modelo en un mismo pipeline\n",
    "MLPX = Pipeline([('preprocessing', preprocessorX),\n",
    "                 ('modelo', MLPRegressor(max_iter=10000, random_state=123, verbose = True))])\n",
    "MLPZ = Pipeline([('preprocessing', preprocessorZ),\n",
    "                 ('modelo', MLPRegressor(max_iter=10000, random_state=123, verbose = True))])\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "# ==============================================================================\n",
    "gridX = GridSearchCV(\n",
    "        estimator  = MLPX,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 1,\n",
    "        return_train_score = True\n",
    "       )\n",
    "gridZ = GridSearchCV(\n",
    "        estimator  = MLPZ,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 1,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridX.fit(X = X_train, y = y_train)\n",
    "gridZ.fit(X = Z_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8eb4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final_MLPX = gridX.best_estimator_\n",
    "modelo_final_MLPZ = gridZ.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "245c7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b54f166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-6.65450484e+09 -1.11860649e+10 -6.98902063e+09 -7.61088810e+09\n",
      " -7.70202692e+09 -1.17463523e+10 -6.98970499e+09 -1.11366760e+10\n",
      " -9.50293709e+09 -8.08372245e+09 -1.17490989e+10 -7.80302753e+09\n",
      " -6.68453993e+09 -7.79747546e+09 -1.08967195e+10 -1.61527848e+10\n",
      " -8.41040312e+09 -7.69431936e+09 -1.86277038e+10 -6.76304245e+09\n",
      " -6.47100533e+09 -8.84946607e+09 -6.20937654e+09 -1.28160807e+11\n",
      " -8.64457482e+09 -3.28601204e+10 -7.85609490e+09 -8.17144462e+09\n",
      " -1.00264660e+10 -6.93413332e+09 -7.83757084e+09 -8.62689257e+09\n",
      " -5.94505776e+09 -6.39776410e+09 -1.23526871e+10 -5.55785800e+10\n",
      " -9.10756273e+09 -7.65505930e+10 -6.75753758e+09 -1.75835789e+10\n",
      " -1.14229094e+10 -7.38787838e+09 -9.76805843e+09 -7.35839050e+09\n",
      " -8.88409101e+09             nan -1.23504955e+10 -8.93579095e+09\n",
      " -1.17725427e+10 -9.34441445e+09 -9.13394195e+09 -1.16705292e+10\n",
      " -1.08817951e+10 -7.17732818e+09 -6.56133710e+09 -8.57173891e+09\n",
      " -2.52594011e+10 -9.50978938e+09 -7.83343139e+09 -2.10004148e+11\n",
      " -6.05564657e+09 -9.78019329e+09 -7.48721293e+10 -1.07161186e+10\n",
      " -6.68879151e+09 -6.29801843e+09 -1.28682023e+10 -5.72546042e+09\n",
      " -7.36886171e+09 -8.59847831e+09 -1.39889576e+10 -7.07061956e+09\n",
      " -1.07687059e+10 -6.07714970e+09 -1.08138081e+10 -2.11976911e+10\n",
      " -8.64873409e+09 -6.35671881e+09 -1.35348439e+10 -7.11064454e+09\n",
      " -1.12238216e+10 -6.57945807e+09 -1.10403547e+10 -3.09868926e+10\n",
      " -7.52185555e+09 -6.10724281e+09 -9.57720926e+09 -5.90816482e+09\n",
      " -1.34118665e+10 -8.26986007e+09 -6.66342049e+09 -2.06406225e+10\n",
      " -1.20268211e+10 -1.14143648e+11 -7.12289350e+09 -1.52273672e+10\n",
      " -1.02480588e+10 -5.43011008e+10 -6.62113949e+10 -6.97760615e+09\n",
      " -6.61711084e+09             nan -7.46859613e+09 -2.38117648e+10\n",
      " -6.25635678e+09 -7.15818594e+09 -1.19785493e+10 -8.46485899e+09\n",
      " -1.02696623e+10 -6.11949759e+09 -1.96383879e+11 -3.62746070e+10\n",
      " -5.83571921e+09 -8.26645139e+09 -7.64202962e+09 -8.38440088e+09\n",
      " -1.80200794e+10 -5.79977684e+09 -1.17233979e+11 -8.63985037e+09\n",
      " -1.23013345e+11 -6.29296770e+09 -1.61507444e+10 -6.25019132e+09\n",
      " -9.39657944e+09 -1.05474043e+10 -6.95787508e+09 -9.60478825e+10\n",
      " -1.23173102e+10 -3.50330238e+10 -6.75589152e+09 -5.97444563e+09\n",
      " -7.68068135e+09 -1.24551454e+10 -1.08321399e+10 -8.94821644e+09\n",
      " -1.06123966e+11 -6.84042366e+09 -6.95105594e+09 -6.28993433e+09\n",
      " -5.77283285e+09 -2.56547738e+10 -4.63034424e+10 -1.04741292e+10\n",
      " -2.91398306e+10 -1.62678369e+10 -3.05096366e+10 -6.84110373e+10\n",
      " -1.02998740e+10 -1.66815796e+10 -9.65979010e+10 -7.16236695e+10\n",
      " -2.64355883e+10 -9.18126343e+09 -6.87259818e+09 -8.75528886e+09\n",
      " -9.05530463e+09 -2.60791030e+10 -2.72556433e+10 -7.82433548e+09\n",
      " -1.49725815e+11 -6.00235900e+09 -2.34669736e+10 -1.64672194e+10\n",
      " -1.48480410e+11 -1.47735831e+10 -1.07612531e+10 -8.39885904e+09\n",
      " -1.16103819e+10 -7.79284468e+09 -1.26285487e+10 -1.01802871e+10\n",
      " -8.40241077e+09 -8.30405105e+09 -9.50193207e+09 -2.97675696e+10\n",
      " -7.50723216e+09 -1.23745090e+10 -9.98346920e+09 -7.13887312e+09\n",
      " -6.80418067e+09 -6.53834205e+09 -1.34613948e+10 -7.19498776e+09\n",
      " -9.23454195e+09 -7.15785437e+09 -1.51382285e+10 -6.27657552e+09\n",
      " -6.88637391e+09 -6.35001673e+09 -4.76265491e+10 -9.63127702e+09\n",
      " -6.48542665e+09 -1.20259745e+10 -6.15377961e+09 -1.52251064e+10\n",
      " -6.72404946e+09 -9.06144164e+09 -1.03255545e+10 -2.27800300e+10\n",
      " -7.44624122e+09 -6.23485100e+09 -5.77792983e+09 -7.24246007e+09\n",
      " -6.91922631e+09 -2.59022006e+10 -7.27030063e+09 -9.72565990e+09\n",
      " -9.06335624e+09 -1.73310726e+10 -7.27071810e+09 -9.13531430e+09\n",
      " -7.92498752e+10 -6.38548385e+09 -7.10812295e+09 -8.18901176e+09\n",
      " -8.74304493e+09 -7.46662431e+09 -5.80157587e+09 -7.32946991e+09\n",
      " -7.91473299e+09 -6.27122616e+09 -1.61406087e+11 -6.27027962e+09\n",
      " -6.76374733e+09 -4.25357177e+10 -9.85316206e+09 -6.06775160e+09\n",
      " -4.64688140e+10 -1.70828477e+10 -7.70353503e+09 -1.32042267e+10\n",
      " -6.64228250e+09 -6.15736890e+09 -1.42715132e+10 -1.35670041e+10\n",
      " -8.03183492e+09 -5.65147303e+09 -6.27629753e+09 -6.37562052e+09\n",
      " -2.32807295e+10 -8.23731103e+09 -2.06102538e+10 -7.49178608e+09\n",
      " -6.08188435e+09 -1.54824950e+11 -6.08843085e+09 -2.07821876e+11\n",
      " -1.41923968e+10 -1.10543734e+10 -1.00801036e+10 -6.00222793e+09\n",
      " -6.84281206e+09 -7.67163723e+09 -6.87637946e+09 -1.08278426e+10\n",
      " -6.22734770e+09 -9.86878648e+09 -2.68007226e+10 -8.54054920e+09\n",
      " -7.22457202e+09 -5.74203347e+09 -9.53578118e+09 -1.09577601e+10\n",
      " -7.20841420e+09 -2.26997023e+11 -6.38789632e+09 -7.00547822e+09\n",
      " -1.49539568e+10 -8.20136838e+09 -1.04961725e+10 -9.53593043e+09\n",
      " -1.34325930e+10 -6.32089914e+09 -1.33238091e+10 -6.75985973e+09\n",
      " -1.03452008e+10 -3.38343034e+10 -1.27493756e+10 -7.71471531e+09\n",
      " -6.27012760e+09 -7.27551801e+09 -6.97384578e+09 -2.39025347e+10\n",
      " -7.04352330e+09 -7.63337770e+09 -7.12873832e+10 -1.72931236e+10\n",
      " -1.20069345e+10 -2.39783227e+10 -1.00135697e+10 -7.74240479e+09\n",
      " -8.62965254e+09 -3.34098892e+10 -6.33522424e+09 -7.94630860e+09\n",
      " -7.29067264e+09 -7.71465291e+09 -7.66476895e+09 -2.61578675e+10\n",
      " -8.61122213e+09 -1.07189196e+10 -9.05202858e+09 -7.28462053e+09\n",
      " -7.38550818e+09 -6.51384023e+09 -5.14789132e+10 -2.60415768e+10\n",
      " -4.17611738e+10 -5.96646255e+09 -8.16797300e+09 -2.25782099e+10\n",
      " -6.52809327e+09 -8.27842787e+09 -7.88651978e+09 -7.35174201e+09\n",
      " -4.57026295e+10 -9.69059961e+09             nan -6.54233296e+09\n",
      " -9.34819186e+10 -7.29514763e+09 -4.57446076e+10 -1.15772156e+10\n",
      " -7.73346379e+09 -8.12762169e+09 -9.66158420e+10 -6.14632455e+09\n",
      " -1.34443318e+10 -9.76824918e+09 -1.78514774e+11 -1.16480808e+10\n",
      " -4.36167557e+10 -7.87187718e+09 -1.04187458e+10 -1.09349445e+10\n",
      " -6.73564425e+09 -8.53402677e+09 -6.66048782e+09 -6.91964916e+09\n",
      " -5.93107953e+09 -8.00563090e+09 -4.72797267e+10 -6.63846290e+09\n",
      " -1.27771358e+10 -9.78484134e+09 -1.30403280e+10 -1.50395707e+10\n",
      " -5.93892338e+09 -1.18817960e+10 -6.15921671e+09 -6.05490714e+09\n",
      " -5.85476840e+09             nan -7.06924682e+09 -8.36363398e+09\n",
      " -6.46932307e+09 -7.39524849e+09 -4.48883329e+10 -8.75364401e+09\n",
      " -1.12806673e+10 -5.94788481e+09 -8.79444065e+09 -8.20971711e+10\n",
      " -7.96383415e+09 -9.38528584e+09 -9.26816252e+09 -1.48200676e+10\n",
      " -6.36007269e+09 -1.04126100e+10 -7.71574638e+09 -8.63000003e+09\n",
      " -7.33078860e+09 -1.93364946e+10 -8.38302700e+09 -9.49455989e+09\n",
      " -1.15369609e+10 -1.27323394e+10 -2.78303654e+10 -1.16644990e+10\n",
      " -9.30751150e+09 -6.31106079e+10 -7.36743913e+09 -4.08182469e+10\n",
      " -1.33660850e+10 -6.03583877e+09 -2.29034794e+10 -6.52477711e+09\n",
      " -8.24093680e+09 -9.39029544e+09 -6.89659473e+09 -1.08241403e+10\n",
      " -2.88750799e+10 -9.66812263e+09 -1.17011251e+10 -8.68713694e+09\n",
      " -7.31569916e+09 -7.69120227e+09 -7.28646667e+09 -7.87994285e+09\n",
      " -9.09596509e+09 -1.43855864e+11 -7.00052556e+09 -2.33684025e+11\n",
      " -1.05511559e+10 -7.10735819e+09 -9.15196672e+10 -2.24739479e+10\n",
      " -9.38988060e+09 -6.56518521e+09 -1.38092031e+10 -4.87677152e+10\n",
      " -1.21063601e+10 -3.05885670e+10 -2.35354525e+10 -4.01667987e+10\n",
      " -7.45498698e+09 -6.69564904e+09 -8.85302407e+09 -6.70114529e+09\n",
      " -7.08479090e+09 -8.13418067e+09 -7.50093660e+09 -8.18679339e+09\n",
      " -1.04313490e+10 -1.33524643e+10 -6.05718637e+09 -6.84575422e+09\n",
      " -7.29424250e+09 -1.26401038e+10 -4.31352425e+10 -1.03717956e+10\n",
      " -4.25195416e+10 -6.36492392e+09 -7.49205805e+09 -1.95181697e+10\n",
      " -7.22096249e+09 -4.76234631e+10 -6.98174622e+09 -1.30095662e+10\n",
      " -8.50732090e+09 -1.68755450e+10 -9.79139938e+09 -6.42402850e+09\n",
      " -1.06814683e+10 -7.70981738e+09 -7.77605600e+09 -9.12035158e+09\n",
      " -4.95060837e+10 -7.25188648e+09 -6.10095725e+09 -8.41916545e+09\n",
      " -5.79707161e+09 -1.83309544e+10 -1.18425099e+10 -1.27188345e+10\n",
      " -7.16274787e+09 -7.94999103e+09 -8.42765660e+09 -7.96888907e+09\n",
      " -6.85186375e+09 -7.58464090e+09 -9.79048632e+09 -6.90487768e+09\n",
      " -6.30350409e+09 -7.23951245e+09 -6.95469479e+09 -3.31272286e+10\n",
      " -6.86416370e+09 -4.77752568e+10 -8.78316929e+09 -6.68538891e+09\n",
      " -1.37730989e+10 -1.09288598e+10 -7.21182534e+09 -1.33825555e+10\n",
      " -6.69724054e+09 -6.25478752e+09 -9.25869529e+09 -1.02802087e+10\n",
      " -1.21626050e+11 -8.20061246e+09 -7.92806990e+09 -7.46942050e+09\n",
      " -7.88272682e+09 -8.72933087e+09 -1.04605224e+10 -6.37353329e+09\n",
      " -7.07172062e+09 -1.37746361e+10 -9.14910313e+09 -3.73214660e+10\n",
      " -6.88349320e+09 -9.61575212e+09 -5.77645826e+09 -6.88435943e+09\n",
      " -6.78944823e+09 -6.76744598e+09 -6.83110450e+09 -1.20641890e+11\n",
      " -1.89525496e+10 -1.11025020e+10 -6.70374911e+09 -9.26183305e+09\n",
      " -6.59805998e+09 -6.93412537e+09 -2.16082081e+10 -9.98165584e+10\n",
      " -7.21257009e+09 -7.40221902e+10 -1.20509066e+10 -7.19908019e+09\n",
      " -1.58865653e+10 -7.44108430e+09             nan -7.59121588e+09\n",
      " -2.02576672e+10 -9.85466205e+09 -6.23525923e+09 -6.05998879e+09\n",
      " -1.35388664e+10 -6.75743291e+09 -6.74543153e+09 -1.11933925e+10\n",
      " -1.46621850e+10 -6.09335111e+09 -6.54906088e+09 -6.06465694e+09\n",
      " -8.70010625e+09 -1.07498405e+10 -2.03427973e+10 -8.92052019e+09\n",
      " -1.49754969e+10 -6.90646997e+09 -5.96323274e+09 -1.29659221e+10\n",
      " -1.81545016e+11             nan -6.47005217e+09 -1.02725895e+10\n",
      " -9.91413922e+09 -6.26131099e+09 -6.48920287e+09 -5.85923350e+10\n",
      " -8.48817945e+09 -9.50911849e+09 -1.42092741e+10 -1.62416872e+10\n",
      " -6.22264604e+09 -7.13894792e+09 -1.25877079e+10 -9.29138138e+09\n",
      " -1.03209098e+10 -1.12782504e+10 -9.99672100e+09 -2.62944172e+10\n",
      " -9.61771656e+09 -1.44821343e+10 -7.39863487e+09 -1.14963683e+10\n",
      " -6.83353036e+09 -3.91277189e+10 -8.60920354e+09 -1.07966418e+10\n",
      " -8.19248460e+09 -1.34797594e+10 -9.66697524e+09 -7.38805706e+09\n",
      " -7.20994712e+09 -1.03057492e+10 -1.43835157e+10 -5.94745148e+09\n",
      " -1.64446294e+10 -1.13336072e+11 -7.47899737e+10 -6.59713748e+09\n",
      " -7.64608616e+10 -7.10598434e+10 -4.35846935e+10 -1.64128963e+10\n",
      " -1.08754401e+10 -9.98965455e+09 -7.60736755e+09 -8.22939846e+09\n",
      " -8.88709850e+09 -3.38185385e+10 -6.28589587e+09 -2.04416553e+10\n",
      " -5.63059865e+10 -7.95160623e+09 -1.56863090e+10 -1.12322806e+10\n",
      " -8.16869162e+09 -4.99230552e+10 -6.40658971e+09 -8.79479867e+09\n",
      " -1.99892870e+11 -1.98787938e+10 -1.72288021e+10 -5.89194960e+09\n",
      " -7.03957638e+09 -7.46585616e+09 -6.80309880e+09 -6.60472783e+09\n",
      " -5.00569028e+10 -2.26763698e+11 -8.89193204e+09 -8.61152971e+09\n",
      " -8.37179536e+09 -8.52428537e+09 -6.55128472e+09 -7.94438951e+09\n",
      " -8.51161948e+09 -9.04977981e+09 -1.01163267e+10 -6.63551433e+09\n",
      " -4.57896040e+10 -3.56988271e+10 -4.39451804e+10 -9.25404428e+09\n",
      " -8.55006893e+09 -9.36748335e+09 -8.80024770e+09 -7.99589443e+09\n",
      " -6.63836338e+09 -7.95999385e+09 -9.63838892e+09 -1.35765511e+10\n",
      " -1.15071197e+10 -6.01249606e+09 -7.61180180e+09 -9.19088845e+09\n",
      " -1.36374715e+10 -6.46668671e+09 -4.01896083e+10 -9.24556925e+09\n",
      " -6.51418405e+09 -5.91153071e+10 -9.98412992e+09             nan\n",
      " -9.33699431e+09 -6.78930301e+09 -7.32955082e+09 -6.49356726e+09\n",
      " -1.24421651e+10 -1.05569001e+10 -5.78437540e+09 -8.31689079e+09\n",
      " -6.24280264e+09 -1.26165762e+10 -1.40870482e+10 -6.31174111e+09\n",
      " -1.40107136e+10 -2.37715955e+10 -9.81341727e+09 -1.23476640e+10\n",
      " -9.11064506e+09 -9.45602088e+09 -6.28662645e+09 -4.17677725e+10\n",
      " -9.12260067e+09 -6.20713430e+10 -6.20740332e+09 -1.31988403e+10\n",
      " -6.07315836e+09 -1.03596447e+11 -7.09856836e+09 -6.02259463e+09\n",
      " -7.87596730e+09 -1.45720169e+10 -6.45248203e+09 -8.36036186e+09\n",
      " -2.57548842e+10 -6.46911731e+09 -1.00452340e+10 -7.94534665e+09\n",
      " -8.96619916e+09 -9.11714732e+09 -8.54323263e+09 -8.76280410e+09\n",
      " -4.96030852e+10 -5.78489151e+09 -6.26358784e+10 -6.85367123e+09\n",
      " -6.92136595e+09 -5.81974412e+09 -2.61374605e+10 -6.20913765e+09\n",
      " -6.59330571e+09 -7.79834913e+09 -5.88755899e+09 -8.55436057e+09\n",
      " -2.15750946e+10 -7.21167528e+09 -1.24199036e+10 -7.56592775e+10\n",
      " -5.81598735e+09 -7.84346956e+09 -1.45926984e+11 -9.94132300e+09\n",
      " -1.40767522e+10 -4.96533277e+10 -8.71977800e+10 -1.30763489e+10\n",
      " -1.40297610e+10 -6.00804136e+09 -9.28237853e+09 -9.09433428e+09\n",
      " -8.89544781e+09 -1.31403742e+10 -7.35791476e+09 -3.07919030e+10\n",
      " -6.06721811e+09 -1.11082785e+10 -7.51674420e+09 -4.43817037e+10\n",
      " -1.32833594e+11 -2.66263579e+10 -1.73808336e+10 -4.60887256e+10\n",
      " -7.78527456e+09 -9.40504800e+09 -9.56190599e+09 -7.75672013e+09\n",
      " -1.36885696e+10 -1.85219360e+10 -6.92833869e+09 -1.45455763e+10\n",
      " -1.83128876e+10 -2.08591622e+10 -6.09487508e+09 -1.87684456e+10\n",
      " -1.05808053e+10 -7.02749635e+09 -6.93783206e+10 -2.17489381e+10\n",
      " -8.99724446e+09 -6.93970695e+09             nan -7.63775494e+09\n",
      " -7.03048311e+09 -9.50425534e+09 -1.28581681e+10 -1.61372236e+10\n",
      " -6.52229790e+09 -6.29527085e+09 -1.24745608e+10 -8.19708902e+09\n",
      " -9.16349563e+09 -6.32606817e+09 -6.97163809e+09 -7.65691844e+09\n",
      " -7.72188643e+09 -1.91610903e+10 -7.50347412e+09 -9.35526148e+09\n",
      " -9.95503747e+09 -8.01054059e+09 -1.05956352e+10 -8.08544779e+09\n",
      " -7.73928977e+09 -5.71496622e+09 -1.17633871e+10 -1.13695401e+11\n",
      " -6.07235485e+09 -2.70908084e+10 -1.18898538e+10 -6.57582316e+09\n",
      " -8.14629498e+09 -6.84500860e+09 -3.73802799e+10 -2.11829163e+10\n",
      " -8.76591479e+09 -6.14079920e+09 -2.01281062e+10 -1.03902624e+10\n",
      " -6.71234837e+09 -1.25526818e+10             nan -9.78689524e+09\n",
      " -6.32400051e+09 -7.86626876e+09 -1.13332099e+10 -6.37703018e+09\n",
      " -9.60883667e+09 -7.91603704e+09 -2.83181028e+10 -8.90913578e+09\n",
      " -1.30250788e+10 -8.76854251e+09 -9.76989445e+09 -2.12257417e+10\n",
      " -8.09401426e+09 -2.02347991e+10 -7.08080093e+09 -7.87465470e+09\n",
      " -1.30360919e+10 -1.09095228e+10 -7.00099859e+09 -8.67486101e+09\n",
      " -6.98391408e+09 -2.77532184e+10 -1.52574101e+10 -3.20988539e+10\n",
      " -6.75162563e+09 -7.87110919e+09 -1.36216264e+10 -8.88221381e+09\n",
      " -6.29397839e+09 -8.88658314e+09 -7.02231283e+09 -1.53298043e+10\n",
      " -1.20716338e+10 -6.08580745e+09 -3.63055844e+10 -1.48561123e+10\n",
      " -1.49915882e+10 -8.38111146e+09 -6.90810114e+09 -1.40670431e+10\n",
      " -1.06930626e+10 -6.05167583e+09 -1.16322426e+10 -1.23365427e+10\n",
      " -5.70091844e+10 -1.18364741e+10 -6.84182267e+09 -1.08807718e+10\n",
      " -6.92979060e+09 -8.73864414e+09 -6.18939008e+09 -5.83917586e+09\n",
      " -5.80191229e+09 -7.04009347e+09 -8.18895761e+10 -8.84474613e+09\n",
      " -8.53878146e+09 -1.33973461e+10 -7.12023503e+09 -5.17428798e+10\n",
      " -7.02528370e+09 -7.22495395e+09 -6.74246680e+09 -2.48034795e+10\n",
      " -1.43184820e+11 -3.28095967e+10 -1.81403649e+10 -2.28276945e+10\n",
      " -3.83372773e+10 -8.39928206e+09 -6.15399962e+09 -9.18222426e+09\n",
      " -6.91708081e+09 -6.20838388e+09 -8.73095696e+09 -2.24136082e+10\n",
      " -6.24075236e+09 -1.16909485e+10 -8.88242608e+09 -1.04408708e+10\n",
      " -6.18112824e+09 -9.02082381e+09 -9.08359996e+10 -1.14930821e+10\n",
      " -3.14262477e+10 -6.64988061e+09 -1.04959768e+10 -8.05791668e+09\n",
      " -5.17449701e+10 -9.30180942e+09 -1.22811091e+10 -1.23571518e+10\n",
      " -1.41550992e+10 -6.25422782e+09 -6.89805876e+09 -1.46575477e+10\n",
      " -1.24199978e+10 -1.41198898e+11 -6.21365532e+09 -1.02592821e+10\n",
      " -1.32126086e+10 -1.63294346e+10 -7.01892507e+09 -8.50341581e+09\n",
      " -2.13923300e+10 -7.93258335e+09 -6.25067755e+09 -1.46818270e+10\n",
      " -8.73540799e+09 -1.10459717e+10 -4.10173112e+10 -8.23519518e+09\n",
      " -9.02159240e+09 -9.40384270e+09 -2.24773782e+10 -1.03379848e+10\n",
      " -1.23837133e+10 -6.37495995e+09 -1.51102127e+10 -4.94418853e+10\n",
      " -5.20237882e+10 -1.82685516e+10 -5.96196330e+09 -9.24095756e+09\n",
      " -3.32083583e+10 -1.58008520e+10 -7.88620799e+09 -1.64376200e+10\n",
      " -1.00178284e+10 -1.56265708e+10 -6.72392469e+09 -3.07366056e+10\n",
      " -7.46058763e+09 -4.79262797e+10 -3.13602533e+10 -1.02450856e+10\n",
      " -6.27916377e+09 -2.66159623e+10 -1.30685491e+10 -1.14058333e+10\n",
      " -3.32375744e+10 -2.92742375e+10 -1.18982076e+10 -8.28285967e+09\n",
      " -2.60112062e+10 -1.79618775e+10 -1.27320408e+10 -8.89813760e+09\n",
      " -9.82127212e+09 -2.38228705e+10 -9.78100244e+09 -1.72276409e+10\n",
      " -1.34248510e+10 -9.65900910e+09 -1.57523284e+10 -6.54432848e+09\n",
      " -7.69344590e+09 -1.73656239e+11 -6.74790513e+09 -1.49220018e+10\n",
      " -7.06531908e+09 -6.37397558e+09 -9.11100135e+09 -7.45742506e+09\n",
      " -6.66628507e+09 -1.98236396e+10 -2.43092472e+10 -5.66587405e+09\n",
      " -8.85686781e+09 -6.54990130e+10 -5.39419441e+10 -7.36677911e+09\n",
      " -7.30009256e+09 -3.47524251e+10 -5.90017715e+09 -7.05474593e+09\n",
      " -6.28330495e+09 -1.74705909e+10 -6.91481063e+09 -1.07083501e+10\n",
      " -9.01159247e+09 -3.02661886e+10 -3.15175861e+10 -5.62508165e+09\n",
      " -9.83414501e+09 -1.81682463e+11 -8.05810364e+09 -1.22647191e+10\n",
      " -6.66911221e+09 -2.78657209e+10 -1.03032854e+10 -7.62818455e+09\n",
      " -6.40051076e+09 -1.36052826e+10 -7.91996969e+09 -6.46364819e+09\n",
      " -7.09072465e+09 -7.56028770e+09 -8.14936498e+09 -7.78131458e+09\n",
      " -7.71465150e+09 -6.86181711e+09 -9.50036381e+09 -1.10687620e+10\n",
      " -1.05256653e+10 -1.32298893e+10 -6.73729596e+09 -7.92082709e+09\n",
      " -8.66768308e+09 -1.47530372e+10 -1.14396222e+10 -9.86673879e+09\n",
      " -6.35821345e+09 -9.38877309e+09 -7.67104312e+09 -9.66132594e+09\n",
      " -8.85231579e+09 -6.45644241e+09 -6.54115374e+09 -6.20175111e+09]\n",
      "  warnings.warn(\n",
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the train scores are non-finite: [-3.76573500e+09 -3.30494087e+09 -3.71166387e+09 -3.62103145e+09\n",
      " -3.60857889e+09 -3.27667812e+09 -3.71148842e+09 -3.30762212e+09\n",
      " -3.41679681e+09 -3.55999817e+09 -3.27656294e+09 -3.59536282e+09\n",
      " -3.76072716e+09 -3.59595792e+09 -3.32099763e+09 -3.13015530e+09\n",
      " -3.52191942e+09 -3.60958771e+09 -3.07789965e+09 -3.74784210e+09\n",
      " -3.79711303e+09 -3.47580185e+09 -3.84444025e+09 -2.57435455e+09\n",
      " -3.49665611e+09 -2.90571981e+09 -3.58845861e+09 -3.54939462e+09\n",
      " -3.37670874e+09 -3.72034698e+09 -3.59086656e+09 -3.49853090e+09\n",
      " -3.89587686e+09 -3.81006522e+09 -3.24958428e+09 -2.76897327e+09\n",
      " -3.45130551e+09 -2.69131784e+09 -3.74862695e+09 -3.09838917e+09\n",
      " -3.29257553e+09 -3.65199894e+09 -3.39594858e+09 -3.65618431e+09\n",
      " -3.47239708e+09             nan -3.24968204e+09 -3.46744993e+09\n",
      " -3.27542752e+09 -3.43014554e+09 -3.44885858e+09 -3.28029302e+09\n",
      " -3.32185884e+09 -3.68291126e+09 -3.78155345e+09 -3.50430566e+09\n",
      " -2.98060485e+09 -3.41627445e+09 -3.59136937e+09 -2.39600448e+09\n",
      " -3.87385037e+09 -3.39486289e+09 -2.69632348e+09 -3.33157805e+09\n",
      " -3.76004420e+09 -3.82803302e+09 -3.22890140e+09 -3.94237939e+09\n",
      " -3.65469527e+09 -3.50149199e+09 -3.18980000e+09 -3.69909958e+09\n",
      " -3.32847145e+09 -3.86962028e+09 -3.32585147e+09 -3.03475504e+09\n",
      " -3.49617496e+09 -3.81738251e+09 -3.20476652e+09 -3.69293638e+09\n",
      " -3.30294468e+09 -3.77837993e+09 -3.31292488e+09 -2.92189804e+09\n",
      " -3.63314910e+09 -3.86379795e+09 -3.41092600e+09 -3.90342926e+09\n",
      " -3.20904218e+09 -3.53787248e+09 -3.76420473e+09 -3.04338559e+09\n",
      " -3.26374460e+09 -2.60025477e+09 -3.69113582e+09 -3.15360703e+09\n",
      " -3.36133247e+09 -2.77478230e+09 -2.72601976e+09 -3.71338538e+09\n",
      " -3.77198388e+09             nan -3.64059886e+09 -2.99837867e+09\n",
      " -3.83566472e+09 -3.68577174e+09 -3.26591792e+09 -3.51589125e+09\n",
      " -3.35984859e+09 -3.86146173e+09 -2.48109149e+09 -2.87891821e+09\n",
      " -3.91853867e+09 -3.53828129e+09 -3.61657251e+09 -3.52478740e+09\n",
      " -3.08958345e+09 -3.92618732e+09 -2.59426963e+09 -3.49715437e+09\n",
      " -2.58375574e+09 -3.82901677e+09 -3.13020365e+09 -3.83687452e+09\n",
      " -3.42584707e+09 -3.34188992e+09 -3.71653475e+09 -2.63868400e+09\n",
      " -3.25109293e+09 -2.88831735e+09 -3.74888032e+09 -3.88996300e+09\n",
      " -3.61139349e+09 -3.24531334e+09 -3.32473120e+09 -3.46617474e+09\n",
      " -2.61631722e+09 -3.73516441e+09 -3.71757766e+09 -3.82948694e+09\n",
      " -3.93199403e+09 -2.97600996e+09 -2.81506677e+09 -3.34661621e+09\n",
      " -2.93908618e+09 -3.12737269e+09 -2.92622179e+09 -2.71809472e+09\n",
      " -3.35793948e+09 -3.11784212e+09 -2.63748762e+09 -2.70712923e+09\n",
      " -2.96717595e+09 -3.44453107e+09 -3.73001612e+09 -3.48526593e+09\n",
      " -3.45604895e+09 -2.97111563e+09 -2.95822401e+09 -3.59253777e+09\n",
      " -2.54142564e+09 -3.88436668e+09 -3.00284415e+09 -3.12271266e+09\n",
      " -2.54326042e+09 -3.16611246e+09 -3.32893128e+09 -3.52318780e+09\n",
      " -3.28322878e+09 -3.59656435e+09 -3.23827783e+09 -3.36593391e+09\n",
      " -3.52277817e+09 -3.53392076e+09 -3.41706595e+09 -2.93307555e+09\n",
      " -3.63510344e+09 -3.24866564e+09 -3.37974466e+09 -3.68863638e+09\n",
      " -3.74102789e+09 -3.78545015e+09 -3.20731306e+09 -3.68019961e+09\n",
      " -3.43982252e+09 -3.68585103e+09 -3.15601138e+09 -3.83196976e+09\n",
      " -3.72789907e+09 -3.81861676e+09 -2.80782744e+09 -3.40654638e+09\n",
      " -3.79461308e+09 -3.26378269e+09 -3.85487731e+09 -3.15367955e+09\n",
      " -3.75424651e+09 -3.45546932e+09 -3.35613608e+09 -3.01197981e+09\n",
      " -3.64367299e+09 -3.83970920e+09 -3.93089528e+09 -3.67318758e+09\n",
      " -3.72256212e+09 -2.97319283e+09 -3.66914680e+09 -3.39907022e+09\n",
      " -3.45527345e+09 -3.10362548e+09 -3.66897564e+09 -3.44885865e+09\n",
      " -2.68307674e+09 -3.81230855e+09 -3.69330969e+09 -3.54729259e+09\n",
      " -3.48645004e+09 -3.64078442e+09 -3.92581093e+09 -3.66043122e+09\n",
      " -3.58092105e+09 -3.83297405e+09 -2.52424449e+09 -3.83314720e+09\n",
      " -3.74760049e+09 -2.83695165e+09 -3.38937848e+09 -3.87149338e+09\n",
      " -2.81415770e+09 -3.10888944e+09 -3.60837315e+09 -3.21640348e+09\n",
      " -3.76777302e+09 -3.85421767e+09 -3.18097426e+09 -3.20368913e+09\n",
      " -3.56627526e+09 -3.95902249e+09 -3.83198966e+09 -3.81401535e+09\n",
      " -3.00528328e+09 -3.54173063e+09 -3.04388682e+09 -3.63726758e+09\n",
      " -3.86871504e+09 -2.53317974e+09 -3.86746503e+09 -2.39563367e+09\n",
      " -3.18335843e+09 -3.31213051e+09 -3.37286904e+09 -3.88438037e+09\n",
      " -3.73489388e+09 -3.61262379e+09 -3.72952352e+09 -3.32504377e+09\n",
      " -3.84110129e+09 -3.38819428e+09 -2.96313507e+09 -3.50766217e+09\n",
      " -3.67581283e+09 -3.93872717e+09 -3.41411683e+09 -3.31750353e+09\n",
      " -3.67825249e+09 -2.43463205e+09 -3.81178651e+09 -3.70908766e+09\n",
      " -3.16108311e+09 -3.54595384e+09 -3.34511466e+09 -3.41418746e+09\n",
      " -3.20830952e+09 -3.82384382e+09 -3.21212068e+09 -3.74824981e+09\n",
      " -3.35488901e+09 -2.89774097e+09 -3.23349905e+09 -3.60685701e+09\n",
      " -3.83312394e+09 -3.66833396e+09 -3.71407119e+09 -2.99723244e+09\n",
      " -3.70323236e+09 -3.61778820e+09 -2.70817565e+09 -3.10441899e+09\n",
      " -3.26464624e+09 -2.99611777e+09 -3.37768420e+09 -3.60331353e+09\n",
      " -3.49825918e+09 -2.90119319e+09 -3.82128910e+09 -3.57695346e+09\n",
      " -3.66602500e+09 -3.60691489e+09 -3.61362868e+09 -2.97030703e+09\n",
      " -3.50019471e+09 -3.33149877e+09 -3.45640243e+09 -3.66692412e+09\n",
      " -3.65229373e+09 -3.78967454e+09 -2.78810184e+09 -2.97161514e+09\n",
      " -2.84170322e+09 -3.89155649e+09 -3.54998933e+09 -3.01469649e+09\n",
      " -3.78726944e+09 -3.53693927e+09 -3.58446857e+09 -3.65717033e+09\n",
      " -2.81838372e+09 -3.40182073e+09             nan -3.78475892e+09\n",
      " -2.64489246e+09 -3.66550618e+09 -2.81818251e+09 -3.28487574e+09\n",
      " -3.60439587e+09 -3.55461020e+09 -2.63738959e+09 -3.85632494e+09\n",
      " -3.20790744e+09 -3.39589342e+09 -2.50240030e+09 -3.28138599e+09\n",
      " -2.83039383e+09 -3.58645472e+09 -3.35010166e+09 -3.31879209e+09\n",
      " -3.75233880e+09 -3.50835066e+09 -3.76476363e+09 -3.72260068e+09\n",
      " -3.89872260e+09 -3.56955773e+09 -2.80970279e+09 -3.76848605e+09\n",
      " -3.23241675e+09 -3.39450370e+09 -3.22241336e+09 -3.15868514e+09\n",
      " -3.89714809e+09 -3.27035183e+09 -3.85390481e+09 -3.87395721e+09\n",
      " -3.91451985e+09             nan -3.69920624e+09 -3.52719914e+09\n",
      " -3.79741854e+09 -3.65103159e+09 -2.82303584e+09 -3.48536075e+09\n",
      " -3.29995172e+09 -3.89530584e+09 -3.48134114e+09 -2.67482594e+09\n",
      " -3.57468575e+09 -3.42672874e+09 -3.43677178e+09 -3.16480320e+09\n",
      " -3.81679989e+09 -3.35045728e+09 -3.60685528e+09 -3.49817957e+09\n",
      " -3.66027299e+09 -3.06500738e+09 -3.52508260e+09 -3.41750356e+09\n",
      " -3.28683732e+09 -3.23416659e+09 -2.95229586e+09 -3.28061277e+09\n",
      " -3.43338659e+09 -2.73752836e+09 -3.65498173e+09 -2.84768636e+09\n",
      " -3.21064137e+09 -3.87773711e+09 -3.01029705e+09 -3.78782742e+09\n",
      " -3.54120063e+09 -3.42643171e+09 -3.72629813e+09 -3.32517446e+09\n",
      " -2.94173407e+09 -3.40370784e+09 -3.27882511e+09 -3.49217820e+09\n",
      " -3.66244546e+09 -3.60996825e+09 -3.66667554e+09 -3.58533010e+09\n",
      " -3.45230494e+09 -2.55016052e+09 -3.70992162e+09 -2.42188368e+09\n",
      " -3.34167864e+09 -3.69343442e+09 -2.64968198e+09 -3.01622521e+09\n",
      " -3.42625563e+09 -3.78088820e+09 -3.19560932e+09 -2.80174239e+09\n",
      " -3.26020004e+09 -2.92554240e+09 -3.00188495e+09 -2.85188498e+09\n",
      " -3.64244961e+09 -3.75885937e+09 -3.47542934e+09 -3.75803884e+09\n",
      " -3.69688799e+09 -3.55392773e+09 -3.63612001e+09 -3.54755034e+09\n",
      " -3.34924483e+09 -3.21111423e+09 -3.87352355e+09 -3.73443924e+09\n",
      " -3.66555130e+09 -3.23781444e+09 -2.83325760e+09 -3.35317767e+09\n",
      " -2.83705552e+09 -3.81590604e+09 -3.63732642e+09 -3.06195481e+09\n",
      " -3.67631371e+09 -2.80788776e+09 -3.71277445e+09 -3.22355924e+09\n",
      " -3.51132412e+09 -3.11350668e+09 -3.39407573e+09 -3.80544213e+09\n",
      " -3.33368375e+09 -3.60760592e+09 -3.59875189e+09 -3.45000839e+09\n",
      " -2.79802856e+09 -3.67171530e+09 -3.86504121e+09 -3.52091029e+09\n",
      " -3.92677909e+09 -3.08347500e+09 -3.27217628e+09 -3.23469651e+09\n",
      " -3.68506308e+09 -3.57664271e+09 -3.52009525e+09 -3.57414219e+09\n",
      " -3.73330067e+09 -3.62445774e+09 -3.39404614e+09 -3.72483762e+09\n",
      " -3.82709319e+09 -3.67354189e+09 -3.71696400e+09 -2.90351675e+09\n",
      " -3.73144549e+09 -2.80707745e+09 -3.48248796e+09 -3.76059506e+09\n",
      " -3.19678180e+09 -3.31917315e+09 -3.67769618e+09 -3.21006749e+09\n",
      " -3.75866557e+09 -3.83603264e+09 -3.43760588e+09 -3.35916939e+09\n",
      " -2.58626457e+09 -3.54596457e+09 -3.57925643e+09 -3.64041542e+09\n",
      " -3.58499675e+09 -3.48789638e+09 -3.34737864e+09 -3.81434820e+09\n",
      " -3.69883176e+09 -3.19672825e+09 -3.44742651e+09 -2.87135039e+09\n",
      " -3.72830021e+09 -3.40766507e+09 -3.93121636e+09 -3.72810572e+09\n",
      " -3.74341260e+09 -3.74702909e+09 -3.73671440e+09 -2.58806513e+09\n",
      " -3.07197064e+09 -3.30947233e+09 -3.75747299e+09 -3.43734856e+09\n",
      " -3.77521816e+09 -3.72027494e+09 -3.02860510e+09 -2.63004093e+09\n",
      " -3.67761643e+09 -2.69927867e+09 -3.26267471e+09 -3.67960339e+09\n",
      " -3.13660122e+09 -3.64437582e+09             nan -3.62350414e+09\n",
      " -3.04955480e+09 -3.38924644e+09 -3.83957179e+09 -3.87300752e+09\n",
      " -3.20465279e+09 -3.74868016e+09 -3.75064584e+09 -3.30461975e+09\n",
      " -3.16936391e+09 -3.86646840e+09 -3.78364736e+09 -3.87205480e+09\n",
      " -3.49083374e+09 -3.32955700e+09 -3.04811117e+09 -3.46893445e+09\n",
      " -3.16048973e+09 -3.72476005e+09 -3.89218841e+09 -3.22519618e+09\n",
      " -2.49900643e+09             nan -3.79730920e+09 -3.35978819e+09\n",
      " -3.38480056e+09 -3.83475522e+09 -3.79392852e+09 -2.75584385e+09\n",
      " -3.51335586e+09 -3.41631148e+09 -3.18288810e+09 -3.12803897e+09\n",
      " -3.84192096e+09 -3.68860493e+09 -3.23991191e+09 -3.43475323e+09\n",
      " -3.35643132e+09 -3.30003531e+09 -3.37886814e+09 -2.96863841e+09\n",
      " -3.40749873e+09 -3.17460475e+09 -3.65051450e+09 -3.28885352e+09\n",
      " -3.73633242e+09 -2.85882002e+09 -3.50041180e+09 -3.32679024e+09\n",
      " -3.54692121e+09 -3.20668480e+09 -3.40368489e+09 -3.65197715e+09\n",
      " -3.67806144e+09 -3.35757268e+09 -3.17753697e+09 -3.89541494e+09\n",
      " -3.12319464e+09 -2.60180655e+09 -2.69680716e+09 -3.77538563e+09\n",
      " -2.69158870e+09 -2.70897947e+09 -2.83063629e+09 -3.12396733e+09\n",
      " -3.32228018e+09 -3.37936249e+09 -3.62127809e+09 -3.54254006e+09\n",
      " -3.47211808e+09 -2.89788264e+09 -3.83023910e+09 -3.04657432e+09\n",
      " -2.76560501e+09 -3.57622424e+09 -3.14165490e+09 -3.30246177e+09\n",
      " -3.54970665e+09 -2.79591255e+09 -3.80851213e+09 -3.48131443e+09\n",
      " -2.47725444e+09 -3.05580670e+09 -3.10579428e+09 -3.90678904e+09\n",
      " -3.70384686e+09 -3.64103270e+09 -3.74121206e+09 -3.77412792e+09\n",
      " -2.79512979e+09 -2.43502838e+09 -3.47164489e+09 -3.50020593e+09\n",
      " -3.52620447e+09 -3.50950321e+09 -3.78327604e+09 -3.57720480e+09\n",
      " -3.51076942e+09 -3.45668356e+09 -3.37044856e+09 -3.76893955e+09\n",
      " -2.81786162e+09 -2.88311297e+09 -2.82851256e+09 -3.43800620e+09\n",
      " -3.50672926e+09 -3.42819285e+09 -3.48066317e+09 -3.57091586e+09\n",
      " -3.76839739e+09 -3.57521857e+09 -3.40585654e+09 -3.20336716e+09\n",
      " -3.28831388e+09 -3.88235500e+09 -3.62083074e+09 -3.44368013e+09\n",
      " -3.20130879e+09 -3.79795814e+09 -2.85174481e+09 -3.43886536e+09\n",
      " -3.78958265e+09 -2.75349930e+09 -3.37981131e+09             nan\n",
      " -3.43079757e+09 -3.74343749e+09 -3.66038365e+09 -3.79323496e+09\n",
      " -3.24584875e+09 -3.34138475e+09 -3.92950661e+09 -3.53246422e+09\n",
      " -3.83821803e+09 -3.23875369e+09 -3.18669040e+09 -3.82553500e+09\n",
      " -3.18910020e+09 -2.99876397e+09 -3.39234527e+09 -3.24979386e+09\n",
      " -3.45091966e+09 -3.42084997e+09 -3.83010959e+09 -2.84166399e+09\n",
      " -3.44987780e+09 -2.74173374e+09 -3.84476933e+09 -3.21660712e+09\n",
      " -3.87044019e+09 -2.62169672e+09 -3.69481196e+09 -3.88034467e+09\n",
      " -3.58579646e+09 -3.17194303e+09 -3.80035359e+09 -3.52758939e+09\n",
      " -2.97485236e+09 -3.79751791e+09 -3.37535194e+09 -3.57726472e+09\n",
      " -3.46457922e+09 -3.45052084e+09 -3.50734796e+09 -3.48444142e+09\n",
      " -2.79751568e+09 -3.92939810e+09 -2.73950834e+09 -3.73304532e+09\n",
      " -3.72222931e+09 -3.92193654e+09 -2.97039236e+09 -3.84444975e+09\n",
      " -3.77603033e+09 -3.59602260e+09 -3.90769014e+09 -3.50619134e+09\n",
      " -3.02910681e+09 -3.67771484e+09 -3.24678173e+09 -2.69399843e+09\n",
      " -3.92272621e+09 -3.59017009e+09 -2.54704069e+09 -3.38294890e+09\n",
      " -3.18696773e+09 -2.79725800e+09 -2.66088875e+09 -3.22107813e+09\n",
      " -3.18849283e+09 -3.88321615e+09 -3.43571308e+09 -3.45251432e+09\n",
      " -3.47129865e+09 -3.21873073e+09 -3.65635924e+09 -2.92368694e+09\n",
      " -3.87155362e+09 -3.30921319e+09 -3.63380098e+09 -2.82595617e+09\n",
      " -2.56702926e+09 -2.96505627e+09 -3.10256536e+09 -2.81625345e+09\n",
      " -3.59763854e+09 -3.42499396e+09 -3.41200849e+09 -3.60143913e+09\n",
      " -3.19956701e+09 -3.07993232e+09 -3.72121220e+09 -3.17271324e+09\n",
      " -3.08382038e+09 -3.03996259e+09 -3.86617459e+09 -3.07534091e+09\n",
      " -3.33985438e+09 -3.70561189e+09 -2.71471021e+09 -3.02652868e+09\n",
      " -3.46151978e+09 -3.71934322e+09             nan -3.61723811e+09\n",
      " -3.70518508e+09 -3.41679005e+09 -3.22928802e+09 -3.13051453e+09\n",
      " -3.78828380e+09 -3.82851155e+09 -3.24451377e+09 -3.54644249e+09\n",
      " -3.44608529e+09 -3.82298183e+09 -3.71431580e+09 -3.61477188e+09\n",
      " -3.60594922e+09 -3.06822677e+09 -3.63573488e+09 -3.42920134e+09\n",
      " -3.38184710e+09 -3.56897224e+09 -3.33898271e+09 -3.55989401e+09\n",
      " -3.60360354e+09 -3.94470313e+09 -3.27588444e+09 -2.60097163e+09\n",
      " -3.87058413e+09 -2.96003891e+09 -3.26995392e+09 -3.77901134e+09\n",
      " -3.55247305e+09 -3.73444677e+09 -2.87082383e+09 -3.03496374e+09\n",
      " -3.48413646e+09 -3.85737286e+09 -3.05167395e+09 -3.35188570e+09\n",
      " -3.75607490e+09 -3.24132768e+09             nan -3.39435650e+09\n",
      " -3.82332099e+09 -3.58706145e+09 -3.29719091e+09 -3.81375181e+09\n",
      " -3.40828773e+09 -3.58087394e+09 -2.94730267e+09 -3.46995172e+09\n",
      " -3.22297802e+09 -3.48394111e+09 -3.39563037e+09 -3.03433392e+09\n",
      " -3.55888879e+09 -3.04991691e+09 -3.69742076e+09 -3.58621960e+09\n",
      " -3.22256761e+09 -3.32026805e+09 -3.70973706e+09 -3.49350647e+09\n",
      " -3.71240030e+09 -2.95309991e+09 -3.15273889e+09 -2.91212240e+09\n",
      " -3.74967422e+09 -3.58646487e+09 -3.20184598e+09 -3.47256538e+09\n",
      " -3.82877063e+09 -3.47225409e+09 -3.70642732e+09 -3.15082311e+09\n",
      " -3.26174020e+09 -3.86793905e+09 -2.87871713e+09 -3.16376099e+09\n",
      " -3.16003864e+09 -3.52516509e+09 -3.72441929e+09 -3.18730483e+09\n",
      " -3.33296088e+09 -3.87460661e+09 -3.28217741e+09 -3.25028353e+09\n",
      " -2.76267321e+09 -3.27243267e+09 -3.73501527e+09 -3.32196510e+09\n",
      " -3.72105487e+09 -3.48690799e+09 -3.84818824e+09 -3.91780294e+09\n",
      " -3.92574160e+09 -3.70378271e+09 -2.67534983e+09 -3.47641800e+09\n",
      " -3.50790297e+09 -3.20954742e+09 -3.69141451e+09 -2.78688085e+09\n",
      " -3.70603519e+09 -3.67572472e+09 -3.75109486e+09 -2.98604341e+09\n",
      " -2.55115059e+09 -2.90610678e+09 -3.08724557e+09 -3.01125770e+09\n",
      " -2.86420896e+09 -3.52319847e+09 -3.85490572e+09 -3.44444372e+09\n",
      " -3.72296008e+09 -3.84458973e+09 -3.48766874e+09 -3.01694694e+09\n",
      " -3.83857648e+09 -3.27932097e+09 -3.47256122e+09 -3.34863892e+09\n",
      " -3.84974471e+09 -3.45934556e+09 -2.65149476e+09 -3.28904238e+09\n",
      " -2.91800275e+09 -3.76654638e+09 -3.34520615e+09 -3.56305435e+09\n",
      " -2.78685752e+09 -3.43389966e+09 -3.25262316e+09 -3.24941722e+09\n",
      " -3.18453275e+09 -3.83610617e+09 -3.72596527e+09 -3.16944762e+09\n",
      " -3.24677950e+09 -2.55412687e+09 -3.84365816e+09 -3.36063359e+09\n",
      " -3.21610958e+09 -3.12594707e+09 -3.70693890e+09 -3.51164960e+09\n",
      " -3.03183254e+09 -3.57863257e+09 -3.83677844e+09 -3.16879104e+09\n",
      " -3.48734771e+09 -3.31256740e+09 -2.84640431e+09 -3.54187363e+09\n",
      " -3.45925183e+09 -3.42505552e+09 -3.01617229e+09 -3.35530898e+09\n",
      " -3.24829806e+09 -3.81418081e+09 -3.15677398e+09 -2.79828267e+09\n",
      " -2.78550666e+09 -3.08474515e+09 -3.89247826e+09 -3.43931100e+09\n",
      " -2.90280698e+09 -3.13877240e+09 -3.58449645e+09 -3.12341459e+09\n",
      " -3.37729811e+09 -3.14316700e+09 -3.75416882e+09 -2.92419584e+09\n",
      " -3.64169172e+09 -2.80615922e+09 -2.91851424e+09 -3.36149416e+09\n",
      " -3.83154715e+09 -2.96512902e+09 -3.22136435e+09 -3.29347706e+09\n",
      " -2.90253924e+09 -2.93787784e+09 -3.26957604e+09 -3.53645383e+09\n",
      " -2.97188464e+09 -3.09074309e+09 -3.23417808e+09 -3.47099665e+09\n",
      " -3.39186478e+09 -2.99822612e+09 -3.39480997e+09 -3.10578930e+09\n",
      " -3.20857063e+09 -3.40429048e+09 -3.13997513e+09 -3.78448826e+09\n",
      " -3.60978252e+09 -2.50826913e+09 -3.75028133e+09 -3.16197772e+09\n",
      " -3.69981457e+09 -3.81432746e+09 -3.45087130e+09 -3.64216060e+09\n",
      " -3.76376366e+09 -3.05669800e+09 -2.99206541e+09 -3.95573545e+09\n",
      " -3.47511939e+09 -2.72864612e+09 -2.77644024e+09 -3.65500343e+09\n",
      " -3.66474247e+09 -2.89043838e+09 -3.90508561e+09 -3.70154912e+09\n",
      " -3.83075851e+09 -3.10074344e+09 -3.72325681e+09 -3.33206665e+09\n",
      " -3.46023990e+09 -2.92843076e+09 -2.91719655e+09 -3.96509579e+09\n",
      " -3.39081197e+09 -2.49839057e+09 -3.56316285e+09 -3.25334408e+09\n",
      " -3.76333070e+09 -2.95182381e+09 -3.35761537e+09 -3.61860234e+09\n",
      " -3.80958173e+09 -3.20239502e+09 -3.58034876e+09 -3.79839666e+09\n",
      " -3.69591929e+09 -3.62784277e+09 -3.55211564e+09 -3.59804797e+09\n",
      " -3.60687521e+09 -3.73174140e+09 -3.41701939e+09 -3.31131113e+09\n",
      " -3.34333482e+09 -3.21548760e+09 -3.75196647e+09 -3.58033618e+09\n",
      " -3.49418855e+09 -3.16675168e+09 -3.29173022e+09 -3.38830356e+09\n",
      " -3.81716939e+09 -3.42637989e+09 -3.61270129e+09 -3.40418318e+09\n",
      " -3.47564523e+09 -3.79968000e+09 -3.78498126e+09 -3.84583513e+09]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-5.13328242e+09 -7.66569018e+09 -5.29907931e+09 -5.65279164e+09\n",
      " -5.70807651e+09 -7.90527107e+09 -5.29934000e+09 -7.64450637e+09\n",
      " -6.81323125e+09 -5.94557041e+09 -7.90813851e+09 -5.77027423e+09\n",
      " -5.14731680e+09 -5.76672232e+09 -7.53453958e+09 -9.28331330e+09\n",
      " -6.15170444e+09 -5.70334974e+09 -9.83083306e+09 -5.18482312e+09\n",
      " -5.05140307e+09 -6.42524069e+09 -4.94663546e+09 -1.53012678e+10\n",
      " -6.29876468e+09 -1.17454401e+10 -5.80312461e+09 -6.00079343e+09\n",
      " -7.10241543e+09 -5.27044321e+09 -5.79165127e+09 -6.28791299e+09\n",
      " -4.85550421e+09 -5.02064296e+09 -8.14187331e+09 -1.33039547e+10\n",
      " -6.58245223e+09 -1.41488070e+10 -5.18212569e+09 -9.61159724e+09\n",
      " -7.76959740e+09 -5.52038829e+09 -6.96380057e+09 -5.50317946e+09\n",
      " -6.44645606e+09             nan -8.14212251e+09 -6.47854936e+09\n",
      " -7.91480895e+09 -6.72184996e+09 -6.59805968e+09 -7.87268246e+09\n",
      " -7.52772831e+09 -5.40082123e+09 -5.09089076e+09 -6.25288645e+09\n",
      " -1.08944151e+10 -6.81748484e+09 -5.78905084e+09 -1.63524923e+10\n",
      " -4.89181396e+09 -6.96893253e+09 -1.41164245e+10 -7.44933142e+09\n",
      " -5.14932482e+09 -4.98051864e+09 -8.33217872e+09 -4.79120571e+09\n",
      " -5.50927742e+09 -6.26984601e+09 -8.69423653e+09 -5.34254399e+09\n",
      " -7.47524649e+09 -4.89916119e+09 -7.49766403e+09 -1.02931973e+10\n",
      " -6.30093841e+09 -5.00387083e+09 -8.55706867e+09 -5.36412112e+09\n",
      " -7.68350289e+09 -5.09897411e+09 -7.60193151e+09 -1.15637944e+10\n",
      " -5.59946433e+09 -4.90963515e+09 -6.85695886e+09 -4.84398460e+09\n",
      " -8.51188744e+09 -6.06299394e+09 -5.13741627e+09 -1.01994823e+10\n",
      " -8.01849282e+09 -1.50586475e+10 -5.37089790e+09 -9.04857323e+09\n",
      " -7.21795081e+09 -1.32375300e+10 -1.37767880e+10 -5.29301233e+09\n",
      " -5.11604013e+09             nan -5.56785665e+09 -1.06943657e+10\n",
      " -4.96437148e+09 -5.39021324e+09 -7.99919136e+09 -6.18596116e+09\n",
      " -7.22833447e+09 -4.91396586e+09 -1.59932302e+10 -1.20551020e+10\n",
      " -4.82219484e+09 -6.06093074e+09 -5.67147820e+09 -6.13502747e+09\n",
      " -9.70498687e+09 -4.81179924e+09 -1.51193716e+10 -6.29585311e+09\n",
      " -1.52092899e+10 -4.97857062e+09 -9.28287267e+09 -4.96204724e+09\n",
      " -6.75327785e+09 -7.36750230e+09 -5.28280790e+09 -1.46922852e+10\n",
      " -8.13157414e+09 -1.19434216e+10 -5.18132501e+09 -4.86492325e+09\n",
      " -5.69500980e+09 -8.17945950e+09 -7.50442896e+09 -6.48559155e+09\n",
      " -1.49068705e+10 -5.22286955e+09 -5.27922540e+09 -4.97734720e+09\n",
      " -4.80419135e+09 -1.09454893e+10 -1.27825822e+10 -7.33448218e+09\n",
      " -1.13733323e+10 -9.31515719e+09 -1.15146320e+10 -1.38654403e+10\n",
      " -7.24601460e+09 -9.40955680e+09 -1.47007821e+10 -1.39803224e+10\n",
      " -1.10466303e+10 -6.62600098e+09 -5.23902351e+09 -6.36769215e+09\n",
      " -6.55048392e+09 -1.10055381e+10 -1.11534874e+10 -5.78340543e+09\n",
      " -1.55686415e+10 -4.87400666e+09 -1.06438983e+10 -9.36219761e+09\n",
      " -1.55544464e+10 -8.92945780e+09 -7.47238591e+09 -6.14428428e+09\n",
      " -7.84936874e+09 -5.76386399e+09 -8.24942622e+09 -7.18288857e+09\n",
      " -6.14642658e+09 -6.08448874e+09 -6.81414890e+09 -1.14420439e+10\n",
      " -5.59054426e+09 -8.14954066e+09 -7.07868899e+09 -5.37951023e+09\n",
      " -5.20490018e+09 -5.08067058e+09 -8.52978517e+09 -5.41050593e+09\n",
      " -6.65790952e+09 -5.39008300e+09 -9.02494737e+09 -4.97217136e+09\n",
      " -5.24600921e+09 -5.00117913e+09 -1.28707170e+10 -6.88701040e+09\n",
      " -5.05760003e+09 -8.01817849e+09 -4.92620371e+09 -9.04670047e+09\n",
      " -5.16605723e+09 -6.55413619e+09 -7.25691662e+09 -1.05447072e+10\n",
      " -5.55448137e+09 -4.95621385e+09 -4.80561945e+09 -5.43716063e+09\n",
      " -5.26274883e+09 -1.09759537e+10 -5.45301461e+09 -6.93901572e+09\n",
      " -6.55518138e+09 -9.55928135e+09 -5.45304281e+09 -6.59962276e+09\n",
      " -1.42415232e+10 -5.01561575e+09 -5.36273278e+09 -6.01177701e+09\n",
      " -6.35951430e+09 -5.56646358e+09 -4.81232053e+09 -5.48664658e+09\n",
      " -5.83954411e+09 -4.97011251e+09 -1.57013434e+10 -4.96974670e+09\n",
      " -5.18513186e+09 -1.25337787e+10 -7.00917402e+09 -4.89595173e+09\n",
      " -1.27922694e+10 -9.50838985e+09 -5.70899495e+09 -8.44705760e+09\n",
      " -5.12761741e+09 -4.92751264e+09 -8.77979817e+09 -8.56354681e+09\n",
      " -5.91285102e+09 -4.77186161e+09 -4.97204895e+09 -5.01155645e+09\n",
      " -1.06172924e+10 -6.04288222e+09 -1.01921046e+10 -5.58138797e+09\n",
      " -4.90080346e+09 -1.56429541e+10 -4.90308170e+09 -1.63551808e+10\n",
      " -8.76329370e+09 -7.60749286e+09 -7.13011276e+09 -4.87395042e+09\n",
      " -5.22408453e+09 -5.68951350e+09 -5.24095332e+09 -7.50469607e+09\n",
      " -4.95337927e+09 -7.01749815e+09 -1.10955999e+10 -6.23347953e+09\n",
      " -5.42706212e+09 -4.79570147e+09 -6.83203787e+09 -7.56207505e+09\n",
      " -5.41809266e+09 -1.62188688e+10 -5.01656509e+09 -5.30772199e+09\n",
      " -8.97382796e+09 -6.02011528e+09 -7.34245549e+09 -6.83281631e+09\n",
      " -8.52113644e+09 -4.98952626e+09 -8.48702812e+09 -5.18325113e+09\n",
      " -7.26801137e+09 -1.18367620e+10 -8.28671777e+09 -5.71581331e+09\n",
      " -4.96966412e+09 -5.45588600e+09 -5.29118762e+09 -1.07061964e+10\n",
      " -5.32796703e+09 -5.66626526e+09 -1.39754390e+10 -9.55180664e+09\n",
      " -8.01179105e+09 -1.07302389e+10 -7.09642893e+09 -5.73289982e+09\n",
      " -6.28980345e+09 -1.17959740e+10 -4.99524684e+09 -5.85927781e+09\n",
      " -5.46433303e+09 -5.71581454e+09 -5.68540029e+09 -1.10083061e+10\n",
      " -6.27825465e+09 -7.45378599e+09 -6.54878500e+09 -5.46091451e+09\n",
      " -5.51891256e+09 -5.06991585e+09 -1.30971566e+10 -1.09936097e+10\n",
      " -1.24832973e+10 -4.86233891e+09 -5.99921466e+09 -1.05189843e+10\n",
      " -5.07618023e+09 -6.06876077e+09 -5.82193788e+09 -5.49939520e+09\n",
      " -1.27510179e+10 -6.91974872e+09             nan -5.08243174e+09\n",
      " -1.46286052e+10 -5.46715077e+09 -1.27465329e+10 -7.83785915e+09\n",
      " -5.72732700e+09 -5.97307448e+09 -1.47036649e+10 -4.92353187e+09\n",
      " -8.52359841e+09 -6.96351557e+09 -1.58592443e+10 -7.86410126e+09\n",
      " -1.26184631e+10 -5.81295236e+09 -7.30504076e+09 -7.55136651e+09\n",
      " -5.17160833e+09 -6.22927140e+09 -5.13607421e+09 -5.26298242e+09\n",
      " -4.85110193e+09 -5.89645138e+09 -1.28480094e+10 -5.12587930e+09\n",
      " -8.29601025e+09 -6.97143467e+09 -8.38970119e+09 -9.00078583e+09\n",
      " -4.85359235e+09 -7.96177109e+09 -4.92820049e+09 -4.89154340e+09\n",
      " -4.82781003e+09             nan -5.34164158e+09 -6.12246320e+09\n",
      " -5.05068878e+09 -5.52486918e+09 -1.26917518e+10 -6.36594652e+09\n",
      " -7.70911570e+09 -4.85640266e+09 -6.39206060e+09 -1.43270789e+10\n",
      " -5.87018286e+09 -6.74616945e+09 -6.67719301e+09 -8.94122886e+09\n",
      " -5.00523599e+09 -7.30092056e+09 -5.71655567e+09 -6.28963498e+09\n",
      " -5.48747046e+09 -9.97426436e+09 -6.13518525e+09 -6.80858076e+09\n",
      " -7.81792807e+09 -8.28189402e+09 -1.12135139e+10 -7.87300976e+09\n",
      " -6.70064686e+09 -1.36625284e+10 -5.50862790e+09 -1.24123927e+10\n",
      " -8.49797727e+09 -4.88513606e+09 -1.05634760e+10 -5.07471885e+09\n",
      " -6.04455484e+09 -6.75001040e+09 -5.25120683e+09 -7.49982531e+09\n",
      " -1.13370812e+10 -6.90834107e+09 -7.88561526e+09 -6.32477699e+09\n",
      " -5.47877309e+09 -5.70141706e+09 -5.46200801e+09 -5.81787037e+09\n",
      " -6.57509013e+09 -1.54986029e+10 -5.30520347e+09 -1.62656321e+10\n",
      " -7.37008044e+09 -5.36233033e+09 -1.45825710e+10 -1.04956266e+10\n",
      " -6.74824529e+09 -5.09260565e+09 -8.63871030e+09 -1.29507508e+10\n",
      " -8.04830098e+09 -1.15178565e+10 -1.06596931e+10 -1.23668639e+10\n",
      " -5.55965994e+09 -5.15254331e+09 -6.42727705e+09 -5.15516942e+09\n",
      " -5.35012105e+09 -5.97742852e+09 -5.58715542e+09 -6.01035745e+09\n",
      " -7.31015198e+09 -8.49514834e+09 -4.89232531e+09 -5.22555880e+09\n",
      " -5.46646340e+09 -8.25134934e+09 -1.25873806e+10 -7.28216774e+09\n",
      " -1.25316528e+10 -5.00719253e+09 -5.58179631e+09 -9.99732476e+09\n",
      " -5.42497701e+09 -1.28636667e+10 -5.29523046e+09 -8.37887992e+09\n",
      " -6.21322822e+09 -9.45397547e+09 -6.97574328e+09 -5.03156752e+09\n",
      " -7.43349529e+09 -5.71289372e+09 -5.75349879e+09 -6.58935652e+09\n",
      " -1.29767126e+10 -5.44232706e+09 -4.90744722e+09 -6.15697146e+09\n",
      " -4.81103775e+09 -9.77519392e+09 -7.94629835e+09 -8.27642380e+09\n",
      " -5.39269229e+09 -5.86170521e+09 -6.16330496e+09 -5.87343900e+09\n",
      " -5.22858635e+09 -5.63684640e+09 -6.97424941e+09 -5.25540557e+09\n",
      " -4.98269880e+09 -5.43535099e+09 -5.28105690e+09 -1.17691477e+10\n",
      " -5.23478643e+09 -1.28727670e+10 -6.38524597e+09 -5.14771898e+09\n",
      " -8.62992912e+09 -7.54991614e+09 -5.41990981e+09 -8.50227267e+09\n",
      " -5.15331689e+09 -4.96380717e+09 -6.67162979e+09 -7.23428335e+09\n",
      " -1.51868632e+10 -6.01927888e+09 -5.84788602e+09 -5.56817649e+09\n",
      " -5.81962549e+09 -6.35150138e+09 -7.32477148e+09 -5.01068704e+09\n",
      " -5.34298014e+09 -8.63089591e+09 -6.60678907e+09 -1.21381659e+10\n",
      " -5.24453830e+09 -6.87724554e+09 -4.80521798e+09 -5.24496772e+09\n",
      " -5.19766163e+09 -5.18693573e+09 -5.21823619e+09 -1.51704442e+10\n",
      " -9.88987220e+09 -7.62861912e+09 -5.15636208e+09 -6.67360616e+09\n",
      " -5.10737215e+09 -5.27042495e+09 -1.03608264e+10 -1.47751302e+10\n",
      " -5.42038273e+09 -1.40642655e+10 -8.02906479e+09 -5.41281114e+09\n",
      " -9.22159121e+09 -5.55138869e+09             nan -5.64076706e+09\n",
      " -1.01304853e+10 -7.00976360e+09 -4.95633889e+09 -4.89329645e+09\n",
      " -8.55369111e+09 -5.18208497e+09 -5.17629022e+09 -7.67234225e+09\n",
      " -8.89184392e+09 -4.90477054e+09 -5.08542866e+09 -4.89487077e+09\n",
      " -6.33276848e+09 -7.46503984e+09 -1.01517927e+10 -6.46928214e+09\n",
      " -8.97917408e+09 -5.25624650e+09 -4.86128266e+09 -8.36198979e+09\n",
      " -1.58794157e+10             nan -5.05100806e+09 -7.23262127e+09\n",
      " -7.04155317e+09 -4.96627370e+09 -5.05921581e+09 -1.34529355e+10\n",
      " -6.20076793e+09 -6.81695036e+09 -8.76101771e+09 -9.30445618e+09\n",
      " -4.95158306e+09 -5.37951696e+09 -8.22873561e+09 -6.69093854e+09\n",
      " -7.25428835e+09 -7.70575232e+09 -7.08699456e+09 -1.10386005e+10\n",
      " -6.87826460e+09 -8.84440118e+09 -5.52677117e+09 -7.80005677e+09\n",
      " -5.21944519e+09 -1.22822100e+10 -6.27702352e+09 -7.48712076e+09\n",
      " -6.01414161e+09 -8.53427990e+09 -6.90667148e+09 -5.52050041e+09\n",
      " -5.41901469e+09 -7.24955040e+09 -8.81776401e+09 -4.85628697e+09\n",
      " -9.36060824e+09 -1.50443732e+10 -1.40923606e+10 -5.10695843e+09\n",
      " -1.41464837e+10 -1.39634826e+10 -1.26059254e+10 -9.34988689e+09\n",
      " -7.52680958e+09 -7.08296101e+09 -5.65049453e+09 -6.03722936e+09\n",
      " -6.44839392e+09 -1.18335707e+10 -4.97577987e+09 -1.01631779e+10\n",
      " -1.33549488e+10 -5.86253774e+09 -9.16676870e+09 -7.68550976e+09\n",
      " -5.99899257e+09 -1.29993495e+10 -5.02429948e+09 -6.39237409e+09\n",
      " -1.60109331e+10 -1.00640451e+10 -9.53691160e+09 -4.83902241e+09\n",
      " -5.32586962e+09 -5.56635979e+09 -5.20436979e+09 -5.11041420e+09\n",
      " -1.30254792e+10 -1.62171307e+10 -6.45134621e+09 -6.27884098e+09\n",
      " -6.12708411e+09 -6.22402137e+09 -5.08641895e+09 -5.85808604e+09\n",
      " -6.21518927e+09 -6.54783463e+09 -7.15122425e+09 -5.12450551e+09\n",
      " -1.27641075e+10 -1.20191017e+10 -1.26291096e+10 -6.66882320e+09\n",
      " -6.24021281e+09 -6.73545476e+09 -6.39472836e+09 -5.89051433e+09\n",
      " -5.12579597e+09 -5.86783413e+09 -6.88988256e+09 -8.56601686e+09\n",
      " -7.80443057e+09 -4.87735315e+09 -5.65328767e+09 -6.63180716e+09\n",
      " -8.58510655e+09 -5.04959518e+09 -1.23671718e+10 -6.66454584e+09\n",
      " -5.07005200e+09 -1.34905604e+10 -7.08073257e+09             nan\n",
      " -6.71761514e+09 -5.19759080e+09 -5.48661908e+09 -5.06112895e+09\n",
      " -8.17449288e+09 -7.37490858e+09 -4.80743545e+09 -6.09267462e+09\n",
      " -4.95922171e+09 -8.24010657e+09 -8.72483937e+09 -4.98591595e+09\n",
      " -8.70209473e+09 -1.06998402e+10 -6.98719638e+09 -8.13967581e+09\n",
      " -6.58368022e+09 -6.78763472e+09 -4.97606621e+09 -1.24834684e+10\n",
      " -6.59116899e+09 -1.36044996e+10 -4.94588001e+09 -8.44160579e+09\n",
      " -4.89780835e+09 -1.48554001e+10 -5.35761872e+09 -4.88069745e+09\n",
      " -5.81535471e+09 -8.87141192e+09 -5.04351342e+09 -6.12054579e+09\n",
      " -1.09591230e+10 -5.05062681e+09 -7.11202244e+09 -5.85883043e+09\n",
      " -6.49742251e+09 -6.58875951e+09 -6.23494084e+09 -6.37170574e+09\n",
      " -1.29851520e+10 -4.80758314e+09 -1.36299707e+10 -5.22949939e+09\n",
      " -5.26384806e+09 -4.81755001e+09 -1.10189879e+10 -4.94652923e+09\n",
      " -5.10522126e+09 -5.76742792e+09 -4.83767696e+09 -6.24223432e+09\n",
      " -1.03543323e+10 -5.41981944e+09 -8.16845156e+09 -1.41283575e+10\n",
      " -4.81645513e+09 -5.79537745e+09 -1.55246117e+10 -7.05809570e+09\n",
      " -8.72880339e+09 -1.29882934e+10 -1.44658168e+10 -8.40300400e+09\n",
      " -8.70837624e+09 -4.87585694e+09 -6.68678993e+09 -6.57445823e+09\n",
      " -6.45347785e+09 -8.42217525e+09 -5.50312810e+09 -1.15399380e+10\n",
      " -4.89574700e+09 -7.63374253e+09 -5.59626338e+09 -1.26592192e+10\n",
      " -1.53565392e+10 -1.10721342e+10 -9.57129478e+09 -1.27699448e+10\n",
      " -5.75926890e+09 -6.75720335e+09 -6.84698942e+09 -5.74171563e+09\n",
      " -8.60635614e+09 -9.80483292e+09 -5.26744891e+09 -8.86451287e+09\n",
      " -9.77169883e+09 -1.02361333e+10 -4.90530202e+09 -9.85349341e+09\n",
      " -7.38518964e+09 -5.31928692e+09 -1.39026023e+10 -1.03844603e+10\n",
      " -6.51554195e+09 -5.27329563e+09             nan -5.66895371e+09\n",
      " -5.32092733e+09 -6.81480847e+09 -8.32464409e+09 -9.28086892e+09\n",
      " -5.07364346e+09 -4.97943200e+09 -8.18681701e+09 -6.01734110e+09\n",
      " -6.61512923e+09 -4.99161203e+09 -5.28988954e+09 -5.68069004e+09\n",
      " -5.72024184e+09 -9.92950473e+09 -5.58858586e+09 -6.72807928e+09\n",
      " -7.06407864e+09 -5.89955745e+09 -7.39387612e+09 -5.94684053e+09\n",
      " -5.73088646e+09 -4.78838570e+09 -7.91388890e+09 -1.50568661e+10\n",
      " -4.89752577e+09 -1.11280806e+10 -7.96192668e+09 -5.09734597e+09\n",
      " -5.98505659e+09 -5.22516366e+09 -1.21588321e+10 -1.02923794e+10\n",
      " -6.37372904e+09 -4.92154566e+09 -1.01077485e+10 -7.28924423e+09\n",
      " -5.16045120e+09 -8.21685158e+09             nan -6.97265523e+09\n",
      " -4.99077503e+09 -5.80934955e+09 -7.73117202e+09 -5.01212699e+09\n",
      " -6.87396904e+09 -5.84044971e+09 -1.12715210e+10 -6.46175656e+09\n",
      " -8.38629367e+09 -6.37603901e+09 -6.96307808e+09 -1.02974245e+10\n",
      " -5.95230638e+09 -1.01275669e+10 -5.34783994e+09 -5.81480801e+09\n",
      " -8.39060643e+09 -7.54062649e+09 -5.30529093e+09 -6.31768387e+09\n",
      " -5.29631472e+09 -1.12037930e+10 -9.06336110e+09 -1.16765906e+10\n",
      " -5.17928965e+09 -5.81238112e+09 -8.57947115e+09 -6.44520937e+09\n",
      " -4.97893739e+09 -6.44861854e+09 -5.31655573e+09 -9.08132252e+09\n",
      " -8.03540311e+09 -4.90215436e+09 -1.20541622e+10 -8.95402412e+09\n",
      " -8.98419933e+09 -6.13301679e+09 -5.25706774e+09 -8.72125894e+09\n",
      " -7.43821849e+09 -4.89046516e+09 -7.85967466e+09 -8.13958080e+09\n",
      " -1.33729233e+10 -7.94104513e+09 -5.22358320e+09 -7.52899907e+09\n",
      " -5.26820980e+09 -6.35688931e+09 -4.93922229e+09 -4.82320392e+09\n",
      " -4.81241894e+09 -5.32616920e+09 -1.43269651e+10 -6.42345210e+09\n",
      " -6.23279860e+09 -8.50759645e+09 -5.36923964e+09 -1.31011674e+10\n",
      " -5.31823362e+09 -5.42721965e+09 -5.17485219e+09 -1.08332237e+10\n",
      " -1.54907250e+10 -1.17447130e+10 -9.72761028e+09 -1.05578300e+10\n",
      " -1.22213297e+10 -6.14497581e+09 -4.92631789e+09 -6.62656593e+09\n",
      " -5.26165764e+09 -4.94624753e+09 -6.35188926e+09 -1.04969123e+10\n",
      " -4.95843288e+09 -7.88216315e+09 -6.44544333e+09 -7.31504635e+09\n",
      " -4.93618317e+09 -6.53003090e+09 -1.45604408e+10 -7.80098995e+09\n",
      " -1.16065467e+10 -5.13114985e+09 -7.34467747e+09 -5.92920438e+09\n",
      " -1.31033084e+10 -6.69742507e+09 -8.11616069e+09 -8.14773059e+09\n",
      " -8.74977456e+09 -4.96357923e+09 -5.25193587e+09 -8.89632618e+09\n",
      " -8.16896077e+09 -1.54660267e+10 -4.94824219e+09 -7.22483394e+09\n",
      " -8.44630299e+09 -9.32737948e+09 -5.31473999e+09 -6.20994882e+09\n",
      " -1.03239976e+10 -5.85066338e+09 -4.96223007e+09 -8.89798053e+09\n",
      " -6.35598396e+09 -7.60238247e+09 -1.24282802e+10 -6.04095012e+09\n",
      " -6.53037817e+09 -6.75620702e+09 -1.04966318e+10 -7.26303112e+09\n",
      " -8.15670399e+09 -5.01130792e+09 -9.01732335e+09 -1.29869502e+10\n",
      " -1.31184658e+10 -9.75532463e+09 -4.86091083e+09 -6.66205574e+09\n",
      " -1.17815811e+10 -9.19581366e+09 -5.82173267e+09 -9.35367297e+09\n",
      " -7.09736499e+09 -9.15224326e+09 -5.16596952e+09 -1.15331405e+10\n",
      " -5.56304596e+09 -1.29012337e+10 -1.16091539e+10 -7.21562748e+09\n",
      " -4.97319828e+09 -1.10748074e+10 -8.40157116e+09 -7.76437307e+09\n",
      " -1.17879033e+10 -1.13777605e+10 -7.96604255e+09 -6.07172947e+09\n",
      " -1.09966552e+10 -9.69188360e+09 -8.28122351e+09 -6.45486639e+09\n",
      " -6.99272344e+09 -1.06969120e+10 -6.96946500e+09 -9.53941408e+09\n",
      " -8.52048454e+09 -6.90201418e+09 -9.18492487e+09 -5.08334363e+09\n",
      " -5.70287765e+09 -1.58170457e+10 -5.17749385e+09 -8.96457710e+09\n",
      " -5.33953938e+09 -5.01089362e+09 -6.58379471e+09 -5.56123408e+09\n",
      " -5.13876556e+09 -1.00576626e+10 -1.07681402e+10 -4.77553037e+09\n",
      " -6.43006558e+09 -1.37477397e+10 -1.32189092e+10 -5.50808933e+09\n",
      " -5.46989016e+09 -1.19244581e+10 -4.84153695e+09 -5.33403812e+09\n",
      " -4.97479273e+09 -9.58582575e+09 -5.26048458e+09 -7.44645525e+09\n",
      " -6.52475565e+09 -1.14933118e+10 -1.16159787e+10 -4.76524186e+09\n",
      " -6.99884096e+09 -1.58921650e+10 -5.92951917e+09 -8.11343803e+09\n",
      " -5.14009841e+09 -1.12278836e+10 -7.24568596e+09 -5.66320241e+09\n",
      " -5.02177927e+09 -8.57482147e+09 -5.84288281e+09 -5.04826017e+09\n",
      " -5.35322615e+09 -5.62234016e+09 -5.98701291e+09 -5.75672665e+09\n",
      " -5.71578195e+09 -5.23359079e+09 -6.81185087e+09 -7.61283130e+09\n",
      " -7.35938843e+09 -8.45195135e+09 -5.17237307e+09 -5.84349179e+09\n",
      " -6.31262226e+09 -8.91746143e+09 -7.77719877e+09 -7.01583872e+09\n",
      " -5.00449894e+09 -6.74782272e+09 -5.68915003e+09 -6.90399921e+09\n",
      " -6.42786101e+09 -5.04520359e+09 -5.08191831e+09 -4.94378118e+09]\n",
      "  warnings.warn(\n",
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the train scores are non-finite: [-4.24724150e+09 -3.92652952e+09 -4.20854266e+09 -4.14408226e+09\n",
      " -4.13540197e+09 -3.90679188e+09 -4.20845068e+09 -3.92836912e+09\n",
      " -4.00337437e+09 -4.10148145e+09 -3.90666647e+09 -4.12609769e+09\n",
      " -4.24365869e+09 -4.12657209e+09 -3.93765654e+09 -3.80242315e+09\n",
      " -4.07519062e+09 -4.13611892e+09 -3.76497281e+09 -4.23441595e+09\n",
      " -4.26962235e+09 -4.04359774e+09 -4.30300339e+09 -3.52900898e+09\n",
      " -4.05782766e+09 -3.65126027e+09 -4.12128847e+09 -4.09416691e+09\n",
      " -3.97596423e+09 -4.21473814e+09 -4.12296096e+09 -4.05909296e+09\n",
      " -4.33849969e+09 -4.27880199e+09 -3.88776257e+09 -3.58314611e+09\n",
      " -4.02681548e+09 -3.55591137e+09 -4.23501900e+09 -3.77963159e+09\n",
      " -3.91790788e+09 -4.16603739e+09 -3.98905014e+09 -4.16903470e+09\n",
      " -4.04127453e+09             nan -3.88780561e+09 -4.03784284e+09\n",
      " -3.90594541e+09 -4.01246547e+09 -4.02516978e+09 -3.90935931e+09\n",
      " -3.93824864e+09 -4.18798679e+09 -4.25852020e+09 -4.06311013e+09\n",
      " -3.69801429e+09 -4.00299710e+09 -4.12332714e+09 -3.51344667e+09\n",
      " -4.32342382e+09 -3.98839268e+09 -3.55733020e+09 -3.94497471e+09\n",
      " -4.24316169e+09 -4.29149723e+09 -3.87305854e+09 -4.36953179e+09\n",
      " -4.16796821e+09 -4.06115580e+09 -3.84525569e+09 -4.19953498e+09\n",
      " -3.94280249e+09 -4.32051739e+09 -3.94095778e+09 -3.73470170e+09\n",
      " -4.05754185e+09 -4.28398860e+09 -3.85586181e+09 -4.19515955e+09\n",
      " -3.92511181e+09 -4.25628500e+09 -3.93202532e+09 -3.66084010e+09\n",
      " -4.15266685e+09 -4.31648927e+09 -3.99927814e+09 -4.34361281e+09\n",
      " -3.85900871e+09 -4.08619184e+09 -4.24616141e+09 -3.74069875e+09\n",
      " -3.89769561e+09 -3.53369236e+09 -4.19384416e+09 -3.81926274e+09\n",
      " -3.96543262e+09 -3.58552907e+09 -3.56706761e+09 -4.20980341e+09\n",
      " -4.25172157e+09             nan -4.15793069e+09 -3.70985530e+09\n",
      " -4.29686916e+09 -4.19003390e+09 -3.89922966e+09 -4.07104794e+09\n",
      " -3.96444103e+09 -4.31486307e+09 -3.51708749e+09 -3.63596380e+09\n",
      " -4.35376489e+09 -4.08646257e+09 -4.14104645e+09 -4.07719899e+09\n",
      " -3.77332545e+09 -4.35885997e+09 -3.53255267e+09 -4.05816535e+09\n",
      " -3.53063103e+09 -4.29216945e+09 -3.80245702e+09 -4.29769456e+09\n",
      " -4.00944815e+09 -3.95209154e+09 -4.21202818e+09 -3.54190245e+09\n",
      " -3.88875437e+09 -3.64126109e+09 -4.23520603e+09 -4.33446481e+09\n",
      " -4.13739547e+09 -3.88476024e+09 -3.94023832e+09 -4.03702953e+09\n",
      " -3.53693866e+09 -4.22538439e+09 -4.21278828e+09 -4.29252890e+09\n",
      " -4.36270606e+09 -3.69500375e+09 -3.60329271e+09 -3.95524671e+09\n",
      " -3.67130114e+09 -3.80036407e+09 -3.66345693e+09 -3.56436375e+09\n",
      " -3.96304272e+09 -3.79357444e+09 -3.54163077e+09 -3.56079772e+09\n",
      " -3.68923081e+09 -4.02224931e+09 -4.22169503e+09 -4.05001912e+09\n",
      " -4.03011527e+09 -3.69174406e+09 -3.68340003e+09 -4.12414791e+09\n",
      " -3.52392241e+09 -4.33064500e+09 -3.71287278e+09 -3.79702685e+09\n",
      " -3.52417978e+09 -3.82816859e+09 -3.94309975e+09 -4.07608068e+09\n",
      " -3.91136975e+09 -4.12699530e+09 -3.87965407e+09 -3.96859243e+09\n",
      " -4.07581011e+09 -4.08347600e+09 -4.00346374e+09 -3.66758049e+09\n",
      " -4.15409584e+09 -3.88712632e+09 -3.97807828e+09 -4.19210170e+09\n",
      " -4.22957883e+09 -4.26131583e+09 -3.85774286e+09 -4.18609022e+09\n",
      " -4.01900750e+09 -4.19007513e+09 -3.82098625e+09 -4.29426364e+09\n",
      " -4.22015119e+09 -4.28485114e+09 -3.59989064e+09 -3.99631707e+09\n",
      " -4.26783863e+09 -3.89772193e+09 -4.31030023e+09 -3.81933480e+09\n",
      " -4.23899958e+09 -4.02972513e+09 -3.96188901e+09 -3.71903523e+09\n",
      " -4.16015219e+09 -4.29968543e+09 -4.36197869e+09 -4.18107530e+09\n",
      " -4.21637341e+09 -3.69317854e+09 -4.17816700e+09 -3.99125579e+09\n",
      " -4.02960378e+09 -3.78333910e+09 -4.17810340e+09 -4.02508630e+09\n",
      " -3.55346976e+09 -4.28037240e+09 -4.19543114e+09 -4.09272740e+09\n",
      " -4.05088809e+09 -4.15811594e+09 -4.35860701e+09 -4.17201344e+09\n",
      " -4.11605519e+09 -4.29496251e+09 -3.52164472e+09 -4.29508450e+09\n",
      " -4.23428787e+09 -3.61388177e+09 -3.98463057e+09 -4.32179635e+09\n",
      " -3.60287167e+09 -3.78704501e+09 -4.13525960e+09 -3.86418146e+09\n",
      " -4.24870278e+09 -4.30983368e+09 -3.83892025e+09 -3.85516278e+09\n",
      " -4.10587226e+09 -4.38034382e+09 -4.29428832e+09 -4.28159924e+09\n",
      " -3.71451375e+09 -4.08879767e+09 -3.74107900e+09 -4.15562123e+09\n",
      " -4.31988726e+09 -3.52281591e+09 -4.31901694e+09 -3.51344601e+09\n",
      " -3.84050891e+09 -3.93149682e+09 -3.97336291e+09 -4.33065919e+09\n",
      " -4.22515074e+09 -4.13825218e+09 -4.22130346e+09 -3.94038634e+09\n",
      " -4.30066176e+09 -3.98383056e+09 -3.68657976e+09 -4.06539812e+09\n",
      " -4.18295704e+09 -4.36713641e+09 -4.00154156e+09 -3.93525731e+09\n",
      " -4.18467447e+09 -3.51419905e+09 -4.28003396e+09 -4.20670699e+09\n",
      " -3.82464736e+09 -4.09171923e+09 -3.95430706e+09 -4.00154723e+09\n",
      " -3.85844018e+09 -4.28855355e+09 -3.86112810e+09 -4.23474796e+09\n",
      " -3.96099426e+09 -3.64662571e+09 -3.87638789e+09 -4.13420787e+09\n",
      " -4.29508552e+09 -4.17761369e+09 -4.21024651e+09 -3.70909903e+09\n",
      " -4.20250443e+09 -4.14188194e+09 -3.56110327e+09 -3.78389398e+09\n",
      " -3.89830135e+09 -3.70819047e+09 -3.97659438e+09 -4.13166684e+09\n",
      " -4.05888959e+09 -3.64863547e+09 -4.28673731e+09 -4.11328262e+09\n",
      " -4.17601937e+09 -4.13422677e+09 -4.13892216e+09 -3.69130084e+09\n",
      " -4.06022060e+09 -3.94482466e+09 -4.03032443e+09 -4.17665145e+09\n",
      " -4.16627168e+09 -4.26432622e+09 -3.59108944e+09 -3.69215149e+09\n",
      " -3.61623763e+09 -4.33555631e+09 -4.09446806e+09 -3.72082406e+09\n",
      " -4.26259269e+09 -4.08550148e+09 -4.11854689e+09 -4.16971952e+09\n",
      " -3.60480842e+09 -3.99312121e+09             nan -4.26082500e+09\n",
      " -3.54338609e+09 -4.17557776e+09 -3.60476556e+09 -3.91246254e+09\n",
      " -4.13247002e+09 -4.09779081e+09 -3.54160322e+09 -4.31129761e+09\n",
      " -3.85817863e+09 -3.98903396e+09 -3.51910106e+09 -3.91010518e+09\n",
      " -3.61056064e+09 -4.11987981e+09 -3.95770293e+09 -3.93615535e+09\n",
      " -4.23763361e+09 -4.06588341e+09 -4.24653627e+09 -4.21636420e+09\n",
      " -4.34043095e+09 -4.10813139e+09 -3.60076385e+09 -4.24918676e+09\n",
      " -3.87563149e+09 -3.98815009e+09 -3.86849008e+09 -3.82286682e+09\n",
      " -4.33935369e+09 -3.90231408e+09 -4.30960351e+09 -4.32350969e+09\n",
      " -4.35107804e+09             nan -4.19966254e+09 -4.07879642e+09\n",
      " -4.26983555e+09 -4.16530309e+09 -3.60707558e+09 -4.05015572e+09\n",
      " -3.92301291e+09 -4.33811061e+09 -4.04731542e+09 -3.55113722e+09\n",
      " -4.11173489e+09 -4.01009149e+09 -4.01698075e+09 -3.82724777e+09\n",
      " -4.28356972e+09 -3.95798164e+09 -4.13414698e+09 -4.05887501e+09\n",
      " -4.17188335e+09 -3.75574887e+09 -4.07728102e+09 -4.00384721e+09\n",
      " -3.91390887e+09 -3.87683656e+09 -3.67971272e+09 -3.90950921e+09\n",
      " -4.01464383e+09 -3.57106043e+09 -4.16812597e+09 -3.61930478e+09\n",
      " -3.86012855e+09 -4.32609673e+09 -3.71788867e+09 -4.26299513e+09\n",
      " -4.08851443e+09 -4.00981616e+09 -4.21899630e+09 -3.94057021e+09\n",
      " -3.67302357e+09 -3.99434061e+09 -3.90832380e+09 -4.05481199e+09\n",
      " -4.17343691e+09 -4.13640217e+09 -4.17646268e+09 -4.11913754e+09\n",
      " -4.02754380e+09 -3.52517167e+09 -4.20727224e+09 -3.51381936e+09\n",
      " -3.95192301e+09 -4.19551595e+09 -3.54455122e+09 -3.72196070e+09\n",
      " -4.00981701e+09 -4.25804824e+09 -3.84941435e+09 -3.59704597e+09\n",
      " -3.89523274e+09 -3.66309766e+09 -3.71215306e+09 -3.62144970e+09\n",
      " -4.15927925e+09 -4.24233073e+09 -4.04335963e+09 -4.24171104e+09\n",
      " -4.19797581e+09 -4.09726349e+09 -4.15473252e+09 -4.09290874e+09\n",
      " -3.95715222e+09 -3.86043502e+09 -4.32320681e+09 -4.22481870e+09\n",
      " -4.17565639e+09 -3.87937077e+09 -3.61195572e+09 -3.95979405e+09\n",
      " -3.61394150e+09 -4.28294565e+09 -4.15560541e+09 -3.75374932e+09\n",
      " -4.18333177e+09 -3.59996422e+09 -4.20934895e+09 -3.86930966e+09\n",
      " -4.06784683e+09 -3.79046814e+09 -3.98782020e+09 -4.27551233e+09\n",
      " -3.94640505e+09 -4.13469054e+09 -4.12853051e+09 -4.02601675e+09\n",
      " -3.59549569e+09 -4.18007001e+09 -4.31734034e+09 -4.07452583e+09\n",
      " -4.35924901e+09 -3.76887634e+09 -3.90358543e+09 -3.87722497e+09\n",
      " -4.18954000e+09 -4.11299863e+09 -4.07385194e+09 -4.11131487e+09\n",
      " -4.22405911e+09 -4.14656575e+09 -3.98785259e+09 -4.21800148e+09\n",
      " -4.29081498e+09 -4.18137048e+09 -4.21236927e+09 -3.64998946e+09\n",
      " -4.22269015e+09 -3.59959332e+09 -4.04808540e+09 -4.24356094e+09\n",
      " -3.85020811e+09 -3.93637964e+09 -4.18430351e+09 -3.85974019e+09\n",
      " -4.24216681e+09 -4.29710112e+09 -4.01754840e+09 -3.96395316e+09\n",
      " -3.53107947e+09 -4.09178055e+09 -4.11488497e+09 -4.15784048e+09\n",
      " -4.11889471e+09 -4.05182940e+09 -3.95586566e+09 -4.28184880e+09\n",
      " -4.19939268e+09 -3.85016124e+09 -4.02422864e+09 -3.63184727e+09\n",
      " -4.22045863e+09 -3.99714238e+09 -4.36218878e+09 -4.22033919e+09\n",
      " -4.23128875e+09 -4.23386723e+09 -4.22647683e+09 -3.53140485e+09\n",
      " -3.76083311e+09 -3.92966877e+09 -4.24135409e+09 -4.01736057e+09\n",
      " -4.25402794e+09 -4.21471270e+09 -3.73044227e+09 -3.53992276e+09\n",
      " -4.18423055e+09 -3.55833069e+09 -3.89691545e+09 -4.18565788e+09\n",
      " -3.80699307e+09 -4.16066467e+09             nan -4.14591684e+09\n",
      " -3.74504359e+09 -3.98455166e+09 -4.29960969e+09 -4.32284093e+09\n",
      " -3.85586560e+09 -4.23504441e+09 -4.23645215e+09 -3.92621000e+09\n",
      " -3.83060594e+09 -4.31834192e+09 -4.26001669e+09 -4.32219726e+09\n",
      " -4.05389854e+09 -3.94358967e+09 -3.74394405e+09 -4.03885030e+09\n",
      " -3.82423003e+09 -4.21788495e+09 -4.33599433e+09 -3.87050815e+09\n",
      " -3.51874934e+09             nan -4.26975120e+09 -3.96428998e+09\n",
      " -3.98153355e+09 -4.29622898e+09 -4.26736144e+09 -3.57793944e+09\n",
      " -4.06928980e+09 -4.00303172e+09 -3.84029775e+09 -3.80090926e+09\n",
      " -4.30125445e+09 -4.19208957e+09 -3.88092746e+09 -4.01559582e+09\n",
      " -3.96210099e+09 -3.92313535e+09 -3.97742455e+09 -3.69006965e+09\n",
      " -3.99703403e+09 -3.83430029e+09 -4.16495488e+09 -3.91533478e+09\n",
      " -4.22620021e+09 -3.62512554e+09 -4.06036605e+09 -3.94168026e+09\n",
      " -4.09244350e+09 -3.85732163e+09 -3.99438540e+09 -4.16601984e+09\n",
      " -4.18451921e+09 -3.96277301e+09 -3.83636957e+09 -4.33817662e+09\n",
      " -3.79731669e+09 -3.53399449e+09 -3.55756253e+09 -4.25414360e+09\n",
      " -3.55598990e+09 -3.56137696e+09 -3.61075728e+09 -3.79791893e+09\n",
      " -3.93847967e+09 -3.97777399e+09 -4.14435800e+09 -4.08944569e+09\n",
      " -4.04107291e+09 -3.64672390e+09 -4.29305381e+09 -3.74295216e+09\n",
      " -3.58170712e+09 -4.11280353e+09 -3.81069323e+09 -3.92482425e+09\n",
      " -4.09439292e+09 -3.59456567e+09 -4.27769612e+09 -4.04728806e+09\n",
      " -3.51677224e+09 -3.74941228e+09 -3.78488859e+09 -4.34587540e+09\n",
      " -4.20294085e+09 -4.15820932e+09 -4.22970756e+09 -4.25323492e+09\n",
      " -3.59410090e+09 -3.51421364e+09 -4.04075051e+09 -4.06018765e+09\n",
      " -4.07817451e+09 -4.06658125e+09 -4.25974835e+09 -4.11345326e+09\n",
      " -4.06754667e+09 -4.03046851e+09 -3.97161790e+09 -4.24952583e+09\n",
      " -3.60450777e+09 -3.63817378e+09 -3.60972715e+09 -4.01782748e+09\n",
      " -4.06467441e+09 -4.01111995e+09 -4.04694458e+09 -4.10900518e+09\n",
      " -4.24916103e+09 -4.11208119e+09 -3.99591313e+09 -3.85494367e+09\n",
      " -3.91496278e+09 -4.32926565e+09 -4.14397420e+09 -4.02166131e+09\n",
      " -3.85348005e+09 -4.27019177e+09 -3.62138821e+09 -4.01834291e+09\n",
      " -4.26427224e+09 -3.57696808e+09 -3.97804849e+09             nan\n",
      " -4.01290212e+09 -4.23130613e+09 -4.17199928e+09 -4.26684462e+09\n",
      " -3.88514242e+09 -3.95165736e+09 -4.36105862e+09 -4.08246101e+09\n",
      " -4.29864522e+09 -3.88008976e+09 -3.84301424e+09 -4.28973647e+09\n",
      " -3.84473300e+09 -3.70997755e+09 -3.98667091e+09 -3.88791811e+09\n",
      " -4.02662304e+09 -4.00605088e+09 -4.29296114e+09 -3.61622005e+09\n",
      " -4.02587650e+09 -3.57265733e+09 -4.30324692e+09 -3.86439430e+09\n",
      " -4.32106948e+09 -3.53808491e+09 -4.19647972e+09 -4.32789039e+09\n",
      " -4.11948258e+09 -3.83237123e+09 -4.27192666e+09 -4.07904718e+09\n",
      " -3.69423807e+09 -4.26988393e+09 -3.97504999e+09 -4.11341500e+09\n",
      " -4.03584657e+09 -4.02621703e+09 -4.06520664e+09 -4.04951805e+09\n",
      " -3.59524891e+09 -4.36098589e+09 -3.57183936e+09 -4.22386406e+09\n",
      " -4.21613324e+09 -4.35602837e+09 -3.69120548e+09 -4.30302171e+09\n",
      " -4.25460593e+09 -4.12653685e+09 -4.34648563e+09 -4.06437771e+09\n",
      " -3.73080367e+09 -4.18431869e+09 -3.88574808e+09 -3.55668093e+09\n",
      " -4.35655764e+09 -4.12244462e+09 -3.52471882e+09 -3.98017902e+09\n",
      " -3.84308959e+09 -3.59513282e+09 -3.54740567e+09 -3.86752197e+09\n",
      " -3.84428947e+09 -4.32986489e+09 -4.01614307e+09 -4.02764651e+09\n",
      " -4.04051658e+09 -3.86590083e+09 -4.16910027e+09 -3.66196168e+09\n",
      " -4.32185204e+09 -3.92941753e+09 -4.15316266e+09 -3.60847767e+09\n",
      " -3.52778505e+09 -3.68784060e+09 -3.78256428e+09 -3.60384366e+09\n",
      " -4.12770894e+09 -4.00894338e+09 -4.00009627e+09 -4.13034695e+09\n",
      " -3.85214547e+09 -3.76648938e+09 -4.21537493e+09 -3.83291275e+09\n",
      " -3.76911919e+09 -3.73832327e+09 -4.31813834e+09 -3.76323048e+09\n",
      " -3.95064717e+09 -4.20425237e+09 -3.56323810e+09 -3.72899748e+09\n",
      " -4.03383524e+09 -4.21406433e+09             nan -4.14147619e+09\n",
      " -4.20392991e+09 -4.00331805e+09 -3.87341044e+09 -3.80266060e+09\n",
      " -4.26331040e+09 -4.29184223e+09 -3.88419089e+09 -4.09206802e+09\n",
      " -4.02333993e+09 -4.28792005e+09 -4.21047060e+09 -4.13968757e+09\n",
      " -4.13355132e+09 -3.75818852e+09 -4.15447840e+09 -4.01182930e+09\n",
      " -3.97948954e+09 -4.10771384e+09 -3.95000112e+09 -4.10135483e+09\n",
      " -4.13192400e+09 -4.37105282e+09 -3.90619345e+09 -3.53383314e+09\n",
      " -4.32117284e+09 -3.68462224e+09 -3.90211342e+09 -4.25673131e+09\n",
      " -4.09625830e+09 -4.22486374e+09 -3.63141774e+09 -3.73482383e+09\n",
      " -4.04929984e+09 -4.31202792e+09 -3.74652552e+09 -3.95897929e+09\n",
      " -4.24034494e+09 -3.88191158e+09             nan -3.98804470e+09\n",
      " -4.28817117e+09 -4.12035498e+09 -3.92111543e+09 -4.28141663e+09\n",
      " -3.99752992e+09 -4.11597025e+09 -3.67654184e+09 -4.03960725e+09\n",
      " -3.86885700e+09 -4.04909777e+09 -3.98892679e+09 -3.73441550e+09\n",
      " -4.10063907e+09 -3.74528137e+09 -4.19839534e+09 -4.11966017e+09\n",
      " -3.86855511e+09 -3.93714734e+09 -4.20719447e+09 -4.05566602e+09\n",
      " -4.20909867e+09 -3.68023045e+09 -3.81853197e+09 -3.65498309e+09\n",
      " -4.23574052e+09 -4.11992743e+09 -3.85387437e+09 -4.04140034e+09\n",
      " -4.29201668e+09 -4.04110589e+09 -4.20482885e+09 -3.81717452e+09\n",
      " -3.89630188e+09 -4.31935579e+09 -3.63588517e+09 -3.82645435e+09\n",
      " -3.82389587e+09 -4.07745175e+09 -4.21766948e+09 -3.84341099e+09\n",
      " -3.94593162e+09 -4.32395005e+09 -3.91060216e+09 -3.88816480e+09\n",
      " -3.58063415e+09 -3.90383754e+09 -4.22525096e+09 -3.93827043e+09\n",
      " -4.21523681e+09 -4.05119139e+09 -4.30562279e+09 -4.35327515e+09\n",
      " -4.35856007e+09 -4.20288731e+09 -3.55126196e+09 -4.04390080e+09\n",
      " -4.06551700e+09 -3.85936054e+09 -4.19410668e+09 -3.59062796e+09\n",
      " -4.20451513e+09 -4.18291053e+09 -4.23678680e+09 -3.70160989e+09\n",
      " -3.52531789e+09 -3.65144663e+09 -3.77169267e+09 -3.71847204e+09\n",
      " -3.62798140e+09 -4.07603827e+09 -4.31029700e+09 -4.02219064e+09\n",
      " -4.21663784e+09 -4.30312002e+09 -4.05173504e+09 -3.72232007e+09\n",
      " -4.29890375e+09 -3.90865154e+09 -4.04138581e+09 -3.95673078e+09\n",
      " -4.30670894e+09 -4.03232073e+09 -3.54501286e+09 -3.91540662e+09\n",
      " -3.65851858e+09 -4.24780841e+09 -3.95429692e+09 -4.10364677e+09\n",
      " -3.59060555e+09 -4.01498252e+09 -3.88987532e+09 -3.88754358e+09\n",
      " -3.84139102e+09 -4.29716268e+09 -4.21879295e+09 -3.83057084e+09\n",
      " -3.88573525e+09 -3.52576202e+09 -4.30245049e+09 -3.96490831e+09\n",
      " -3.86403856e+09 -3.79937951e+09 -4.20520105e+09 -4.06816106e+09\n",
      " -3.73269513e+09 -4.11447451e+09 -4.29762917e+09 -3.83018514e+09\n",
      " -4.05138392e+09 -3.93183596e+09 -3.61863760e+09 -4.08897688e+09\n",
      " -4.03227101e+09 -4.00900858e+09 -3.72191842e+09 -3.96132706e+09\n",
      " -3.88677725e+09 -4.28170039e+09 -3.82153536e+09 -3.59551745e+09\n",
      " -3.59002685e+09 -3.76988898e+09 -4.33617875e+09 -4.01862339e+09\n",
      " -3.64952968e+09 -3.80862078e+09 -4.11857172e+09 -3.79755358e+09\n",
      " -3.97638759e+09 -3.81176849e+09 -4.23897905e+09 -3.66228167e+09\n",
      " -4.15872383e+09 -3.59904467e+09 -3.65872762e+09 -3.96557489e+09\n",
      " -4.29394902e+09 -3.68784326e+09 -3.86770231e+09 -3.91847971e+09\n",
      " -3.64933902e+09 -3.67066358e+09 -3.90182840e+09 -4.08514525e+09\n",
      " -3.69224736e+09 -3.77416878e+09 -3.87685581e+09 -4.04033882e+09\n",
      " -3.98627989e+09 -3.70974097e+09 -3.98835191e+09 -3.78484401e+09\n",
      " -3.85859182e+09 -3.99481041e+09 -3.80946388e+09 -4.26060609e+09\n",
      " -4.13622144e+09 -3.51973872e+09 -4.23617621e+09 -3.82529762e+09\n",
      " -4.20009428e+09 -4.28181405e+09 -4.02660102e+09 -4.15904264e+09\n",
      " -4.24583244e+09 -3.74998768e+09 -3.70558292e+09 -4.37822319e+09\n",
      " -4.04309779e+09 -3.56798033e+09 -3.58621553e+09 -4.16818204e+09\n",
      " -4.17505719e+09 -3.64240735e+09 -4.34472756e+09 -4.20127936e+09\n",
      " -4.29340406e+09 -3.78133476e+09 -4.21687209e+09 -3.94528686e+09\n",
      " -4.03290570e+09 -3.66475429e+09 -3.65803338e+09 -4.38424770e+09\n",
      " -3.98560734e+09 -3.51868929e+09 -4.10365612e+09 -3.89029787e+09\n",
      " -4.24550890e+09 -3.67930446e+09 -3.96290027e+09 -4.14240618e+09\n",
      " -4.27845768e+09 -3.85425641e+09 -4.11561614e+09 -4.27053601e+09\n",
      " -4.19731530e+09 -4.14892672e+09 -4.09600592e+09 -4.12804457e+09\n",
      " -4.13421638e+09 -4.22292994e+09 -4.00352059e+09 -3.93096109e+09\n",
      " -3.95300669e+09 -3.86359817e+09 -4.23740299e+09 -4.11556507e+09\n",
      " -4.05619362e+09 -3.82872975e+09 -3.91730713e+09 -3.98393129e+09\n",
      " -4.28381911e+09 -4.00988447e+09 -4.13830763e+09 -3.99469674e+09\n",
      " -4.04339563e+09 -4.27144051e+09 -4.26097618e+09 -4.30398954e+09]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_modelo__alpha</th>\n",
       "      <th>param_modelo__l1_ratio</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>9.818287</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>-5.625082e+09</td>\n",
       "      <td>4.398817e+09</td>\n",
       "      <td>-3.965096e+09</td>\n",
       "      <td>7.262548e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>9.990184</td>\n",
       "      <td>0.05921</td>\n",
       "      <td>-5.651473e+09</td>\n",
       "      <td>4.442843e+09</td>\n",
       "      <td>-3.959022e+09</td>\n",
       "      <td>7.260700e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>9.663854</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>-5.665874e+09</td>\n",
       "      <td>4.466946e+09</td>\n",
       "      <td>-3.955735e+09</td>\n",
       "      <td>7.259637e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9.557926</td>\n",
       "      <td>0.063832</td>\n",
       "      <td>-5.714966e+09</td>\n",
       "      <td>4.549601e+09</td>\n",
       "      <td>-3.944703e+09</td>\n",
       "      <td>7.255771e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_modelo__alpha param_modelo__l1_ratio  mean_test_score  \\\n",
       "963            9.818287               0.022513    -5.625082e+09   \n",
       "237            9.990184                0.05921    -5.651473e+09   \n",
       "947            9.663854               0.038339    -5.665874e+09   \n",
       "761            9.557926               0.063832    -5.714966e+09   \n",
       "\n",
       "     std_test_score  mean_train_score  std_train_score  \n",
       "963    4.398817e+09     -3.965096e+09     7.262548e+08  \n",
       "237    4.442843e+09     -3.959022e+09     7.260700e+08  \n",
       "947    4.466946e+09     -3.955735e+09     7.259637e+08  \n",
       "761    4.549601e+09     -3.944703e+09     7.255771e+08  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Espacio de búsqueda de cada hiperparámetro\n",
    "# ==============================================================================\n",
    "param_distributions = {\n",
    "    'modelo__alpha': uniform(0.001, 10) ,\n",
    "    'modelo__l1_ratio' : uniform(0.019, 0.99)\n",
    "}\n",
    "\n",
    "# Se combinan los pasos de preprocesado y el modelo en un mismo pipeline\n",
    "ENX = Pipeline([('preprocessing', preprocessorX),\n",
    "                 ('modelo', ElasticNet(random_state=123))])\n",
    "\n",
    "ENZ = Pipeline([('preprocessing', preprocessorZ),\n",
    "                 ('modelo', ElasticNet(random_state=123))])\n",
    "\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "# ==============================================================================\n",
    "gridX = RandomizedSearchCV(\n",
    "        estimator  = ENX,\n",
    "        param_distributions = param_distributions,\n",
    "        n_iter     = 1000,\n",
    "        scoring    = 'neg_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123),  \n",
    "        verbose    = 4,\n",
    "        random_state = 123,\n",
    "        return_train_score = True\n",
    "       )\n",
    "gridZ = RandomizedSearchCV(\n",
    "        estimator  = ENZ,\n",
    "        param_distributions = param_distributions,\n",
    "        n_iter     = 1000,\n",
    "        scoring    = 'neg_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123),  \n",
    "        verbose    = 4,\n",
    "        random_state = 123,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridX.fit(X = X_train, y = y_train)\n",
    "gridZ.fit(X = Z_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e683075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final_ENX = gridX.best_estimator_\n",
    "modelo_final_ENZ = gridZ.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2511732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5405324228832.488, tolerance: 1998996785.7667134\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_modelo__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.001819</td>\n",
       "      <td>-2.070410e+11</td>\n",
       "      <td>3.663949e+11</td>\n",
       "      <td>-2.395520e+09</td>\n",
       "      <td>2.539667e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>0.021919</td>\n",
       "      <td>-2.070425e+11</td>\n",
       "      <td>3.663816e+11</td>\n",
       "      <td>-2.395522e+09</td>\n",
       "      <td>2.539672e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.027881</td>\n",
       "      <td>-2.070429e+11</td>\n",
       "      <td>3.663777e+11</td>\n",
       "      <td>-2.395522e+09</td>\n",
       "      <td>2.539673e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.036322</td>\n",
       "      <td>-2.070435e+11</td>\n",
       "      <td>3.663721e+11</td>\n",
       "      <td>-2.395523e+09</td>\n",
       "      <td>2.539675e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_modelo__alpha  mean_test_score  std_test_score  mean_train_score  \\\n",
       "494            0.001819    -2.070410e+11    3.663949e+11     -2.395520e+09   \n",
       "671            0.021919    -2.070425e+11    3.663816e+11     -2.395522e+09   \n",
       "118            0.027881    -2.070429e+11    3.663777e+11     -2.395522e+09   \n",
       "320            0.036322    -2.070435e+11    3.663721e+11     -2.395523e+09   \n",
       "\n",
       "     std_train_score  \n",
       "494     2.539667e+08  \n",
       "671     2.539672e+08  \n",
       "118     2.539673e+08  \n",
       "320     2.539675e+08  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Espacio de búsqueda de cada hiperparámetro\n",
    "# ==============================================================================\n",
    "param_distributions = {\n",
    "    'modelo__alpha': uniform(0.001, 10)\n",
    "}\n",
    "\n",
    "# Se combinan los pasos de preprocesado y el modelo en un mismo pipeline\n",
    "LASSOX = Pipeline([('preprocessing', preprocessorX),\n",
    "                 ('modelo', Lasso(random_state=123))])\n",
    "\n",
    "LASSOZ = Pipeline([('preprocessing', preprocessorZ),\n",
    "                 ('modelo', ElasticNet(random_state=123))])\n",
    "\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "# ==============================================================================\n",
    "gridX = RandomizedSearchCV(\n",
    "        estimator  = LASSOX,\n",
    "        param_distributions = param_distributions,\n",
    "        n_iter     = 1000,\n",
    "        scoring    = 'neg_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123),  \n",
    "        verbose    = 4,\n",
    "        random_state = 123,\n",
    "        return_train_score = True\n",
    "       )\n",
    "gridZ = RandomizedSearchCV(\n",
    "        estimator  = LASSOZ,\n",
    "        param_distributions = param_distributions,\n",
    "        n_iter     = 1000,\n",
    "        scoring    = 'neg_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123),  \n",
    "        verbose    = 4,\n",
    "        random_state = 123,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridX.fit(X = X_train, y = y_train)\n",
    "gridZ.fit(X = Z_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e5f6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final_LASSOX = gridX.best_estimator_\n",
    "modelo_final_LASSOZ = gridZ.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3eb4209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1000 candidates, totalling 15000 fits\n",
      "Fitting 15 folds for each of 1000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_modelo__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>9.990184</td>\n",
       "      <td>-2.291501e+11</td>\n",
       "      <td>3.767050e+11</td>\n",
       "      <td>-2.435820e+09</td>\n",
       "      <td>2.684508e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>9.961863</td>\n",
       "      <td>-2.292111e+11</td>\n",
       "      <td>3.767843e+11</td>\n",
       "      <td>-2.435721e+09</td>\n",
       "      <td>2.684155e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>9.959611</td>\n",
       "      <td>-2.292159e+11</td>\n",
       "      <td>3.767906e+11</td>\n",
       "      <td>-2.435713e+09</td>\n",
       "      <td>2.684127e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>9.958818</td>\n",
       "      <td>-2.292176e+11</td>\n",
       "      <td>3.767928e+11</td>\n",
       "      <td>-2.435711e+09</td>\n",
       "      <td>2.684117e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_modelo__alpha  mean_test_score  std_test_score  mean_train_score  \\\n",
       "474            9.990184    -2.291501e+11    3.767050e+11     -2.435820e+09   \n",
       "203            9.961863    -2.292111e+11    3.767843e+11     -2.435721e+09   \n",
       "637            9.959611    -2.292159e+11    3.767906e+11     -2.435713e+09   \n",
       "696            9.958818    -2.292176e+11    3.767928e+11     -2.435711e+09   \n",
       "\n",
       "     std_train_score  \n",
       "474     2.684508e+08  \n",
       "203     2.684155e+08  \n",
       "637     2.684127e+08  \n",
       "696     2.684117e+08  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se combinan los pasos de preprocesado y el modelo en un mismo pipeline\n",
    "RIDGEX = Pipeline([('preprocessing', preprocessorX),\n",
    "                 ('modelo', Ridge())])\n",
    "\n",
    "RIDGEZ = Pipeline([('preprocessing', preprocessorZ),\n",
    "                 ('modelo', Ridge())])\n",
    "\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "# ==============================================================================\n",
    "gridX = RandomizedSearchCV(\n",
    "        estimator  = RIDGEX,\n",
    "        param_distributions = param_distributions,\n",
    "        n_iter     = 1000,\n",
    "        scoring    = 'neg_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123),  \n",
    "        verbose    = 4,\n",
    "        random_state = 123,\n",
    "        return_train_score = True\n",
    "       )\n",
    "# ==============================================================================\n",
    "gridZ = RandomizedSearchCV(\n",
    "        estimator  = RIDGEZ,\n",
    "        param_distributions = param_distributions,\n",
    "        n_iter     = 1000,\n",
    "        scoring    = 'neg_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123),  \n",
    "        verbose    = 4,\n",
    "        random_state = 123,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridX.fit(X = X_train, y = y_train)\n",
    "gridZ.fit(X = Z_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fa661f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_modelo__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>9.990184</td>\n",
       "      <td>-2.291501e+11</td>\n",
       "      <td>3.767050e+11</td>\n",
       "      <td>-2.435820e+09</td>\n",
       "      <td>2.684508e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>9.961863</td>\n",
       "      <td>-2.292111e+11</td>\n",
       "      <td>3.767843e+11</td>\n",
       "      <td>-2.435721e+09</td>\n",
       "      <td>2.684155e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>9.959611</td>\n",
       "      <td>-2.292159e+11</td>\n",
       "      <td>3.767906e+11</td>\n",
       "      <td>-2.435713e+09</td>\n",
       "      <td>2.684127e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>9.958818</td>\n",
       "      <td>-2.292176e+11</td>\n",
       "      <td>3.767928e+11</td>\n",
       "      <td>-2.435711e+09</td>\n",
       "      <td>2.684117e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_modelo__alpha  mean_test_score  std_test_score  mean_train_score  \\\n",
       "474            9.990184    -2.291501e+11    3.767050e+11     -2.435820e+09   \n",
       "203            9.961863    -2.292111e+11    3.767843e+11     -2.435721e+09   \n",
       "637            9.959611    -2.292159e+11    3.767906e+11     -2.435713e+09   \n",
       "696            9.958818    -2.292176e+11    3.767928e+11     -2.435711e+09   \n",
       "\n",
       "     std_train_score  \n",
       "474     2.684508e+08  \n",
       "203     2.684155e+08  \n",
       "637     2.684127e+08  \n",
       "696     2.684117e+08  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(gridX.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3d83ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final_RIDGEX = gridX.best_estimator_\n",
    "modelo_final_RIDGEZ = gridZ.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042038a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hola =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d76830e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('case_value_session2.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81be02d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-43287baae401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexplained_variance_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelo_final_XGBX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform_average'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_grid' is not defined"
     ]
    }
   ],
   "source": [
    "explained_variance_score(y_test, modelo_final_XGBX.predict(X_test_grid), multioutput='uniform_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dfb1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metric Results\n",
    "\n",
    "metric_results_oosX = pd.DataFrame({'Linear Regression' :  [explained_variance_score(y_test, LRX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, LRX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, LRX.predict(X_test)),\n",
    "    mean_squared_error(y_test, LRX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, LRX.predict(X_test))], \n",
    "                                     'GB' :  [explained_variance_score(y_test, modelo_final_GBX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_GBX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_GBX.predict(X_test)),\n",
    "    mean_squared_error(y_test, modelo_final_GBX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_GBX.predict(X_test))],\n",
    "                                     'HGB' :  [explained_variance_score(y_test, modelo_final_HGBX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_HGBX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_HGBX.predict(X_test)),\n",
    "    mean_squared_error(y_test, modelo_final_HGBX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_HGBX.predict(X_test))],\n",
    "                                    'RF' :  [explained_variance_score(y_test, modelo_final_RFX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_RFX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_RFX.predict(X_test)),\n",
    "    mean_squared_error(y_test, modelo_final_RFX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_RFX.predict(X_test))],\n",
    "                                    'PC Regression' :  [explained_variance_score(y_test, pcrX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, pcrX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, pcrX.predict(X_test)),\n",
    "    mean_squared_error(y_test, pcrX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, pcrX.predict(X_test))], \n",
    "                                    'PLS' :  [explained_variance_score(y_test, plsX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, plsX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, plsX.predict(X_test)),\n",
    "    mean_squared_error(y_test, plsX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, plsX.predict(X_test))], \n",
    "                                    'MLP' :  [explained_variance_score(y_test, modelo_final_MLPX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_MLPX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_MLPX.predict(X_test)),\n",
    "    mean_squared_error(y_test, modelo_final_MLPX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_MLPX.predict(X_test))],\n",
    "                                     'ElasticNet' :  [explained_variance_score(y_test, modelo_final_ENX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_ENX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_ENX.predict(X_test)),\n",
    "    mean_squared_error(y_test, modelo_final_ENX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_ENX.predict(X_test))],\n",
    "                                     'LASSO' :  [explained_variance_score(y_test, modelo_final_LASSOX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_LASSOX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_LASSOX.predict(X_test)),\n",
    "    mean_squared_error(y_test, modelo_final_LASSOX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_LASSOX.predict(X_test))],\n",
    "                                     'RIDGE' :  [explained_variance_score(y_test, modelo_final_RIDGEX.predict(X_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_RIDGEX.predict(X_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_RIDGEX.predict(X_test)),\n",
    "    mean_squared_error(y_test, modelo_final_RIDGEX.predict(X_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_RIDGEX.predict(X_test))]                                 \n",
    "                        })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42666d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_insX = pd.DataFrame({'Linear Regression' :  [explained_variance_score(y_train, LRX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, LRX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, LRX.predict(X_train)),\n",
    "    mean_squared_error(y_train, LRX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, LRX.predict(X_train))], \n",
    "                                     'GB' :  [explained_variance_score(y_train, modelo_final_GBX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_GBX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_GBX.predict(X_train)),\n",
    "    mean_squared_error(y_train, modelo_final_GBX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_GBX.predict(X_train))],\n",
    "                                     'HGB' :  [explained_variance_score(y_train, modelo_final_HGBX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_HGBX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_HGBX.predict(X_train)),\n",
    "    mean_squared_error(y_train, modelo_final_HGBX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_HGBX.predict(X_train))],\n",
    "                                    'RF' :  [explained_variance_score(y_train, modelo_final_RFX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_RFX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_RFX.predict(X_train)),\n",
    "    mean_squared_error(y_train, modelo_final_RFX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_RFX.predict(X_train))],\n",
    "                                    'PC Regression' :  [explained_variance_score(y_train, pcrX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, pcrX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, pcrX.predict(X_train)),\n",
    "    mean_squared_error(y_train, pcrX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, pcrX.predict(X_train))], \n",
    "                                    'PLS' :  [explained_variance_score(y_train, plsX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, plsX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, plsX.predict(X_train)),\n",
    "    mean_squared_error(y_train, plsX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, plsX.predict(X_train))], \n",
    "                                    'MLP' :  [explained_variance_score(y_train, modelo_final_MLPX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_MLPX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_MLPX.predict(X_train)),\n",
    "    mean_squared_error(y_train, modelo_final_MLPX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_MLPX.predict(X_train))],\n",
    "                                     'ElasticNet' :  [explained_variance_score(y_train, modelo_final_ENX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_ENX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_ENX.predict(X_train)),\n",
    "    mean_squared_error(y_train, modelo_final_ENX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_ENX.predict(X_train))],\n",
    "                                     'LASSO' :  [explained_variance_score(y_train, modelo_final_LASSOX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_LASSOX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_LASSOX.predict(X_train)),\n",
    "    mean_squared_error(y_train, modelo_final_LASSOX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_LASSOX.predict(X_train))],\n",
    "                                     'RIDGE' :  [explained_variance_score(y_train, modelo_final_RIDGEX.predict(X_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_RIDGEX.predict(X_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_RIDGEX.predict(X_train)),\n",
    "    mean_squared_error(y_train, modelo_final_RIDGEX.predict(X_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_RIDGEX.predict(X_train))]                                       \n",
    "                        })     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20ea8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_oosZ = pd.DataFrame({'Linear Regression' :  [explained_variance_score(y_test, LRZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, LRZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, LRZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, LRZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, LRZ.predict(Z_test))], \n",
    "                                     'GB' :  [explained_variance_score(y_test, modelo_final_GBZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_GBZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_GBZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, modelo_final_GBZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_GBZ.predict(Z_test))],\n",
    "                                     'HGB' :  [explained_variance_score(y_test, modelo_final_HGBZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_HGBZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_HGBZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, modelo_final_HGBZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_HGBZ.predict(Z_test))],\n",
    "                                    'RF' :  [explained_variance_score(y_test, modelo_final_RFZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_RFZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_RFZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, modelo_final_RFZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_RFZ.predict(Z_test))],\n",
    "                                    'PC Regression' :  [explained_variance_score(y_test, pcrZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, pcrZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, pcrZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, pcrZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, pcrZ.predict(Z_test))], \n",
    "                                    'PLS' :  [explained_variance_score(y_test, plsZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, plsZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, plsZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, plsZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, plsZ.predict(Z_test))], \n",
    "                                    'MLP' :  [explained_variance_score(y_test, modelo_final_MLPZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_MLPZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_MLPZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, modelo_final_MLPZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_MLPZ.predict(Z_test))],\n",
    "                                    'ElasticNet' :  [explained_variance_score(y_test, modelo_final_ENZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_ENZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_ENZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, modelo_final_ENZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_ENZ.predict(Z_test))],\n",
    "                                     'LASSO' :  [explained_variance_score(y_test, modelo_final_LASSOZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_LASSOZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_LASSOZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, modelo_final_LASSOZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_LASSOZ.predict(Z_test))],\n",
    "                                     'RIDGE' :  [explained_variance_score(y_test, modelo_final_RIDGEZ.predict(Z_test), multioutput='uniform_average'),\n",
    "    r2_score(y_test, modelo_final_RIDGEZ.predict(Z_test), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_test, modelo_final_RIDGEZ.predict(Z_test)),\n",
    "    mean_squared_error(y_test, modelo_final_RIDGEZ.predict(Z_test)),\n",
    "    mean_absolute_percentage_error(y_test, modelo_final_RIDGEZ.predict(Z_test))]                                       \n",
    "                        })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72601b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_insZ = pd.DataFrame({'Linear Regression' :  [explained_variance_score(y_train, LRZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, LRZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, LRZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, LRZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, LRZ.predict(Z_train))], \n",
    "                                     'GB' :  [explained_variance_score(y_train, modelo_final_GBZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_GBZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_GBZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, modelo_final_GBZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_GBZ.predict(Z_train))],\n",
    "                                     'HGB' :  [explained_variance_score(y_train, modelo_final_HGBZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_HGBZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_HGBZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, modelo_final_HGBZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_HGBZ.predict(Z_train))],\n",
    "                                    'RF' :  [explained_variance_score(y_train, modelo_final_RFZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_RFZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_RFZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, modelo_final_RFZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_RFZ.predict(Z_train))],\n",
    "                                    'PC Regression' :  [explained_variance_score(y_train, pcrZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, pcrZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, pcrZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, pcrZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, pcrZ.predict(Z_train))], \n",
    "                                    'PLS' :  [explained_variance_score(y_train, plsZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, plsZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, plsZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, plsZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, plsZ.predict(Z_train))], \n",
    "                                    'MLP' :  [explained_variance_score(y_train, modelo_final_MLPZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_MLPZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_MLPZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, modelo_final_MLPZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_MLPZ.predict(Z_train))],\n",
    "                                    'ElasticNet' :  [explained_variance_score(y_train, modelo_final_ENZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_ENZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_ENZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, modelo_final_ENZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_ENZ.predict(Z_train))],\n",
    "                                     'LASSO' :  [explained_variance_score(y_train, modelo_final_LASSOZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_LASSOZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_LASSOZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, modelo_final_LASSOZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_LASSOZ.predict(Z_train))],\n",
    "                                     'RIDGE' :  [explained_variance_score(y_train, modelo_final_RIDGEZ.predict(Z_train), multioutput='uniform_average'),\n",
    "    r2_score(y_train, modelo_final_RIDGEZ.predict(Z_train), multioutput='variance_weighted'),\n",
    "    mean_absolute_error(y_train, modelo_final_RIDGEZ.predict(Z_train)),\n",
    "    mean_squared_error(y_train, modelo_final_RIDGEZ.predict(Z_train)),\n",
    "    mean_absolute_percentage_error(y_train, modelo_final_RIDGEZ.predict(Z_train))]                                       \n",
    "                        })   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f705ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the row indexes\n",
    "metric_results_oosX.index = ['Explained Variance', 'R2', 'MAE', 'MSE', 'MAPE']\n",
    "metric_results_oosZ.index = ['Explained Variance', 'R2', 'MAE', 'MSE', 'MAPE']\n",
    "\n",
    "metric_results_insX.index = ['Explained Variance', 'R2', 'MAE', 'MSE', 'MAPE']\n",
    "metric_results_insZ.index = ['Explained Variance', 'R2', 'MAE', 'MSE', 'MAPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7310d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>GB</th>\n",
       "      <th>HGB</th>\n",
       "      <th>RF</th>\n",
       "      <th>PC Regression</th>\n",
       "      <th>PLS</th>\n",
       "      <th>MLP</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>RIDGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Explained Variance</th>\n",
       "      <td>-2.343740e-01</td>\n",
       "      <td>5.756901e-03</td>\n",
       "      <td>2.568199e-02</td>\n",
       "      <td>-4.057831e-02</td>\n",
       "      <td>-7.726093e-02</td>\n",
       "      <td>-2.452169e-01</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>-2.700171e-02</td>\n",
       "      <td>-1.927239e-01</td>\n",
       "      <td>-1.422428e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-2.349767e-01</td>\n",
       "      <td>4.819893e-03</td>\n",
       "      <td>2.514060e-02</td>\n",
       "      <td>-4.124860e-02</td>\n",
       "      <td>-7.783584e-02</td>\n",
       "      <td>-2.455255e-01</td>\n",
       "      <td>-3.040456e-03</td>\n",
       "      <td>-2.788614e-02</td>\n",
       "      <td>-1.935548e-01</td>\n",
       "      <td>-1.429461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2.858140e+04</td>\n",
       "      <td>2.593138e+04</td>\n",
       "      <td>2.375138e+04</td>\n",
       "      <td>2.463000e+04</td>\n",
       "      <td>2.556174e+04</td>\n",
       "      <td>2.807107e+04</td>\n",
       "      <td>2.479465e+04</td>\n",
       "      <td>2.557508e+04</td>\n",
       "      <td>2.789803e+04</td>\n",
       "      <td>2.719438e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.792510e+10</td>\n",
       "      <td>1.444457e+10</td>\n",
       "      <td>1.414962e+10</td>\n",
       "      <td>1.511323e+10</td>\n",
       "      <td>1.564428e+10</td>\n",
       "      <td>1.807821e+10</td>\n",
       "      <td>1.455866e+10</td>\n",
       "      <td>1.491928e+10</td>\n",
       "      <td>1.732388e+10</td>\n",
       "      <td>1.658932e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>4.312949e+19</td>\n",
       "      <td>3.042754e+19</td>\n",
       "      <td>3.282426e+19</td>\n",
       "      <td>3.584332e+19</td>\n",
       "      <td>3.824218e+19</td>\n",
       "      <td>4.490575e+19</td>\n",
       "      <td>2.555292e+19</td>\n",
       "      <td>3.393574e+19</td>\n",
       "      <td>4.049078e+19</td>\n",
       "      <td>3.963571e+19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Linear Regression            GB           HGB  \\\n",
       "Explained Variance      -2.343740e-01  5.756901e-03  2.568199e-02   \n",
       "R2                      -2.349767e-01  4.819893e-03  2.514060e-02   \n",
       "MAE                      2.858140e+04  2.593138e+04  2.375138e+04   \n",
       "MSE                      1.792510e+10  1.444457e+10  1.414962e+10   \n",
       "MAPE                     4.312949e+19  3.042754e+19  3.282426e+19   \n",
       "\n",
       "                              RF  PC Regression           PLS           MLP  \\\n",
       "Explained Variance -4.057831e-02  -7.726093e-02 -2.452169e-01 -2.220446e-16   \n",
       "R2                 -4.124860e-02  -7.783584e-02 -2.455255e-01 -3.040456e-03   \n",
       "MAE                 2.463000e+04   2.556174e+04  2.807107e+04  2.479465e+04   \n",
       "MSE                 1.511323e+10   1.564428e+10  1.807821e+10  1.455866e+10   \n",
       "MAPE                3.584332e+19   3.824218e+19  4.490575e+19  2.555292e+19   \n",
       "\n",
       "                      ElasticNet         LASSO         RIDGE  \n",
       "Explained Variance -2.700171e-02 -1.927239e-01 -1.422428e-01  \n",
       "R2                 -2.788614e-02 -1.935548e-01 -1.429461e-01  \n",
       "MAE                 2.557508e+04  2.789803e+04  2.719438e+04  \n",
       "MSE                 1.491928e+10  1.732388e+10  1.658932e+10  \n",
       "MAPE                3.393574e+19  4.049078e+19  3.963571e+19  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metric_results_oosX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9325f52a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>GB</th>\n",
       "      <th>HGB</th>\n",
       "      <th>RF</th>\n",
       "      <th>PC Regression</th>\n",
       "      <th>PLS</th>\n",
       "      <th>MLP</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>RIDGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Explained Variance</th>\n",
       "      <td>4.818090e-01</td>\n",
       "      <td>8.475546e-02</td>\n",
       "      <td>2.266503e-01</td>\n",
       "      <td>4.696838e-01</td>\n",
       "      <td>2.044104e-01</td>\n",
       "      <td>3.892432e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.188567e-01</td>\n",
       "      <td>4.591586e-01</td>\n",
       "      <td>4.490588e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>4.818090e-01</td>\n",
       "      <td>8.468013e-02</td>\n",
       "      <td>2.266496e-01</td>\n",
       "      <td>4.696837e-01</td>\n",
       "      <td>2.044104e-01</td>\n",
       "      <td>3.892432e-01</td>\n",
       "      <td>-1.045918e-03</td>\n",
       "      <td>1.188567e-01</td>\n",
       "      <td>4.591586e-01</td>\n",
       "      <td>4.490588e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.953041e+04</td>\n",
       "      <td>2.173867e+04</td>\n",
       "      <td>1.804140e+04</td>\n",
       "      <td>1.934380e+04</td>\n",
       "      <td>2.027697e+04</td>\n",
       "      <td>2.071015e+04</td>\n",
       "      <td>2.121435e+04</td>\n",
       "      <td>2.117004e+04</td>\n",
       "      <td>1.960023e+04</td>\n",
       "      <td>1.965609e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.417979e+09</td>\n",
       "      <td>4.271059e+09</td>\n",
       "      <td>3.608602e+09</td>\n",
       "      <td>2.474558e+09</td>\n",
       "      <td>3.712374e+09</td>\n",
       "      <td>2.849909e+09</td>\n",
       "      <td>4.671073e+09</td>\n",
       "      <td>4.111584e+09</td>\n",
       "      <td>2.523670e+09</td>\n",
       "      <td>2.570798e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>2.967977e+19</td>\n",
       "      <td>3.085985e+19</td>\n",
       "      <td>2.780587e+19</td>\n",
       "      <td>3.003333e+19</td>\n",
       "      <td>3.194653e+19</td>\n",
       "      <td>3.198886e+19</td>\n",
       "      <td>2.729415e+19</td>\n",
       "      <td>3.087164e+19</td>\n",
       "      <td>3.027446e+19</td>\n",
       "      <td>3.040176e+19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Linear Regression            GB           HGB  \\\n",
       "Explained Variance       4.818090e-01  8.475546e-02  2.266503e-01   \n",
       "R2                       4.818090e-01  8.468013e-02  2.266496e-01   \n",
       "MAE                      1.953041e+04  2.173867e+04  1.804140e+04   \n",
       "MSE                      2.417979e+09  4.271059e+09  3.608602e+09   \n",
       "MAPE                     2.967977e+19  3.085985e+19  2.780587e+19   \n",
       "\n",
       "                              RF  PC Regression           PLS           MLP  \\\n",
       "Explained Variance  4.696838e-01   2.044104e-01  3.892432e-01  0.000000e+00   \n",
       "R2                  4.696837e-01   2.044104e-01  3.892432e-01 -1.045918e-03   \n",
       "MAE                 1.934380e+04   2.027697e+04  2.071015e+04  2.121435e+04   \n",
       "MSE                 2.474558e+09   3.712374e+09  2.849909e+09  4.671073e+09   \n",
       "MAPE                3.003333e+19   3.194653e+19  3.198886e+19  2.729415e+19   \n",
       "\n",
       "                      ElasticNet         LASSO         RIDGE  \n",
       "Explained Variance  1.188567e-01  4.591586e-01  4.490588e-01  \n",
       "R2                  1.188567e-01  4.591586e-01  4.490588e-01  \n",
       "MAE                 2.117004e+04  1.960023e+04  1.965609e+04  \n",
       "MSE                 4.111584e+09  2.523670e+09  2.570798e+09  \n",
       "MAPE                3.087164e+19  3.027446e+19  3.040176e+19  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metric_results_insX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d58aaae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>GB</th>\n",
       "      <th>HGB</th>\n",
       "      <th>RF</th>\n",
       "      <th>PC Regression</th>\n",
       "      <th>PLS</th>\n",
       "      <th>MLP</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>RIDGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Explained Variance</th>\n",
       "      <td>2.835337e-02</td>\n",
       "      <td>9.489012e-03</td>\n",
       "      <td>6.621587e-02</td>\n",
       "      <td>-3.226580e-02</td>\n",
       "      <td>3.841113e-02</td>\n",
       "      <td>3.358932e-02</td>\n",
       "      <td>4.841440e-06</td>\n",
       "      <td>1.536531e-02</td>\n",
       "      <td>2.244450e-02</td>\n",
       "      <td>3.044054e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>2.764036e-02</td>\n",
       "      <td>8.563311e-03</td>\n",
       "      <td>6.561256e-02</td>\n",
       "      <td>-3.297225e-02</td>\n",
       "      <td>3.759324e-02</td>\n",
       "      <td>3.290093e-02</td>\n",
       "      <td>-3.657815e-02</td>\n",
       "      <td>1.412666e-02</td>\n",
       "      <td>2.126858e-02</td>\n",
       "      <td>2.972148e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2.659544e+04</td>\n",
       "      <td>2.559719e+04</td>\n",
       "      <td>2.395605e+04</td>\n",
       "      <td>2.386163e+04</td>\n",
       "      <td>2.580167e+04</td>\n",
       "      <td>2.652673e+04</td>\n",
       "      <td>2.323506e+04</td>\n",
       "      <td>2.520455e+04</td>\n",
       "      <td>2.483838e+04</td>\n",
       "      <td>2.645672e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.411334e+10</td>\n",
       "      <td>1.439023e+10</td>\n",
       "      <td>1.356219e+10</td>\n",
       "      <td>1.499310e+10</td>\n",
       "      <td>1.396888e+10</td>\n",
       "      <td>1.403698e+10</td>\n",
       "      <td>1.504544e+10</td>\n",
       "      <td>1.430948e+10</td>\n",
       "      <td>1.420582e+10</td>\n",
       "      <td>1.408313e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>3.974232e+19</td>\n",
       "      <td>3.055337e+19</td>\n",
       "      <td>3.334579e+19</td>\n",
       "      <td>3.357041e+19</td>\n",
       "      <td>3.840729e+19</td>\n",
       "      <td>3.964003e+19</td>\n",
       "      <td>4.031632e+17</td>\n",
       "      <td>2.982192e+19</td>\n",
       "      <td>3.032314e+19</td>\n",
       "      <td>3.949385e+19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Linear Regression            GB           HGB  \\\n",
       "Explained Variance       2.835337e-02  9.489012e-03  6.621587e-02   \n",
       "R2                       2.764036e-02  8.563311e-03  6.561256e-02   \n",
       "MAE                      2.659544e+04  2.559719e+04  2.395605e+04   \n",
       "MSE                      1.411334e+10  1.439023e+10  1.356219e+10   \n",
       "MAPE                     3.974232e+19  3.055337e+19  3.334579e+19   \n",
       "\n",
       "                              RF  PC Regression           PLS           MLP  \\\n",
       "Explained Variance -3.226580e-02   3.841113e-02  3.358932e-02  4.841440e-06   \n",
       "R2                 -3.297225e-02   3.759324e-02  3.290093e-02 -3.657815e-02   \n",
       "MAE                 2.386163e+04   2.580167e+04  2.652673e+04  2.323506e+04   \n",
       "MSE                 1.499310e+10   1.396888e+10  1.403698e+10  1.504544e+10   \n",
       "MAPE                3.357041e+19   3.840729e+19  3.964003e+19  4.031632e+17   \n",
       "\n",
       "                      ElasticNet         LASSO         RIDGE  \n",
       "Explained Variance  1.536531e-02  2.244450e-02  3.044054e-02  \n",
       "R2                  1.412666e-02  2.126858e-02  2.972148e-02  \n",
       "MAE                 2.520455e+04  2.483838e+04  2.645672e+04  \n",
       "MSE                 1.430948e+10  1.420582e+10  1.408313e+10  \n",
       "MAPE                2.982192e+19  3.032314e+19  3.949385e+19  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metric_results_oosZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b0f09e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>GB</th>\n",
       "      <th>HGB</th>\n",
       "      <th>RF</th>\n",
       "      <th>PC Regression</th>\n",
       "      <th>PLS</th>\n",
       "      <th>MLP</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>RIDGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Explained Variance</th>\n",
       "      <td>2.067206e-01</td>\n",
       "      <td>1.554393e-01</td>\n",
       "      <td>2.768596e-01</td>\n",
       "      <td>8.110967e-01</td>\n",
       "      <td>1.957438e-01</td>\n",
       "      <td>2.051874e-01</td>\n",
       "      <td>8.594188e-06</td>\n",
       "      <td>4.545314e-02</td>\n",
       "      <td>6.645025e-02</td>\n",
       "      <td>2.066206e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>2.067206e-01</td>\n",
       "      <td>1.553817e-01</td>\n",
       "      <td>2.768584e-01</td>\n",
       "      <td>8.103849e-01</td>\n",
       "      <td>1.957438e-01</td>\n",
       "      <td>2.051874e-01</td>\n",
       "      <td>-7.420521e-02</td>\n",
       "      <td>4.545314e-02</td>\n",
       "      <td>6.645025e-02</td>\n",
       "      <td>2.066206e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2.188030e+04</td>\n",
       "      <td>2.080569e+04</td>\n",
       "      <td>1.764395e+04</td>\n",
       "      <td>9.064958e+03</td>\n",
       "      <td>2.180754e+04</td>\n",
       "      <td>2.194568e+04</td>\n",
       "      <td>1.881194e+04</td>\n",
       "      <td>2.164840e+04</td>\n",
       "      <td>2.126546e+04</td>\n",
       "      <td>2.180482e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.701594e+09</td>\n",
       "      <td>3.941151e+09</td>\n",
       "      <td>3.374318e+09</td>\n",
       "      <td>8.847805e+08</td>\n",
       "      <td>3.752814e+09</td>\n",
       "      <td>3.708749e+09</td>\n",
       "      <td>5.012448e+09</td>\n",
       "      <td>4.454099e+09</td>\n",
       "      <td>4.356123e+09</td>\n",
       "      <td>3.702061e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>3.322249e+19</td>\n",
       "      <td>2.969248e+19</td>\n",
       "      <td>2.784856e+19</td>\n",
       "      <td>1.110061e+19</td>\n",
       "      <td>3.301983e+19</td>\n",
       "      <td>3.327075e+19</td>\n",
       "      <td>4.303956e+17</td>\n",
       "      <td>3.092333e+19</td>\n",
       "      <td>3.090862e+19</td>\n",
       "      <td>3.309251e+19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Linear Regression            GB           HGB  \\\n",
       "Explained Variance       2.067206e-01  1.554393e-01  2.768596e-01   \n",
       "R2                       2.067206e-01  1.553817e-01  2.768584e-01   \n",
       "MAE                      2.188030e+04  2.080569e+04  1.764395e+04   \n",
       "MSE                      3.701594e+09  3.941151e+09  3.374318e+09   \n",
       "MAPE                     3.322249e+19  2.969248e+19  2.784856e+19   \n",
       "\n",
       "                              RF  PC Regression           PLS           MLP  \\\n",
       "Explained Variance  8.110967e-01   1.957438e-01  2.051874e-01  8.594188e-06   \n",
       "R2                  8.103849e-01   1.957438e-01  2.051874e-01 -7.420521e-02   \n",
       "MAE                 9.064958e+03   2.180754e+04  2.194568e+04  1.881194e+04   \n",
       "MSE                 8.847805e+08   3.752814e+09  3.708749e+09  5.012448e+09   \n",
       "MAPE                1.110061e+19   3.301983e+19  3.327075e+19  4.303956e+17   \n",
       "\n",
       "                      ElasticNet         LASSO         RIDGE  \n",
       "Explained Variance  4.545314e-02  6.645025e-02  2.066206e-01  \n",
       "R2                  4.545314e-02  6.645025e-02  2.066206e-01  \n",
       "MAE                 2.164840e+04  2.126546e+04  2.180482e+04  \n",
       "MSE                 4.454099e+09  4.356123e+09  3.702061e+09  \n",
       "MAPE                3.092333e+19  3.090862e+19  3.309251e+19  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metric_results_insZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0122347",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_oosX.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38125095",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c3fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(path + '/_aux/p3_case_value.csv') \n",
    "predX = df_pred[['gen',\n",
    "            'reclutamiento',\n",
    "            'salario_diario',\n",
    "            'horas_sem',\n",
    "            'reinst',\n",
    "            'prima_dom',\n",
    "            'desc_sem',\n",
    "            'sarimssinf',\n",
    "            'antiguedad',\n",
    "            'c_recsueldo',\n",
    "            'desc_ob',\n",
    "            'min_prima_antig',\n",
    "            'min_ag',\n",
    "            'min_vac',\n",
    "            'min_ley']]\n",
    "\n",
    "predZ = df_pred[['num_actores',\n",
    "            'gen',\n",
    "            'reclutamiento',\n",
    "            'salario_diario',\n",
    "            'antiguedad',          \n",
    "            'horas_sem',\n",
    "            'reinst',\n",
    "            'indem',\n",
    "            'sal_caidos',\n",
    "            'prima_antig',\n",
    "            'prima_vac',\n",
    "            'horas_extra',\n",
    "            'rec20',\n",
    "            'prima_dom',\n",
    "            'desc_sem',\n",
    "            'sarimssinf',\n",
    "            'utilidades',\n",
    "            'nulidad']]\n",
    "\n",
    "\n",
    "dict_modelsX = {\n",
    "    \"GB\": [modelo_final_GBX, GBX],\n",
    "    \"HGB\": [modelo_final_HGBX, HGBX],\n",
    "    \"RF\": [modelo_final_RFX, RFX]\n",
    "}\n",
    "\n",
    "dict_modelsZ = {\n",
    "    \"GB\": [modelo_final_GBZ, GBZ],\n",
    "    \"HGB\": [modelo_final_HGBZ, HGBZ],\n",
    "    \"RF\": [modelo_final_RFZ, RFZ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fc45b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_value = df_pred[['id_actor', 'dem']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d51197eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in dict_modelsX:\n",
    "    params = dict_modelsX[model][0].get_params()\n",
    "    dict_modelsX[model][1].set_params(**params)\n",
    "    dict_modelsX[model][1].fit(X,y2)\n",
    "    pre = pd.DataFrame(dict_modelsX[model][1].predict(predX))\n",
    "    name = 'preX_'+model\n",
    "    pre.rename(columns={0: name}, inplace=True)\n",
    "    case_value = pd.concat([case_value, pre], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b62b52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in dict_modelsZ:\n",
    "    params = dict_modelsZ[model][0].get_params()\n",
    "    dict_modelsZ[model][1].set_params(**params)\n",
    "    dict_modelsZ[model][1].fit(Z,y2)\n",
    "    pre = pd.DataFrame(dict_modelsZ[model][1].predict(predZ))\n",
    "    name = 'preZ_'+model\n",
    "    pre.rename(columns={0: name}, inplace=True)\n",
    "    case_value = pd.concat([case_value, pre], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e391ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_actor</th>\n",
       "      <th>dem</th>\n",
       "      <th>preX_GB</th>\n",
       "      <th>preX_HGB</th>\n",
       "      <th>preX_RF</th>\n",
       "      <th>preZ_GB</th>\n",
       "      <th>preZ_HGB</th>\n",
       "      <th>preZ_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>27711.263221</td>\n",
       "      <td>23891.365194</td>\n",
       "      <td>15159.673135</td>\n",
       "      <td>18350.893952</td>\n",
       "      <td>20280.280089</td>\n",
       "      <td>12947.882439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>14241.634424</td>\n",
       "      <td>15881.867273</td>\n",
       "      <td>11465.052658</td>\n",
       "      <td>15328.599842</td>\n",
       "      <td>14168.255732</td>\n",
       "      <td>1751.510616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000_1</td>\n",
       "      <td>0</td>\n",
       "      <td>18637.475058</td>\n",
       "      <td>17291.948941</td>\n",
       "      <td>12788.842459</td>\n",
       "      <td>17902.191585</td>\n",
       "      <td>16519.780982</td>\n",
       "      <td>8035.597409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>22970.684514</td>\n",
       "      <td>18972.508864</td>\n",
       "      <td>18814.369245</td>\n",
       "      <td>23188.004696</td>\n",
       "      <td>20680.558165</td>\n",
       "      <td>19652.144715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_1</td>\n",
       "      <td>0</td>\n",
       "      <td>16209.037857</td>\n",
       "      <td>17291.948941</td>\n",
       "      <td>11856.464822</td>\n",
       "      <td>15415.054025</td>\n",
       "      <td>15657.642393</td>\n",
       "      <td>5522.309140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>22884.981655</td>\n",
       "      <td>18293.693958</td>\n",
       "      <td>24019.690656</td>\n",
       "      <td>22751.858437</td>\n",
       "      <td>17940.484477</td>\n",
       "      <td>22629.845395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>20457.276448</td>\n",
       "      <td>20120.488736</td>\n",
       "      <td>13627.953228</td>\n",
       "      <td>18158.982323</td>\n",
       "      <td>21248.016080</td>\n",
       "      <td>10987.297812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>959_1</td>\n",
       "      <td>1</td>\n",
       "      <td>17508.592861</td>\n",
       "      <td>19446.885543</td>\n",
       "      <td>14120.860890</td>\n",
       "      <td>19602.185285</td>\n",
       "      <td>17776.988087</td>\n",
       "      <td>14461.967766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>968</td>\n",
       "      <td>1</td>\n",
       "      <td>17359.974086</td>\n",
       "      <td>16048.699123</td>\n",
       "      <td>11465.052658</td>\n",
       "      <td>18229.763040</td>\n",
       "      <td>14995.221808</td>\n",
       "      <td>7576.413293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>986</td>\n",
       "      <td>1</td>\n",
       "      <td>16763.583869</td>\n",
       "      <td>17123.151354</td>\n",
       "      <td>11465.052658</td>\n",
       "      <td>16573.160629</td>\n",
       "      <td>14995.221808</td>\n",
       "      <td>7527.393986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4154 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_actor  dem       preX_GB      preX_HGB       preX_RF       preZ_GB  \\\n",
       "0         100    0  27711.263221  23891.365194  15159.673135  18350.893952   \n",
       "1        1000    0  14241.634424  15881.867273  11465.052658  15328.599842   \n",
       "2      1000_1    0  18637.475058  17291.948941  12788.842459  17902.191585   \n",
       "3        1001    0  22970.684514  18972.508864  18814.369245  23188.004696   \n",
       "4      1001_1    0  16209.037857  17291.948941  11856.464822  15415.054025   \n",
       "...       ...  ...           ...           ...           ...           ...   \n",
       "4149      889    1  22884.981655  18293.693958  24019.690656  22751.858437   \n",
       "4150       91    1  20457.276448  20120.488736  13627.953228  18158.982323   \n",
       "4151    959_1    1  17508.592861  19446.885543  14120.860890  19602.185285   \n",
       "4152      968    1  17359.974086  16048.699123  11465.052658  18229.763040   \n",
       "4153      986    1  16763.583869  17123.151354  11465.052658  16573.160629   \n",
       "\n",
       "          preZ_HGB       preZ_RF  \n",
       "0     20280.280089  12947.882439  \n",
       "1     14168.255732   1751.510616  \n",
       "2     16519.780982   8035.597409  \n",
       "3     20680.558165  19652.144715  \n",
       "4     15657.642393   5522.309140  \n",
       "...            ...           ...  \n",
       "4149  17940.484477  22629.845395  \n",
       "4150  21248.016080  10987.297812  \n",
       "4151  17776.988087  14461.967766  \n",
       "4152  14995.221808   7576.413293  \n",
       "4153  14995.221808   7527.393986  \n",
       "\n",
       "[4154 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1afd71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "case_value.to_csv(os.path.join(path + '/_aux/case_value.csv') , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0bb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
